{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585c0806-03a9-4ed6-b624-43e8049eca08",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用设备: cpu\n",
      "加载数据集...\n",
      "处理24个演员目录...\n",
      "数据集加载完成: 1440个样本, 8种情感\n",
      "情感分布:\n",
      "  surprised: 192个样本\n",
      "  calm: 192个样本\n",
      "  disgust: 192个样本\n",
      "  happy: 192个样本\n",
      "  sad: 192个样本\n",
      "  fearful: 192个样本\n",
      "  neutral: 96个样本\n",
      "  angry: 192个样本\n",
      "模型参数: 403,727\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import librosa\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "\n",
    "# 配置设备\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"使用设备: {device}\")\n",
    "\n",
    "# 1. 数据预处理 - 适配您的数据集结构\n",
    "class SpeechEmotionDataset(Dataset):\n",
    "    def __init__(self, base_path, max_length=500, n_mfcc=40, actor_ids=None):\n",
    "        \"\"\"\n",
    "        :param base_path: 数据集根目录 (e.g., 'F:/F/LifeLongLearning/TUNI/Thesis/Code/archive')\n",
    "        :param max_length: MFCC序列最大长度\n",
    "        :param n_mfcc: MFCC特征维度\n",
    "        :param actor_ids: 使用的演员ID列表 (None表示使用全部)\n",
    "        \"\"\"\n",
    "        self.data = []\n",
    "        self.labels = []\n",
    "        self.max_length = max_length\n",
    "        self.n_mfcc = n_mfcc\n",
    "        \n",
    "        # 情感标签映射\n",
    "        emotion_map = {\n",
    "            '01': 'neutral', '02': 'calm', '03': 'happy', '04': 'sad',\n",
    "            '05': 'angry', '06': 'fearful', '07': 'disgust', '08': 'surprised'\n",
    "        }\n",
    "        \n",
    "        # 获取所有演员目录\n",
    "        if actor_ids is None:\n",
    "            actor_dirs = glob.glob(os.path.join(base_path, 'Actor_*'))\n",
    "        else:\n",
    "            actor_dirs = [os.path.join(base_path, f'Actor_{id:02d}') for id in actor_ids]\n",
    "        \n",
    "        print(f\"处理{len(actor_dirs)}个演员目录...\")\n",
    "        \n",
    "        # 遍历所有演员目录\n",
    "        for actor_dir in actor_dirs:\n",
    "            if not os.path.isdir(actor_dir):\n",
    "                continue\n",
    "                \n",
    "            # 获取该演员的所有wav文件\n",
    "            wav_files = glob.glob(os.path.join(actor_dir, '*.wav'))\n",
    "            \n",
    "            for wav_file in wav_files:\n",
    "                # 提取文件名并解析情感\n",
    "                filename = os.path.basename(wav_file)\n",
    "                parts = filename.split('-')\n",
    "                \n",
    "                # 确保文件名格式正确\n",
    "                if len(parts) < 7:\n",
    "                    continue\n",
    "                \n",
    "                emotion_code = parts[2]\n",
    "                emotion = emotion_map.get(emotion_code, None)\n",
    "                \n",
    "                if emotion is None:\n",
    "                    continue\n",
    "                \n",
    "                # 加载音频并提取MFCC特征\n",
    "                try:\n",
    "                    y, sr = librosa.load(wav_file, sr=16000)\n",
    "                    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)\n",
    "                    \n",
    "                    # 标准化并填充/截断到固定长度\n",
    "                    mfcc = (mfcc - np.mean(mfcc)) / np.std(mfcc)\n",
    "                    if mfcc.shape[1] > max_length:\n",
    "                        mfcc = mfcc[:, :max_length]\n",
    "                    else:\n",
    "                        pad_width = max_length - mfcc.shape[1]\n",
    "                        mfcc = np.pad(mfcc, ((0, 0), (0, pad_width)), mode='constant')\n",
    "                    \n",
    "                    # 添加到数据集\n",
    "                    self.data.append(mfcc)\n",
    "                    self.labels.append(emotion)\n",
    "                except Exception as e:\n",
    "                    print(f\"处理文件 {wav_file} 时出错: {str(e)}\")\n",
    "        \n",
    "        # 将标签转换为数字\n",
    "        self.emotion_to_idx = {e: i for i, e in enumerate(set(self.labels))}\n",
    "        self.labels_idx = [self.emotion_to_idx[l] for l in self.labels]\n",
    "        self.num_classes = len(self.emotion_to_idx)\n",
    "        \n",
    "        print(f\"数据集加载完成: {len(self.data)}个样本, {self.num_classes}种情感\")\n",
    "        print(\"情感分布:\")\n",
    "        for emotion, idx in self.emotion_to_idx.items():\n",
    "            count = self.labels.count(emotion)\n",
    "            print(f\"  {emotion}: {count}个样本\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.data[idx], dtype=torch.float32), torch.tensor(self.labels_idx[idx], dtype=torch.long)\n",
    "\n",
    "# 2. Rossler混沌神经元实现\n",
    "class RosslerCell(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, a=0.2, b=0.2, c=5.7, dt=0.1):\n",
    "        super(RosslerCell, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.a = nn.Parameter(torch.tensor(a, dtype=torch.float32))\n",
    "        self.b = nn.Parameter(torch.tensor(b, dtype=torch.float32))\n",
    "        self.c = nn.Parameter(torch.tensor(c, dtype=torch.float32))\n",
    "        self.dt = dt\n",
    "        \n",
    "        # 输入到隐藏状态的权重\n",
    "        self.w_ih = nn.Linear(input_size, 3 * hidden_size)\n",
    "        \n",
    "        # 隐藏状态到隐藏状态的权重\n",
    "        self.w_hh = nn.Linear(3 * hidden_size, 3 * hidden_size)\n",
    "        \n",
    "        # Lyapunov指数监控\n",
    "        self.le_reg = LyapunovRegularizer(target_le=0.05)\n",
    "        \n",
    "        # 初始化隐藏状态\n",
    "        self.reset_parameters()\n",
    "    \n",
    "    def reset_parameters(self):\n",
    "        \"\"\"初始化权重\"\"\"\n",
    "        stdv = 1.0 / np.sqrt(self.hidden_size)\n",
    "        for weight in self.parameters():\n",
    "            if weight.dim() > 1:\n",
    "                weight.data.uniform_(-stdv, stdv)\n",
    "    \n",
    "    def forward(self, x, hx=None):\n",
    "        batch_size = x.size(0)\n",
    "        \n",
    "        # 初始化隐藏状态\n",
    "        if hx is None:\n",
    "            hx = torch.zeros(batch_size, 3, self.hidden_size, device=x.device)\n",
    "            hx += 0.01 * torch.randn_like(hx)\n",
    "        \n",
    "        # 分离状态分量\n",
    "        x_state, y_state, z_state = torch.chunk(hx, 3, dim=1)\n",
    "        x_state = x_state.squeeze(1)\n",
    "        y_state = y_state.squeeze(1)\n",
    "        z_state = z_state.squeeze(1)\n",
    "        \n",
    "        # 输入变换\n",
    "        i2h = self.w_ih(x)  # (batch_size, 3*hidden_size)\n",
    "        i2h = i2h.view(batch_size, 3, self.hidden_size)\n",
    "        i_x, i_y, i_z = torch.chunk(i2h, 3, dim=1)\n",
    "        \n",
    "        # Rossler方程离散化\n",
    "        dx = (-y_state - z_state + i_x.squeeze(1)) * self.dt\n",
    "        dy = (x_state + self.a * y_state + i_y.squeeze(1)) * self.dt\n",
    "        dz = (self.b + z_state * (x_state - self.c) + i_z.squeeze(1)) * self.dt\n",
    "        \n",
    "        # 更新状态\n",
    "        new_x = x_state + dx\n",
    "        new_y = y_state + dy\n",
    "        new_z = z_state + dz\n",
    "        \n",
    "        # 组合新状态\n",
    "        new_hx = torch.stack([new_x, new_y, new_z], dim=1)\n",
    "        \n",
    "        # 计算Lyapunov损失\n",
    "        le_loss = self.le_reg(new_hx)\n",
    "        \n",
    "        return new_hx, le_loss\n",
    "\n",
    "# Lyapunov正则化器\n",
    "class LyapunovRegularizer(nn.Module):\n",
    "    def __init__(self, target_le=0.05, reg_strength=0.1):\n",
    "        super().__init__()\n",
    "        self.target_le = target_le\n",
    "        self.reg_strength = reg_strength\n",
    "        self.le_history = []\n",
    "    \n",
    "    def forward(self, state):\n",
    "        # 使用雅可比矩阵的谱范数作为LE的近似\n",
    "        with torch.enable_grad():\n",
    "            batch_size, _, hidden_size = state.shape\n",
    "            state = state.detach().requires_grad_(True)\n",
    "            \n",
    "            perturbation = 1e-6 * torch.randn_like(state)\n",
    "            \n",
    "            dx = -state[:, 1] - state[:, 2]\n",
    "            dy = state[:, 0] + 0.2 * state[:, 1]\n",
    "            dz = 0.2 + state[:, 2] * (state[:, 0] - 5.7)\n",
    "            \n",
    "            jvp_dx = torch.autograd.grad(dx, state, grad_outputs=perturbation, \n",
    "                                        retain_graph=True, create_graph=False)[0]\n",
    "            jvp_dy = torch.autograd.grad(dy, state, grad_outputs=perturbation, \n",
    "                                        retain_graph=True, create_graph=False)[0]\n",
    "            jvp_dz = torch.autograd.grad(dz, state, grad_outputs=perturbation, \n",
    "                                        retain_graph=True, create_graph=False)[0]\n",
    "            \n",
    "            jvp = torch.stack([jvp_dx, jvp_dy, jvp_dz], dim=1)\n",
    "            \n",
    "            norm = torch.norm(jvp, dim=(1, 2))\n",
    "            le_approx = torch.log(norm) / 1.0\n",
    "        \n",
    "        current_le = le_approx.mean().item()\n",
    "        self.le_history.append(current_le)\n",
    "        \n",
    "        reg_loss = self.reg_strength * torch.abs(le_approx.mean() - self.target_le)\n",
    "        \n",
    "        return reg_loss\n",
    "\n",
    "# 3. 混沌神经网络架构\n",
    "class ChaoticSpeechNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes, num_layers=1):\n",
    "        super(ChaoticSpeechNet, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        # 输入投影层\n",
    "        self.input_proj = nn.Linear(input_size, hidden_size)\n",
    "        \n",
    "        # Rossler混沌层\n",
    "        self.chaos_cells = nn.ModuleList()\n",
    "        for _ in range(num_layers):\n",
    "            self.chaos_cells.append(RosslerCell(hidden_size, hidden_size))\n",
    "        \n",
    "        # 输出层\n",
    "        self.fc = nn.Linear(3 * hidden_size, num_classes)\n",
    "        \n",
    "        # 层归一化\n",
    "        self.ln = nn.LayerNorm(hidden_size)\n",
    "        \n",
    "        # 注意力机制\n",
    "        self.attention = nn.Linear(3 * hidden_size, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        batch_size, seq_len, _ = x.shape\n",
    "        le_loss_total = 0.0\n",
    "        \n",
    "        # 初始化隐藏状态\n",
    "        hx = None\n",
    "        all_states = []\n",
    "        \n",
    "        # 处理序列\n",
    "        for t in range(seq_len):\n",
    "            # 输入投影\n",
    "            x_t = self.input_proj(x[:, t, :])\n",
    "            \n",
    "            # 通过所有混沌层\n",
    "            for i, cell in enumerate(self.chaos_cells):\n",
    "                if i == 0:\n",
    "                    input_t = x_t\n",
    "                else:\n",
    "                    input_t = h_state\n",
    "                \n",
    "                hx, le_loss = cell(input_t, hx)\n",
    "                le_loss_total += le_loss\n",
    "                h_state = hx[:, -1, :]\n",
    "                h_state = self.ln(h_state)\n",
    "            \n",
    "            all_states.append(hx)\n",
    "        \n",
    "        all_states = torch.stack(all_states, dim=0)\n",
    "        flat_states = all_states.view(seq_len, batch_size, -1)\n",
    "        \n",
    "        # 注意力加权\n",
    "        attn_weights = torch.softmax(self.attention(flat_states).squeeze(-1), dim=0)\n",
    "        context = torch.sum(attn_weights.unsqueeze(-1) * flat_states, dim=0)\n",
    "        \n",
    "        # 分类\n",
    "        output = self.fc(context)\n",
    "        \n",
    "        return output, le_loss_total / seq_len\n",
    "\n",
    "# 4. 可视化函数\n",
    "def visualize_rossler_attractor(model, sample_input, save_path=None):\n",
    "    \"\"\"可视化Rossler吸引子\"\"\"\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        hx = None\n",
    "        trajectory = []\n",
    "        \n",
    "        for t in range(sample_input.size(1)):\n",
    "            x_t = sample_input[:, t, :]\n",
    "            x_t = model.input_proj(x_t)\n",
    "            hx, _ = model.chaos_cells[0](x_t, hx)\n",
    "            state = hx[0, :, 0].cpu().numpy()\n",
    "            trajectory.append(state)\n",
    "        \n",
    "        trajectory = np.array(trajectory)\n",
    "        \n",
    "        fig = plt.figure(figsize=(10, 8))\n",
    "        ax = fig.add_subplot(111, projection='3d')\n",
    "        ax.plot(trajectory[:, 0], trajectory[:, 1], trajectory[:, 2], lw=0.5)\n",
    "        ax.set_title(\"Rossler吸引子轨迹\")\n",
    "        ax.set_xlabel(\"X\")\n",
    "        ax.set_ylabel(\"Y\")\n",
    "        ax.set_zlabel(\"Z\")\n",
    "        \n",
    "        if save_path:\n",
    "            plt.savefig(save_path)\n",
    "            print(f\"吸引子图已保存至: {save_path}\")\n",
    "        else:\n",
    "            plt.show()\n",
    "        \n",
    "        return trajectory\n",
    "\n",
    "# 5. 训练和评估\n",
    "def train_model(model, dataloader, test_dataloader, num_epochs=50, lr=0.001):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode='max', factor=0.5, patience=5, verbose=True\n",
    "    )\n",
    "    \n",
    "    history = {\n",
    "        'train_loss': [], 'train_acc': [], 'test_acc': [], 'le_history': []\n",
    "    }\n",
    "    \n",
    "    best_acc = 0.0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        for i, (inputs, labels) in enumerate(dataloader):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            # 前向传播\n",
    "            outputs, le_loss = model(inputs)\n",
    "            ce_loss = criterion(outputs, labels)\n",
    "            loss = ce_loss + le_loss\n",
    "            \n",
    "            # 反向传播\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "            \n",
    "            # 统计\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            history['le_history'].append(le_loss.item())\n",
    "            \n",
    "            if (i+1) % 10 == 0:\n",
    "                print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(dataloader)}], '\n",
    "                      f'Loss: {loss.item():.4f}, CE: {ce_loss.item():.4f}, LE: {le_loss.item():.4f}')\n",
    "        \n",
    "        # 计算训练精度\n",
    "        train_loss = running_loss / len(dataloader)\n",
    "        train_acc = 100 * correct / total\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['train_acc'].append(train_acc)\n",
    "        \n",
    "        # 在测试集上评估\n",
    "        test_acc = evaluate_model(model, test_dataloader)\n",
    "        history['test_acc'].append(test_acc)\n",
    "        \n",
    "        # 更新学习率\n",
    "        scheduler.step(test_acc)\n",
    "        \n",
    "        # 保存最佳模型\n",
    "        if test_acc > best_acc:\n",
    "            best_acc = test_acc\n",
    "            torch.save(model.state_dict(), 'best_chaotic_model.pth')\n",
    "            print(f\"保存最佳模型，测试精度: {test_acc:.2f}%\")\n",
    "        \n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], '\n",
    "              f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%, Test Acc: {test_acc:.2f}%')\n",
    "    \n",
    "    return history\n",
    "\n",
    "def evaluate_model(model, dataloader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs, _ = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    return 100 * correct / total\n",
    "\n",
    "# 6. 结果可视化\n",
    "def plot_results(history):\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.plot(history['train_loss'], label='Train Loss')\n",
    "    plt.title('Training Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.plot(history['train_acc'], label='Train Accuracy')\n",
    "    plt.plot(history['test_acc'], label='Test Accuracy')\n",
    "    plt.title('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy (%)')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(2, 2, 3)\n",
    "    plt.plot(history['le_history'])\n",
    "    plt.title('Lyapunov Exponent History')\n",
    "    plt.xlabel('Step')\n",
    "    plt.ylabel('LE Loss')\n",
    "    \n",
    "    plt.subplot(2, 2, 4)\n",
    "    window_size = 100\n",
    "    le_ma = np.convolve(history['le_history'], np.ones(window_size)/window_size, mode='valid')\n",
    "    plt.plot(le_ma)\n",
    "    plt.title(f'Lyapunov Exponent (Moving Avg, window={window_size})')\n",
    "    plt.xlabel('Step')\n",
    "    plt.ylabel('Smoothed LE')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('training_results.png')\n",
    "    print(\"训练结果图已保存至: training_results.png\")\n",
    "    plt.show()\n",
    "\n",
    "# 7. 混淆矩阵可视化\n",
    "def plot_confusion_matrix(model, dataloader, class_names):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs, _ = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    # 计算混淆矩阵\n",
    "    cm = np.zeros((len(class_names), len(class_names)), dtype=int)\n",
    "    for i in range(len(all_labels)):\n",
    "        cm[all_labels[i], all_preds[i]] += 1\n",
    "    \n",
    "    # 可视化\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.colorbar()\n",
    "    \n",
    "    tick_marks = np.arange(len(class_names))\n",
    "    plt.xticks(tick_marks, class_names, rotation=45)\n",
    "    plt.yticks(tick_marks, class_names)\n",
    "    \n",
    "    # 添加数值标签\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(len(class_names)):\n",
    "        for j in range(len(class_names)):\n",
    "            plt.text(j, i, format(cm[i, j], 'd'),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    \n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('confusion_matrix.png')\n",
    "    print(\"混淆矩阵已保存至: confusion_matrix.png\")\n",
    "    plt.show()\n",
    "\n",
    "# 主函数\n",
    "def main():\n",
    "    # 参数配置\n",
    "    config = {\n",
    "        'base_path': 'F:/F/LifeLongLearning/TUNI/Thesis/Code/archive',  # 替换为您的实际路径\n",
    "        'batch_size': 32,\n",
    "        'max_length': 500,      # MFCC序列最大长度\n",
    "        'n_mfcc': 40,           # MFCC系数数量\n",
    "        'hidden_size': 128,     # 混沌神经元隐藏大小\n",
    "        'num_layers': 2,        # 混沌层数\n",
    "        'lr': 0.001,\n",
    "        'num_epochs': 30,       # 减少epoch数以加快实验\n",
    "        'test_size': 0.2,\n",
    "        'seed': 42,\n",
    "        'actor_ids': list(range(1, 25))  # 使用所有24位演员\n",
    "    }\n",
    "    \n",
    "    # 设置随机种子\n",
    "    torch.manual_seed(config['seed'])\n",
    "    np.random.seed(config['seed'])\n",
    "    \n",
    "    # 加载数据集\n",
    "    print(\"加载数据集...\")\n",
    "    dataset = SpeechEmotionDataset(\n",
    "        base_path=config['base_path'], \n",
    "        max_length=config['max_length'],\n",
    "        n_mfcc=config['n_mfcc'],\n",
    "        actor_ids=config['actor_ids']\n",
    "    )\n",
    "    \n",
    "    # 划分训练集和测试集\n",
    "    train_indices, test_indices = train_test_split(\n",
    "        range(len(dataset)), \n",
    "        test_size=config['test_size'], \n",
    "        random_state=config['seed'],\n",
    "        stratify=dataset.labels_idx  # 分层抽样保持类别分布\n",
    "    )\n",
    "    \n",
    "    train_dataset = torch.utils.data.Subset(dataset, train_indices)\n",
    "    test_dataset = torch.utils.data.Subset(dataset, test_indices)\n",
    "    \n",
    "    train_dataloader = DataLoader(\n",
    "        train_dataset, \n",
    "        batch_size=config['batch_size'], \n",
    "        shuffle=True,\n",
    "        num_workers=4\n",
    "    )\n",
    "    \n",
    "    test_dataloader = DataLoader(\n",
    "        test_dataset, \n",
    "        batch_size=config['batch_size'], \n",
    "        shuffle=False,\n",
    "        num_workers=4\n",
    "    )\n",
    "    \n",
    "    # 创建模型\n",
    "    model = ChaoticSpeechNet(\n",
    "        input_size=config['n_mfcc'],\n",
    "        hidden_size=config['hidden_size'],\n",
    "        num_classes=dataset.num_classes,\n",
    "        num_layers=config['num_layers']\n",
    "    ).to(device)\n",
    "    \n",
    "    print(f\"模型参数: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "    \n",
    "    # 可视化初始吸引子\n",
    "    sample_input, _ = next(iter(train_dataloader))\n",
    "    visualize_rossler_attractor(\n",
    "        model, \n",
    "        sample_input[:1].to(device),  # 单个样本\n",
    "        save_path='initial_attractor.png'\n",
    "    )\n",
    "    \n",
    "    # 训练模型\n",
    "    print(\"开始训练...\")\n",
    "    history = train_model(\n",
    "        model,\n",
    "        train_dataloader,\n",
    "        test_dataloader,\n",
    "        num_epochs=config['num_epochs'],\n",
    "        lr=config['lr']\n",
    "    )\n",
    "    \n",
    "    # 可视化结果\n",
    "    plot_results(history)\n",
    "    \n",
    "    # 可视化训练后的吸引子\n",
    "    visualize_rossler_attractor(\n",
    "        model, \n",
    "        sample_input[:1].to(device),  # 单个样本\n",
    "        save_path='trained_attractor.png'\n",
    "    )\n",
    "    \n",
    "    # 评估最终模型\n",
    "    final_acc = evaluate_model(model, test_dataloader)\n",
    "    print(f\"最终测试精度: {final_acc:.2f}%\")\n",
    "    \n",
    "    # 绘制混淆矩阵\n",
    "    class_names = list(dataset.emotion_to_idx.keys())\n",
    "    plot_confusion_matrix(model, test_dataloader, class_names)\n",
    "    \n",
    "    # 保存完整模型\n",
    "    torch.save({\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'config': config,\n",
    "        'class_to_idx': dataset.emotion_to_idx\n",
    "    }, 'full_chaotic_speech_model.pth')\n",
    "    print(\"完整模型已保存至: full_chaotic_speech_model.pth\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a783c8-038d-4b68-80d0-e54a17a042a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-VirEnvir] *",
   "language": "python",
   "name": "conda-env-.conda-VirEnvir-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
