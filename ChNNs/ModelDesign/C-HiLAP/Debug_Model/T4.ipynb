{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f984f1b-64a0-438f-b983-9439834095fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "class Config:\n",
    "    # 数据加载器配置\n",
    "    DEBUG_MODE = True\n",
    "    DEBUG_SAMPLE_SIZE = 2000  # 减少样本数量以适应3秒音频\n",
    "    BASE_DIR = os.getcwd()\n",
    "    LIBRISPEECH_PATH = os.path.join(BASE_DIR, \"devDataset\", \"LibriSpeech\")\n",
    "    SAMPLE_RATE = 16000\n",
    "    DURATION = 3.0\n",
    "    MAX_SAMPLES = int(SAMPLE_RATE * DURATION)\n",
    "    NOISE_TYPES = [\"white\", \"babble\"]\n",
    "    SNR_LEVELS = [0, 5, 10]\n",
    "    BATCH_SIZE = 8\n",
    "    NUM_WORKERS = 2\n",
    "    VALID_RATIO = 0.1\n",
    "    MAX_SEQ_LEN = 48000\n",
    "    \n",
    "    # 模型配置\n",
    "    INPUT_DIM = 1\n",
    "    HIDDEN_DIM = 256\n",
    "    EMBEDDING_DIM = 128\n",
    "    CHAOS_DIM = 64\n",
    "    CHAOS_TIME_STEPS = 5\n",
    "    ATTENTION_HEADS = 4\n",
    "    \n",
    "    # 训练配置 \n",
    "    EPOCHS = 200 # 减少训练轮数以适应更长的训练时间\n",
    "    LR = 0.01\n",
    "    LR_DECAY = 0.95\n",
    "    WEIGHT_DECAY = 1e-5\n",
    "    SAVE_INTERVAL = 10\n",
    "    VAL_INTERVAL = 1\n",
    "    CHECKPOINT_DIR = \"../checkpoints_T4\"\n",
    "    WARMUP_EPOCHS = 5\n",
    "    GRAD_CLIP = 1.0\n",
    "    CE_WEIGHT = 1.0\n",
    "    PATIENCE = 10\n",
    "    MIN_DELTA = 0.001\n",
    "    GRADIENT_ACCUMULATION_STEPS = 2  # 减少梯度累积步数\n",
    "    ENABLE_MIXED_PRECISION = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62662b56-7989-456d-9221-c8db77b92099",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "创建T4数据加载器: 批大小=8\n",
      "加载LibriSpeech数据集: /users/tianyuey/Project/devDataset/LibriSpeech\n",
      "处理子集: dev-clean\n",
      "处理子集: dev-other\n",
      "找到 73 个不同的说话人\n",
      "无效文件: /users/tianyuey/Project/devDataset/LibriSpeech/dev-other/1651/136854/1651-136854-0012.flac - 音频过短 (17040采样点)，需要至少2秒音频\n",
      "无效文件: /users/tianyuey/Project/devDataset/LibriSpeech/dev-other/1255/90407/1255-90407-0010.flac - 音频过短 (25920采样点)，需要至少2秒音频\n",
      "无效文件: /users/tianyuey/Project/devDataset/LibriSpeech/dev-other/5849/50873/5849-50873-0030.flac - 音频过短 (30560采样点)，需要至少2秒音频\n",
      "无效文件: /users/tianyuey/Project/devDataset/LibriSpeech/dev-other/6841/88291/6841-88291-0043.flac - 音频过短 (31601采样点)，需要至少2秒音频\n",
      "无效文件: /users/tianyuey/Project/devDataset/LibriSpeech/dev-other/1585/131718/1585-131718-0040.flac - 音频过短 (31120采样点)，需要至少2秒音频\n",
      "无效文件: /users/tianyuey/Project/devDataset/LibriSpeech/dev-clean/2428/83699/2428-83699-0004.flac - 音频过短 (30080采样点)，需要至少2秒音频\n",
      "无效文件: /users/tianyuey/Project/devDataset/LibriSpeech/dev-other/1255/138279/1255-138279-0020.flac - 音频过短 (25040采样点)，需要至少2秒音频\n",
      "无效文件: /users/tianyuey/Project/devDataset/LibriSpeech/dev-clean/5694/64025/5694-64025-0000.flac - 音频过短 (26720采样点)，需要至少2秒音频\n",
      "无效文件: /users/tianyuey/Project/devDataset/LibriSpeech/dev-clean/5338/284437/5338-284437-0025.flac - 音频过短 (31040采样点)，需要至少2秒音频\n",
      "无效文件: /users/tianyuey/Project/devDataset/LibriSpeech/dev-clean/1272/141231/1272-141231-0013.flac - 音频过短 (26239采样点)，需要至少2秒音频\n",
      "无效文件: /users/tianyuey/Project/devDataset/LibriSpeech/dev-other/700/122868/700-122868-0026.flac - 音频过短 (29360采样点)，需要至少2秒音频\n",
      "无效文件: /users/tianyuey/Project/devDataset/LibriSpeech/dev-other/700/122868/700-122868-0033.flac - 音频过短 (21920采样点)，需要至少2秒音频\n",
      "无效文件: /users/tianyuey/Project/devDataset/LibriSpeech/dev-other/116/288045/116-288045-0027.flac - 音频过短 (31600采样点)，需要至少2秒音频\n",
      "无效文件: /users/tianyuey/Project/devDataset/LibriSpeech/dev-other/1630/73710/1630-73710-0004.flac - 音频过短 (28480采样点)，需要至少2秒音频\n",
      "无效文件: /users/tianyuey/Project/devDataset/LibriSpeech/dev-clean/2035/147961/2035-147961-0033.flac - 音频过短 (31120采样点)，需要至少2秒音频\n",
      "无效文件: /users/tianyuey/Project/devDataset/LibriSpeech/dev-other/5543/27761/5543-27761-0019.flac - 音频过短 (31120采样点)，需要至少2秒音频\n",
      "无效文件: /users/tianyuey/Project/devDataset/LibriSpeech/dev-other/8288/274162/8288-274162-0062.flac - 音频过短 (27840采样点)，需要至少2秒音频\n",
      "无效文件: /users/tianyuey/Project/devDataset/LibriSpeech/dev-other/8288/274162/8288-274162-0049.flac - 音频过短 (28560采样点)，需要至少2秒音频\n",
      "无效文件: /users/tianyuey/Project/devDataset/LibriSpeech/dev-clean/2277/149896/2277-149896-0004.flac - 音频过短 (31280采样点)，需要至少2秒音频\n",
      "无效文件: /users/tianyuey/Project/devDataset/LibriSpeech/dev-clean/3081/166546/3081-166546-0018.flac - 音频过短 (28400采样点)，需要至少2秒音频\n",
      "无效文件: /users/tianyuey/Project/devDataset/LibriSpeech/dev-other/3660/6517/3660-6517-0029.flac - 音频过短 (30640采样点)，需要至少2秒音频\n",
      "无效文件: /users/tianyuey/Project/devDataset/LibriSpeech/dev-clean/1272/135031/1272-135031-0009.flac - 音频过短 (30560采样点)，需要至少2秒音频\n",
      "无效文件: /users/tianyuey/Project/devDataset/LibriSpeech/dev-clean/174/50561/174-50561-0014.flac - 音频过短 (28800采样点)，需要至少2秒音频\n",
      "无效文件: /users/tianyuey/Project/devDataset/LibriSpeech/dev-other/1686/142278/1686-142278-0038.flac - 音频过短 (31360采样点)，需要至少2秒音频\n",
      "无效文件: /users/tianyuey/Project/devDataset/LibriSpeech/dev-other/1686/142278/1686-142278-0000.flac - 音频过短 (26480采样点)，需要至少2秒音频\n",
      "无效文件: /users/tianyuey/Project/devDataset/LibriSpeech/dev-clean/777/126732/777-126732-0081.flac - 音频过短 (24080采样点)，需要至少2秒音频\n",
      "无效文件: /users/tianyuey/Project/devDataset/LibriSpeech/dev-other/4153/186222/4153-186222-0002.flac - 音频过短 (30880采样点)，需要至少2秒音频\n",
      "无效文件: /users/tianyuey/Project/devDataset/LibriSpeech/dev-other/4572/112383/4572-112383-0000.flac - 音频过短 (24160采样点)，需要至少2秒音频\n",
      "无效文件: /users/tianyuey/Project/devDataset/LibriSpeech/dev-clean/7976/105575/7976-105575-0017.flac - 音频过短 (30960采样点)，需要至少2秒音频\n",
      "有效文件: 1971/2000\n",
      "找到 73 个不同的说话人\n",
      "最终 train 数据集大小: 1971 个样本\n",
      "加载LibriSpeech数据集: /users/tianyuey/Project/devDataset/LibriSpeech\n",
      "处理子集: dev-clean\n",
      "处理子集: dev-other\n",
      "找到 73 个不同的说话人\n",
      "无效文件: /users/tianyuey/Project/devDataset/LibriSpeech/dev-other/700/122868/700-122868-0023.flac - 音频过短 (22400采样点)，需要至少2秒音频\n",
      "无效文件: /users/tianyuey/Project/devDataset/LibriSpeech/dev-clean/6313/66129/6313-66129-0032.flac - 音频过短 (29760采样点)，需要至少2秒音频\n",
      "无效文件: /users/tianyuey/Project/devDataset/LibriSpeech/dev-other/1255/90413/1255-90413-0015.flac - 音频过短 (28960采样点)，需要至少2秒音频\n",
      "无效文件: /users/tianyuey/Project/devDataset/LibriSpeech/dev-other/116/288045/116-288045-0014.flac - 音频过短 (21760采样点)，需要至少2秒音频\n",
      "无效文件: /users/tianyuey/Project/devDataset/LibriSpeech/dev-other/8254/84205/8254-84205-0013.flac - 音频过短 (31521采样点)，需要至少2秒音频\n",
      "无效文件: /users/tianyuey/Project/devDataset/LibriSpeech/dev-clean/2428/83705/2428-83705-0036.flac - 音频过短 (31360采样点)，需要至少2秒音频\n",
      "无效文件: /users/tianyuey/Project/devDataset/LibriSpeech/dev-clean/3752/4944/3752-4944-0046.flac - 音频过短 (29760采样点)，需要至少2秒音频\n",
      "无效文件: /users/tianyuey/Project/devDataset/LibriSpeech/dev-other/4515/11057/4515-11057-0077.flac - 音频过短 (30880采样点)，需要至少2秒音频\n",
      "无效文件: /users/tianyuey/Project/devDataset/LibriSpeech/dev-clean/1272/135031/1272-135031-0014.flac - 音频过短 (27840采样点)，需要至少2秒音频\n",
      "无效文件: /users/tianyuey/Project/devDataset/LibriSpeech/dev-clean/2078/142845/2078-142845-0023.flac - 音频过短 (28000采样点)，需要至少2秒音频\n",
      "无效文件: /users/tianyuey/Project/devDataset/LibriSpeech/dev-other/1701/141759/1701-141759-0020.flac - 音频过短 (22320采样点)，需要至少2秒音频\n",
      "有效文件: 546/557\n",
      "找到 73 个不同的说话人\n",
      "最终 val 数据集大小: 546 个样本\n",
      "加载LibriSpeech数据集: /users/tianyuey/Project/devDataset/LibriSpeech\n",
      "处理子集: dev-clean\n",
      "处理子集: dev-other\n",
      "找到 73 个不同的说话人\n",
      "无效文件: /users/tianyuey/Project/devDataset/LibriSpeech/dev-other/6267/65525/6267-65525-0055.flac - 音频过短 (31200采样点)，需要至少2秒音频\n",
      "无效文件: /users/tianyuey/Project/devDataset/LibriSpeech/dev-other/1585/157660/1585-157660-0003.flac - 音频过短 (31440采样点)，需要至少2秒音频\n",
      "无效文件: /users/tianyuey/Project/devDataset/LibriSpeech/dev-other/1585/131718/1585-131718-0040.flac - 音频过短 (31120采样点)，需要至少2秒音频\n",
      "无效文件: /users/tianyuey/Project/devDataset/LibriSpeech/dev-other/1255/138279/1255-138279-0020.flac - 音频过短 (25040采样点)，需要至少2秒音频\n",
      "无效文件: /users/tianyuey/Project/devDataset/LibriSpeech/dev-other/1255/90413/1255-90413-0015.flac - 音频过短 (28960采样点)，需要至少2秒音频\n",
      "无效文件: /users/tianyuey/Project/devDataset/LibriSpeech/dev-other/1255/90413/1255-90413-0004.flac - 音频过短 (30560采样点)，需要至少2秒音频\n",
      "无效文件: /users/tianyuey/Project/devDataset/LibriSpeech/dev-other/1255/90413/1255-90413-0003.flac - 音频过短 (29440采样点)，需要至少2秒音频\n",
      "无效文件: /users/tianyuey/Project/devDataset/LibriSpeech/dev-other/1255/90407/1255-90407-0010.flac - 音频过短 (25920采样点)，需要至少2秒音频\n",
      "无效文件: /users/tianyuey/Project/devDataset/LibriSpeech/dev-other/1255/90407/1255-90407-0005.flac - 音频过短 (22080采样点)，需要至少2秒音频\n",
      "无效文件: /users/tianyuey/Project/devDataset/LibriSpeech/dev-other/8254/115543/8254-115543-0037.flac - 音频过短 (28800采样点)，需要至少2秒音频\n",
      "无效文件: /users/tianyuey/Project/devDataset/LibriSpeech/dev-other/8254/84205/8254-84205-0013.flac - 音频过短 (31521采样点)，需要至少2秒音频\n",
      "无效文件: /users/tianyuey/Project/devDataset/LibriSpeech/dev-other/8254/84205/8254-84205-0073.flac - 音频过短 (30560采样点)，需要至少2秒音频\n",
      "无效文件: /users/tianyuey/Project/devDataset/LibriSpeech/dev-other/8254/84205/8254-84205-0026.flac - 音频过短 (28800采样点)，需要至少2秒音频\n",
      "无效文件: /users/tianyuey/Project/devDataset/LibriSpeech/dev-other/8254/84205/8254-84205-0028.flac - 音频过短 (30800采样点)，需要至少2秒音频\n",
      "无效文件: /users/tianyuey/Project/devDataset/LibriSpeech/dev-other/700/122867/700-122867-0029.flac - 音频过短 (30880采样点)，需要至少2秒音频\n",
      "无效文件: /users/tianyuey/Project/devDataset/LibriSpeech/dev-other/700/122867/700-122867-0040.flac - 音频过短 (29600采样点)，需要至少2秒音频\n",
      "无效文件: /users/tianyuey/Project/devDataset/LibriSpeech/dev-other/700/122868/700-122868-0023.flac - 音频过短 (22400采样点)，需要至少2秒音频\n",
      "无效文件: /users/tianyuey/Project/devDataset/LibriSpeech/dev-other/700/122868/700-122868-0026.flac - 音频过短 (29360采样点)，需要至少2秒音频\n",
      "无效文件: /users/tianyuey/Project/devDataset/LibriSpeech/dev-other/700/122868/700-122868-0033.flac - 音频过短 (21920采样点)，需要至少2秒音频\n",
      "无效文件: /users/tianyuey/Project/devDataset/LibriSpeech/dev-other/700/122868/700-122868-0011.flac - 音频过短 (29840采样点)，需要至少2秒音频\n",
      "无效文件: /users/tianyuey/Project/devDataset/LibriSpeech/dev-other/116/288047/116-288047-0006.flac - 音频过短 (26800采样点)，需要至少2秒音频\n",
      "无效文件: /users/tianyuey/Project/devDataset/LibriSpeech/dev-other/116/288046/116-288046-0009.flac - 音频过短 (30080采样点)，需要至少2秒音频\n",
      "无效文件: /users/tianyuey/Project/devDataset/LibriSpeech/dev-other/116/288045/116-288045-0014.flac - 音频过短 (21760采样点)，需要至少2秒音频\n",
      "无效文件: /users/tianyuey/Project/devDataset/LibriSpeech/dev-other/116/288045/116-288045-0027.flac - 音频过短 (31600采样点)，需要至少2秒音频\n",
      "无效文件: /users/tianyuey/Project/devDataset/LibriSpeech/dev-other/116/288045/116-288045-0017.flac - 音频过短 (29200采样点)，需要至少2秒音频\n",
      "无效文件: /users/tianyuey/Project/devDataset/LibriSpeech/dev-other/3660/6517/3660-6517-0029.flac - 音频过短 (30640采样点)，需要至少2秒音频\n",
      "无效文件: /users/tianyuey/Project/devDataset/LibriSpeech/dev-other/1630/96099/1630-96099-0019.flac - 音频过短 (31680采样点)，需要至少2秒音频\n",
      "无效文件: /users/tianyuey/Project/devDataset/LibriSpeech/dev-other/1630/73710/1630-73710-0004.flac - 音频过短 (28480采样点)，需要至少2秒音频\n",
      "无效文件: /users/tianyuey/Project/devDataset/LibriSpeech/dev-other/5543/27761/5543-27761-0019.flac - 音频过短 (31120采样点)，需要至少2秒音频\n",
      "无效文件: /users/tianyuey/Project/devDataset/LibriSpeech/dev-other/4515/11057/4515-11057-0006.flac - 音频过短 (31680采样点)，需要至少2秒音频\n",
      "无效文件: /users/tianyuey/Project/devDataset/LibriSpeech/dev-other/4515/11057/4515-11057-0077.flac - 音频过短 (30880采样点)，需要至少2秒音频\n",
      "无效文件: /users/tianyuey/Project/devDataset/LibriSpeech/dev-other/4515/11057/4515-11057-0053.flac - 音频过短 (21360采样点)，需要至少2秒音频\n",
      "无效文件: /users/tianyuey/Project/devDataset/LibriSpeech/dev-other/8288/274162/8288-274162-0062.flac - 音频过短 (27840采样点)，需要至少2秒音频\n",
      "无效文件: /users/tianyuey/Project/devDataset/LibriSpeech/dev-other/8288/274162/8288-274162-0059.flac - 音频过短 (27440采样点)，需要至少2秒音频\n",
      "无效文件: /users/tianyuey/Project/devDataset/LibriSpeech/dev-other/8288/274162/8288-274162-0049.flac - 音频过短 (28560采样点)，需要至少2秒音频\n",
      "无效文件: /users/tianyuey/Project/devDataset/LibriSpeech/dev-other/4323/18416/4323-18416-0012.flac - 音频过短 (27120采样点)，需要至少2秒音频\n",
      "无效文件: /users/tianyuey/Project/devDataset/LibriSpeech/dev-other/4323/55228/4323-55228-0045.flac - 音频过短 (30720采样点)，需要至少2秒音频\n",
      "无效文件: /users/tianyuey/Project/devDataset/LibriSpeech/dev-other/4323/55228/4323-55228-0038.flac - 音频过短 (31280采样点)，需要至少2秒音频\n",
      "无效文件: /users/tianyuey/Project/devDataset/LibriSpeech/dev-other/6467/94831/6467-94831-0005.flac - 音频过短 (25280采样点)，需要至少2秒音频\n",
      "无效文件: /users/tianyuey/Project/devDataset/LibriSpeech/dev-other/7601/175351/7601-175351-0005.flac - 音频过短 (30880采样点)，需要至少2秒音频\n",
      "无效文件: /users/tianyuey/Project/devDataset/LibriSpeech/dev-other/1651/136854/1651-136854-0012.flac - 音频过短 (17040采样点)，需要至少2秒音频\n",
      "无效文件: /users/tianyuey/Project/devDataset/LibriSpeech/dev-other/6841/88291/6841-88291-0043.flac - 音频过短 (31601采样点)，需要至少2秒音频\n",
      "无效文件: /users/tianyuey/Project/devDataset/LibriSpeech/dev-other/6841/88291/6841-88291-0048.flac - 音频过短 (29920采样点)，需要至少2秒音频\n",
      "无效文件: /users/tianyuey/Project/devDataset/LibriSpeech/dev-other/4153/186222/4153-186222-0002.flac - 音频过短 (30880采样点)，需要至少2秒音频\n",
      "无效文件: /users/tianyuey/Project/devDataset/LibriSpeech/dev-other/4153/186222/4153-186222-0001.flac - 音频过短 (30640采样点)，需要至少2秒音频\n",
      "无效文件: /users/tianyuey/Project/devDataset/LibriSpeech/dev-other/1701/141759/1701-141759-0020.flac - 音频过短 (22320采样点)，需要至少2秒音频\n",
      "无效文件: /users/tianyuey/Project/devDataset/LibriSpeech/dev-other/1686/142278/1686-142278-0000.flac - 音频过短 (26480采样点)，需要至少2秒音频\n",
      "无效文件: /users/tianyuey/Project/devDataset/LibriSpeech/dev-other/1686/142278/1686-142278-0038.flac - 音频过短 (31360采样点)，需要至少2秒音频\n",
      "无效文件: /users/tianyuey/Project/devDataset/LibriSpeech/dev-other/1686/142278/1686-142278-0008.flac - 音频过短 (18800采样点)，需要至少2秒音频\n",
      "无效文件: /users/tianyuey/Project/devDataset/LibriSpeech/dev-other/1686/142278/1686-142278-0068.flac - 音频过短 (18960采样点)，需要至少2秒音频\n",
      "无效文件: /users/tianyuey/Project/devDataset/LibriSpeech/dev-other/1686/142278/1686-142278-0041.flac - 音频过短 (21440采样点)，需要至少2秒音频\n",
      "无效文件: /users/tianyuey/Project/devDataset/LibriSpeech/dev-other/1686/142278/1686-142278-0083.flac - 音频过短 (27360采样点)，需要至少2秒音频\n",
      "无效文件: /users/tianyuey/Project/devDataset/LibriSpeech/dev-other/8173/294714/8173-294714-0037.flac - 音频过短 (29120采样点)，需要至少2秒音频\n",
      "无效文件: /users/tianyuey/Project/devDataset/LibriSpeech/dev-other/4572/112383/4572-112383-0000.flac - 音频过短 (24160采样点)，需要至少2秒音频\n",
      "无效文件: /users/tianyuey/Project/devDataset/LibriSpeech/dev-other/5849/50963/5849-50963-0004.flac - 音频过短 (31520采样点)，需要至少2秒音频\n",
      "无效文件: /users/tianyuey/Project/devDataset/LibriSpeech/dev-other/5849/50873/5849-50873-0030.flac - 音频过短 (30560采样点)，需要至少2秒音频\n",
      "无效文件: /users/tianyuey/Project/devDataset/LibriSpeech/dev-clean/251/136532/251-136532-0022.flac - 音频过短 (24560采样点)，需要至少2秒音频\n",
      "无效文件: /users/tianyuey/Project/devDataset/LibriSpeech/dev-clean/2412/153947/2412-153947-0012.flac - 音频过短 (31680采样点)，需要至少2秒音频\n",
      "无效文件: /users/tianyuey/Project/devDataset/LibriSpeech/dev-clean/5694/64038/5694-64038-0008.flac - 音频过短 (31200采样点)，需要至少2秒音频\n",
      "无效文件: /users/tianyuey/Project/devDataset/LibriSpeech/dev-clean/5694/64025/5694-64025-0000.flac - 音频过短 (26720采样点)，需要至少2秒音频\n",
      "无效文件: /users/tianyuey/Project/devDataset/LibriSpeech/dev-clean/6313/66129/6313-66129-0032.flac - 音频过短 (29760采样点)，需要至少2秒音频\n",
      "无效文件: /users/tianyuey/Project/devDataset/LibriSpeech/dev-clean/3752/4944/3752-4944-0008.flac - 音频过短 (31040采样点)，需要至少2秒音频\n",
      "无效文件: /users/tianyuey/Project/devDataset/LibriSpeech/dev-clean/3752/4944/3752-4944-0046.flac - 音频过短 (29760采样点)，需要至少2秒音频\n",
      "无效文件: /users/tianyuey/Project/devDataset/LibriSpeech/dev-clean/2428/83705/2428-83705-0036.flac - 音频过短 (31360采样点)，需要至少2秒音频\n",
      "无效文件: /users/tianyuey/Project/devDataset/LibriSpeech/dev-clean/2428/83699/2428-83699-0039.flac - 音频过短 (31680采样点)，需要至少2秒音频\n",
      "无效文件: /users/tianyuey/Project/devDataset/LibriSpeech/dev-clean/2428/83699/2428-83699-0022.flac - 音频过短 (31600采样点)，需要至少2秒音频\n",
      "无效文件: /users/tianyuey/Project/devDataset/LibriSpeech/dev-clean/2428/83699/2428-83699-0004.flac - 音频过短 (30080采样点)，需要至少2秒音频\n",
      "无效文件: /users/tianyuey/Project/devDataset/LibriSpeech/dev-clean/2428/83699/2428-83699-0009.flac - 音频过短 (29600采样点)，需要至少2秒音频\n",
      "无效文件: /users/tianyuey/Project/devDataset/LibriSpeech/dev-clean/6345/93302/6345-93302-0028.flac - 音频过短 (31040采样点)，需要至少2秒音频\n",
      "无效文件: /users/tianyuey/Project/devDataset/LibriSpeech/dev-clean/174/50561/174-50561-0014.flac - 音频过短 (28800采样点)，需要至少2秒音频\n",
      "无效文件: /users/tianyuey/Project/devDataset/LibriSpeech/dev-clean/3081/166546/3081-166546-0018.flac - 音频过短 (28400采样点)，需要至少2秒音频\n",
      "无效文件: /users/tianyuey/Project/devDataset/LibriSpeech/dev-clean/3081/166546/3081-166546-0076.flac - 音频过短 (31040采样点)，需要至少2秒音频\n",
      "无效文件: /users/tianyuey/Project/devDataset/LibriSpeech/dev-clean/3081/166546/3081-166546-0008.flac - 音频过短 (28320采样点)，需要至少2秒音频\n",
      "无效文件: /users/tianyuey/Project/devDataset/LibriSpeech/dev-clean/3081/166546/3081-166546-0073.flac - 音频过短 (23120采样点)，需要至少2秒音频\n",
      "无效文件: /users/tianyuey/Project/devDataset/LibriSpeech/dev-clean/3081/166546/3081-166546-0063.flac - 音频过短 (27840采样点)，需要至少2秒音频\n",
      "无效文件: /users/tianyuey/Project/devDataset/LibriSpeech/dev-clean/2035/147960/2035-147960-0015.flac - 音频过短 (24960采样点)，需要至少2秒音频\n",
      "无效文件: /users/tianyuey/Project/devDataset/LibriSpeech/dev-clean/2035/147961/2035-147961-0033.flac - 音频过短 (31120采样点)，需要至少2秒音频\n",
      "无效文件: /users/tianyuey/Project/devDataset/LibriSpeech/dev-clean/2277/149896/2277-149896-0004.flac - 音频过短 (31280采样点)，需要至少2秒音频\n",
      "无效文件: /users/tianyuey/Project/devDataset/LibriSpeech/dev-clean/1988/24833/1988-24833-0006.flac - 音频过短 (31680采样点)，需要至少2秒音频\n",
      "无效文件: /users/tianyuey/Project/devDataset/LibriSpeech/dev-clean/2078/142845/2078-142845-0023.flac - 音频过短 (28000采样点)，需要至少2秒音频\n",
      "无效文件: /users/tianyuey/Project/devDataset/LibriSpeech/dev-clean/5338/284437/5338-284437-0025.flac - 音频过短 (31040采样点)，需要至少2秒音频\n",
      "无效文件: /users/tianyuey/Project/devDataset/LibriSpeech/dev-clean/5338/284437/5338-284437-0014.flac - 音频过短 (29520采样点)，需要至少2秒音频\n",
      "无效文件: /users/tianyuey/Project/devDataset/LibriSpeech/dev-clean/1919/142785/1919-142785-0048.flac - 音频过短 (29440采样点)，需要至少2秒音频\n",
      "无效文件: /users/tianyuey/Project/devDataset/LibriSpeech/dev-clean/1919/142785/1919-142785-0021.flac - 音频过短 (27040采样点)，需要至少2秒音频\n",
      "无效文件: /users/tianyuey/Project/devDataset/LibriSpeech/dev-clean/8842/304647/8842-304647-0007.flac - 音频过短 (27680采样点)，需要至少2秒音频\n",
      "无效文件: /users/tianyuey/Project/devDataset/LibriSpeech/dev-clean/1272/141231/1272-141231-0013.flac - 音频过短 (26239采样点)，需要至少2秒音频\n",
      "无效文件: /users/tianyuey/Project/devDataset/LibriSpeech/dev-clean/1272/141231/1272-141231-0016.flac - 音频过短 (29600采样点)，需要至少2秒音频\n",
      "无效文件: /users/tianyuey/Project/devDataset/LibriSpeech/dev-clean/1272/135031/1272-135031-0014.flac - 音频过短 (27840采样点)，需要至少2秒音频\n",
      "无效文件: /users/tianyuey/Project/devDataset/LibriSpeech/dev-clean/1272/135031/1272-135031-0009.flac - 音频过短 (30560采样点)，需要至少2秒音频\n",
      "无效文件: /users/tianyuey/Project/devDataset/LibriSpeech/dev-clean/7976/105575/7976-105575-0017.flac - 音频过短 (30960采样点)，需要至少2秒音频\n",
      "无效文件: /users/tianyuey/Project/devDataset/LibriSpeech/dev-clean/8297/275155/8297-275155-0021.flac - 音频过短 (28400采样点)，需要至少2秒音频\n",
      "无效文件: /users/tianyuey/Project/devDataset/LibriSpeech/dev-clean/777/126732/777-126732-0026.flac - 音频过短 (31520采样点)，需要至少2秒音频\n",
      "无效文件: /users/tianyuey/Project/devDataset/LibriSpeech/dev-clean/777/126732/777-126732-0081.flac - 音频过短 (24080采样点)，需要至少2秒音频\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 259\u001b[39m\n\u001b[32m    257\u001b[39m \u001b[38;5;66;03m# 测试代码\u001b[39;00m\n\u001b[32m    258\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m259\u001b[39m     dataloaders = \u001b[43mget_dataloaders\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    260\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m dataloaders \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mtrain\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m dataloaders:\n\u001b[32m    261\u001b[39m         x, y = \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(dataloaders[\u001b[33m\"\u001b[39m\u001b[33mtrain\u001b[39m\u001b[33m\"\u001b[39m]))\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 217\u001b[39m, in \u001b[36mget_dataloaders\u001b[39m\u001b[34m(batch_size)\u001b[39m\n\u001b[32m    215\u001b[39m train_dataset = SpeakerRecognitionDataset(split=\u001b[33m\"\u001b[39m\u001b[33mtrain\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    216\u001b[39m val_dataset = SpeakerRecognitionDataset(split=\u001b[33m\"\u001b[39m\u001b[33mval\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m217\u001b[39m test_dataset = \u001b[43mSpeakerRecognitionDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtest\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[38;5;66;03m# 如果训练集为空，尝试直接加载测试集\u001b[39;00m\n\u001b[32m    220\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(train_dataset) == \u001b[32m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(test_dataset) > \u001b[32m0\u001b[39m:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 68\u001b[39m, in \u001b[36mSpeakerRecognitionDataset.__init__\u001b[39m\u001b[34m(self, split, add_noise, noise_type, snr_db)\u001b[39m\n\u001b[32m     65\u001b[39m         \u001b[38;5;28mself\u001b[39m.audio_paths = \u001b[38;5;28mself\u001b[39m.audio_paths[:\u001b[38;5;28mmin\u001b[39m(Config.DEBUG_SAMPLE_SIZE // \u001b[32m2\u001b[39m, \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.audio_paths))]\n\u001b[32m     66\u001b[39m         \u001b[38;5;28mself\u001b[39m.labels = \u001b[38;5;28mself\u001b[39m.labels[:\u001b[38;5;28mmin\u001b[39m(Config.DEBUG_SAMPLE_SIZE // \u001b[32m2\u001b[39m, \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.labels))]\n\u001b[32m---> \u001b[39m\u001b[32m68\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m最终 \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msplit\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m 数据集大小: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.audio_paths)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m 个样本\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 138\u001b[39m, in \u001b[36mSpeakerRecognitionDataset._validate_dataset\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    136\u001b[39m \u001b[38;5;66;03m# 读取音频文件\u001b[39;00m\n\u001b[32m    137\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m path.endswith(\u001b[33m'\u001b[39m\u001b[33m.flac\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m138\u001b[39m     signal, sr = \u001b[43msf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    139\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    140\u001b[39m     signal, sr = librosa.load(path, sr=Config.SAMPLE_RATE, mono=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/soundfile.py:305\u001b[39m, in \u001b[36mread\u001b[39m\u001b[34m(file, frames, start, stop, dtype, always_2d, fill_value, out, samplerate, channels, format, subtype, endian, closefd)\u001b[39m\n\u001b[32m    219\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mread\u001b[39m(file, frames=-\u001b[32m1\u001b[39m, start=\u001b[32m0\u001b[39m, stop=\u001b[38;5;28;01mNone\u001b[39;00m, dtype=\u001b[33m'\u001b[39m\u001b[33mfloat64\u001b[39m\u001b[33m'\u001b[39m, always_2d=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    220\u001b[39m          fill_value=\u001b[38;5;28;01mNone\u001b[39;00m, out=\u001b[38;5;28;01mNone\u001b[39;00m, samplerate=\u001b[38;5;28;01mNone\u001b[39;00m, channels=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    221\u001b[39m          \u001b[38;5;28mformat\u001b[39m=\u001b[38;5;28;01mNone\u001b[39;00m, subtype=\u001b[38;5;28;01mNone\u001b[39;00m, endian=\u001b[38;5;28;01mNone\u001b[39;00m, closefd=\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m    222\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Provide audio data from a sound file as NumPy array.\u001b[39;00m\n\u001b[32m    223\u001b[39m \n\u001b[32m    224\u001b[39m \u001b[33;03m    By default, the whole file is read from the beginning, but the\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    303\u001b[39m \n\u001b[32m    304\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m305\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mSoundFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msamplerate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchannels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    306\u001b[39m \u001b[43m                   \u001b[49m\u001b[43msubtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mendian\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosefd\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    307\u001b[39m \u001b[43m        \u001b[49m\u001b[43mframes\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_prepare_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    308\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malways_2d\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/soundfile.py:770\u001b[39m, in \u001b[36mSoundFile.__exit__\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m    769\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args):\n\u001b[32m--> \u001b[39m\u001b[32m770\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclose\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/soundfile.py:1235\u001b[39m, in \u001b[36mSoundFile.close\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1232\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.closed:\n\u001b[32m   1233\u001b[39m     \u001b[38;5;66;03m# be sure to flush data to disk before closing the file\u001b[39;00m\n\u001b[32m   1234\u001b[39m     \u001b[38;5;28mself\u001b[39m.flush()\n\u001b[32m-> \u001b[39m\u001b[32m1235\u001b[39m     err = \u001b[43m_snd\u001b[49m\u001b[43m.\u001b[49m\u001b[43msf_close\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1236\u001b[39m     \u001b[38;5;28mself\u001b[39m._file = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1237\u001b[39m     _error_check(err)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import librosa\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import soundfile as sf\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 噪声生成与注入\n",
    "class NoiseInjector:\n",
    "    @staticmethod\n",
    "    def generate_white_noise(length):\n",
    "        return np.random.randn(length).astype(np.float32)\n",
    "\n",
    "    @staticmethod\n",
    "    def generate_babble_noise(length, num_speakers=3):\n",
    "        noise = np.zeros(length, dtype=np.float32)\n",
    "        for _ in range(num_speakers):\n",
    "            start = random.randint(0, max(0, length - Config.SAMPLE_RATE))\n",
    "            end = min(start + Config.SAMPLE_RATE, length)\n",
    "            noise[start:end] += np.random.randn(end - start).astype(np.float32)\n",
    "        return noise / num_speakers\n",
    "\n",
    "    @staticmethod\n",
    "    def add_noise(signal, noise_type=\"white\", snr_db=10):\n",
    "        if len(signal) == 0:\n",
    "            return signal\n",
    "        signal_power = np.mean(signal ** 2)\n",
    "        if signal_power < 1e-10:\n",
    "            return signal\n",
    "\n",
    "        signal_db = 10 * np.log10(signal_power)\n",
    "        noise = (NoiseInjector.generate_white_noise(len(signal)) if noise_type == \"white\"\n",
    "                 else NoiseInjector.generate_babble_noise(len(signal)))\n",
    "        noise_power = np.mean(noise ** 2)\n",
    "        noise_db = -100 if noise_power < 1e-10 else 10 * np.log10(noise_power)\n",
    "        target_noise_db = signal_db - snr_db\n",
    "        noise_scale = 10 ** ((target_noise_db - noise_db) / 20)\n",
    "        noisy_signal = signal + noise * noise_scale\n",
    "        max_val = np.max(np.abs(noisy_signal))\n",
    "        if max_val > 1e-5:\n",
    "            noisy_signal = noisy_signal / max_val\n",
    "        return noisy_signal\n",
    "\n",
    "\n",
    "# 数据集类\n",
    "class SpeakerRecognitionDataset(Dataset):\n",
    "    def __init__(self, split=\"train\", add_noise=False, noise_type=\"white\", snr_db=10):\n",
    "        self.split = split\n",
    "        self.add_noise = add_noise\n",
    "        self.noise_type = noise_type\n",
    "        self.snr_db = snr_db\n",
    "\n",
    "        self.audio_paths, self.labels = self._load_dataset()\n",
    "        self.speaker_to_idx = self._build_speaker_map()\n",
    "\n",
    "        # 调试模式：限制样本数\n",
    "        if Config.DEBUG_MODE:\n",
    "            if split == \"train\":\n",
    "                self.audio_paths = self.audio_paths[:Config.DEBUG_SAMPLE_SIZE]\n",
    "                self.labels = self.labels[:Config.DEBUG_SAMPLE_SIZE]\n",
    "            elif split == \"val\":\n",
    "                self.audio_paths = self.audio_paths[:min(Config.DEBUG_SAMPLE_SIZE // 2, len(self.audio_paths))]\n",
    "                self.labels = self.labels[:min(Config.DEBUG_SAMPLE_SIZE // 2, len(self.labels))]\n",
    "\n",
    "        self._validate_dataset()\n",
    "        print(f\"最终 {split} 数据集大小: {len(self.audio_paths)} 个样本\")\n",
    "\n",
    "    def _load_dataset(self):\n",
    "        audio_paths, labels = [], []\n",
    "        root = Config.LIBRISPEECH_PATH\n",
    "        \n",
    "        # 检查路径是否存在\n",
    "        if not os.path.exists(root):\n",
    "            print(f\"错误: LibriSpeech路径不存在 - {root}\")\n",
    "            print(\"请确保数据集已下载并放置在正确位置\")\n",
    "            return [], []\n",
    "\n",
    "        print(f\"加载LibriSpeech数据集: {root}\")\n",
    "        \n",
    "        # 只遍历 dev-clean 和 dev-other\n",
    "        for subset_dir in [\"dev-clean\", \"dev-other\"]:\n",
    "            subset_path = os.path.join(root, subset_dir)\n",
    "            if not os.path.isdir(subset_path):\n",
    "                print(f\"警告: 子集 {subset_dir} 不存在\")\n",
    "                continue\n",
    "                \n",
    "            print(f\"处理子集: {subset_dir}\")\n",
    "            for speaker_dir in os.listdir(subset_path):\n",
    "                speaker_path = os.path.join(subset_path, speaker_dir)\n",
    "                if not os.path.isdir(speaker_path):\n",
    "                    continue\n",
    "                    \n",
    "                for chapter_dir in os.listdir(speaker_path):\n",
    "                    chapter_path = os.path.join(speaker_path, chapter_dir)\n",
    "                    if not os.path.isdir(chapter_path):\n",
    "                        continue\n",
    "                        \n",
    "                    for file in os.listdir(chapter_path):\n",
    "                        if file.endswith(\".flac\"):\n",
    "                            full_path = os.path.join(chapter_path, file)\n",
    "                            audio_paths.append(full_path)\n",
    "                            labels.append(speaker_dir)\n",
    "\n",
    "        # 数据集分割\n",
    "        if self.split != \"test\" and len(audio_paths) > 0:\n",
    "            train_paths, val_paths, train_labels, val_labels = train_test_split(\n",
    "                audio_paths, labels, test_size=Config.VALID_RATIO, random_state=42\n",
    "            )\n",
    "            return (train_paths, train_labels) if self.split == \"train\" else (val_paths, val_labels)\n",
    "            \n",
    "        return audio_paths, labels\n",
    "\n",
    "    def _build_speaker_map(self):\n",
    "        unique_speakers = sorted(set(self.labels))\n",
    "        print(f\"找到 {len(unique_speakers)} 个不同的说话人\")\n",
    "        return {spk: idx for idx, spk in enumerate(unique_speakers)}\n",
    "\n",
    "    def _validate_dataset(self):\n",
    "        if len(self.audio_paths) == 0:\n",
    "            print(f\"警告: {self.split}数据集为空\")\n",
    "            return\n",
    "            \n",
    "        valid_count, invalid_indices = 0, []\n",
    "        for i in range(len(self.audio_paths) - 1, -1, -1):\n",
    "            path = self.audio_paths[i]\n",
    "            try:\n",
    "                if not os.path.exists(path):\n",
    "                    raise FileNotFoundError(\"文件不存在\")\n",
    "                    \n",
    "                if os.path.getsize(path) < 1024:\n",
    "                    raise ValueError(\"文件太小可能已损坏\")\n",
    "                    \n",
    "                # 读取音频文件\n",
    "                if path.endswith('.flac'):\n",
    "                    signal, sr = sf.read(path)\n",
    "                else:\n",
    "                    signal, sr = librosa.load(path, sr=Config.SAMPLE_RATE, mono=True)\n",
    "                    \n",
    "                # 检查音频长度\n",
    "                if len(signal) < Config.SAMPLE_RATE * 2:  # 至少需要2秒音频\n",
    "                    raise ValueError(f\"音频过短 ({len(signal)}采样点)，需要至少2秒音频\")\n",
    "                    \n",
    "                # 检查信号幅度\n",
    "                if np.max(np.abs(signal)) < 1e-5:\n",
    "                    raise ValueError(\"接近静音\")\n",
    "                    \n",
    "                valid_count += 1\n",
    "            except Exception as e:\n",
    "                invalid_indices.append(i)\n",
    "                print(f\"无效文件: {path} - {str(e)}\")\n",
    "                \n",
    "        # 移除无效文件\n",
    "        for i in invalid_indices:\n",
    "            self.audio_paths.pop(i)\n",
    "            self.labels.pop(i)\n",
    "            \n",
    "        print(f\"有效文件: {valid_count}/{len(self.audio_paths) + len(invalid_indices)}\")\n",
    "        self.speaker_to_idx = self._build_speaker_map()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.audio_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path, speaker_id = self.audio_paths[idx], self.labels[idx]\n",
    "        label = self.speaker_to_idx[speaker_id]\n",
    "        \n",
    "        try:\n",
    "            # 加载音频文件\n",
    "            if path.endswith('.flac'):\n",
    "                signal, sr = sf.read(path)\n",
    "                if sr != Config.SAMPLE_RATE:\n",
    "                    signal = librosa.resample(signal, orig_sr=sr, target_sr=Config.SAMPLE_RATE)\n",
    "            else:\n",
    "                signal, sr = librosa.load(path, sr=Config.SAMPLE_RATE, mono=True)\n",
    "        except Exception as e:\n",
    "            print(f\"加载音频错误 {path}: {str(e)}\")\n",
    "            signal = np.zeros(Config.MAX_SAMPLES, dtype=np.float32)\n",
    "\n",
    "        # 处理音频长度\n",
    "        if len(signal) > Config.MAX_SAMPLES:\n",
    "            # 随机裁剪3秒片段\n",
    "            start_idx = random.randint(0, len(signal) - Config.MAX_SAMPLES)\n",
    "            signal = signal[start_idx:start_idx + Config.MAX_SAMPLES]\n",
    "        elif len(signal) < Config.MAX_SAMPLES:\n",
    "            # 如果音频太短，重复填充\n",
    "            repeat_times = Config.MAX_SAMPLES // len(signal) + 1\n",
    "            signal = np.tile(signal, repeat_times)[:Config.MAX_SAMPLES]\n",
    "\n",
    "        # 归一化\n",
    "        max_val = np.max(np.abs(signal))\n",
    "        if max_val > 1e-5:\n",
    "            signal = signal / max_val\n",
    "\n",
    "        # 添加噪声\n",
    "        if self.add_noise and self.split == \"train\":\n",
    "            noise_type = random.choice(Config.NOISE_TYPES)\n",
    "            snr_db = random.choice(Config.SNR_LEVELS)\n",
    "            signal = NoiseInjector.add_noise(signal, noise_type, snr_db)\n",
    "\n",
    "        return torch.FloatTensor(signal), label\n",
    "\n",
    "\n",
    "# 数据加载器\n",
    "def get_dataloaders(batch_size=None):\n",
    "    if batch_size is None:\n",
    "        batch_size = Config.BATCH_SIZE\n",
    "        \n",
    "    print(f\"创建T4数据加载器: 批大小={batch_size}\")\n",
    "    \n",
    "    # 创建数据集\n",
    "    try:\n",
    "        train_dataset = SpeakerRecognitionDataset(split=\"train\")\n",
    "        val_dataset = SpeakerRecognitionDataset(split=\"val\")\n",
    "        test_dataset = SpeakerRecognitionDataset(split=\"test\")\n",
    "\n",
    "        # 如果训练集为空，尝试直接加载测试集\n",
    "        if len(train_dataset) == 0 and len(test_dataset) > 0:\n",
    "            print(\"警告: 训练集为空，使用测试集作为训练集\")\n",
    "            train_dataset = test_dataset\n",
    "\n",
    "        # 如果所有数据集都为空，抛出错误\n",
    "        if len(train_dataset) == 0 and len(val_dataset) == 0 and len(test_dataset) == 0:\n",
    "            raise RuntimeError(\"所有数据集均为空，请检查数据集路径和加载逻辑\")\n",
    "\n",
    "        # 创建带噪声的测试集\n",
    "        noisy_test_dataset = SpeakerRecognitionDataset(split=\"test\", add_noise=True)\n",
    "\n",
    "        # 打印数据集统计信息\n",
    "        print(f\"训练集: {len(train_dataset)} 样本\")\n",
    "        print(f\"验证集: {len(val_dataset)} 样本\")\n",
    "        print(f\"测试集: {len(test_dataset)} 样本\")\n",
    "        print(f\"带噪声测试集: {len(noisy_test_dataset)} 样本\")\n",
    "        print(f\"总说话人数: {len(train_dataset.speaker_to_idx)}\")\n",
    "\n",
    "        # 创建数据加载器\n",
    "        dataloaders = {\n",
    "            \"train\": DataLoader(train_dataset, batch_size=batch_size, shuffle=True,\n",
    "                                num_workers=Config.NUM_WORKERS, pin_memory=True),\n",
    "            \"val\": DataLoader(val_dataset, batch_size=batch_size, shuffle=False,\n",
    "                              num_workers=Config.NUM_WORKERS, pin_memory=True),\n",
    "            \"test\": DataLoader(test_dataset, batch_size=batch_size, shuffle=False,\n",
    "                               num_workers=Config.NUM_WORKERS, pin_memory=True),\n",
    "            \"noisy_test\": DataLoader(noisy_test_dataset, batch_size=batch_size, shuffle=False,\n",
    "                                     num_workers=Config.NUM_WORKERS, pin_memory=True),\n",
    "        }\n",
    "\n",
    "        return dataloaders\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"创建数据加载器时出错: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# 测试代码\n",
    "if __name__ == \"__main__\":\n",
    "    dataloaders = get_dataloaders()\n",
    "    if dataloaders and \"train\" in dataloaders:\n",
    "        x, y = next(iter(dataloaders[\"train\"]))\n",
    "        print(f\"音频数据形状: {x.shape}, 标签形状: {y.shape}\")\n",
    "        print(f\"音频长度: {x.shape[1]} 采样点 ({x.shape[1]/Config.SAMPLE_RATE:.2f} 秒)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70015cad-3249-46ff-a8b5-0bf06f2558cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class ChaoticStimulus(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        \"\"\"\n",
    "        简化的混沌激励模块\n",
    "        :param input_dim: 输入维度\n",
    "        :param output_dim: 输出维度\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.chaos_transform = nn.Sequential(\n",
    "            nn.Conv1d(input_dim, output_dim, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(output_dim),\n",
    "            nn.PReLU(),\n",
    "            nn.Conv1d(output_dim, output_dim, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(output_dim),\n",
    "            nn.PReLU()\n",
    "        )\n",
    "\n",
    "        # 混沌扰动参数\n",
    "        self.chaos_factor = nn.Parameter(torch.tensor(0.1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        前向传播\n",
    "        :param x: 输入特征 [batch_size, channels, seq_len]\n",
    "        :return: 混沌处理后的特征 [batch_size, channels, seq_len]\n",
    "        \"\"\"\n",
    "        # 常规特征变换\n",
    "        transformed = self.chaos_transform(x)\n",
    "\n",
    "        # 添加混沌扰动\n",
    "        batch_size, channels, seq_len = transformed.size()\n",
    "        if self.training:  # 仅在训练时添加混沌扰动\n",
    "            # 生成与特征相同形状的混沌噪声\n",
    "            chaos_noise = torch.randn_like(transformed) * self.chaos_factor\n",
    "            # 应用非线性激活增强混沌特性\n",
    "            chaos_noise = torch.tanh(chaos_noise)\n",
    "            transformed = transformed + chaos_noise\n",
    "\n",
    "        return transformed\n",
    "\n",
    "\n",
    "class SimpleAttention(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        \"\"\"\n",
    "        简化的注意力机制\n",
    "        :param input_dim: 输入维度\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Conv1d(input_dim, 1, kernel_size=1),\n",
    "            nn.Softmax(dim=2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        前向传播\n",
    "        :param x: 输入特征 [batch_size, channels, seq_len]\n",
    "        :return: 注意力加权后的特征 [batch_size, channels, seq_len]\n",
    "        \"\"\"\n",
    "        # 计算注意力权重 [batch_size, 1, seq_len]\n",
    "        attn_weights = self.attention(x)\n",
    "\n",
    "        # 应用注意力权重\n",
    "        return x * attn_weights\n",
    "\n",
    "\n",
    "class StatisticalPooling(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        前向传播\n",
    "        :param x: 输入特征 [batch_size, channels, seq_len]\n",
    "        :return: 池化后的特征 [batch_size, channels*2]\n",
    "        \"\"\"\n",
    "        # 计算均值和标准差\n",
    "        mean = torch.mean(x, dim=2)\n",
    "        std = torch.std(x, dim=2)\n",
    "\n",
    "        # 拼接均值和标准差\n",
    "        return torch.cat((mean, std), dim=1)\n",
    "\n",
    "\n",
    "# 复杂TDNN模块（来自完整模型）\n",
    "class ComplexTDNN(nn.Module):\n",
    "    def __init__(self, hidden_dim):\n",
    "        \"\"\"\n",
    "        复杂TDNN模块\n",
    "        :param hidden_dim: 隐藏层维度\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.tdnn1 = nn.Conv1d(hidden_dim, hidden_dim, kernel_size=3, dilation=1, padding=1)\n",
    "        self.bn_tdnn1 = nn.BatchNorm1d(hidden_dim)\n",
    "        self.prelu_tdnn1 = nn.PReLU()\n",
    "        \n",
    "        self.tdnn2 = nn.Conv1d(hidden_dim, hidden_dim, kernel_size=3, dilation=2, padding=2)\n",
    "        self.bn_tdnn2 = nn.BatchNorm1d(hidden_dim)\n",
    "        self.prelu_tdnn2 = nn.PReLU()\n",
    "        \n",
    "        self.tdnn3 = nn.Conv1d(hidden_dim, hidden_dim, kernel_size=3, dilation=3, padding=3)\n",
    "        self.bn_tdnn3 = nn.BatchNorm1d(hidden_dim)\n",
    "        self.prelu_tdnn3 = nn.PReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        前向传播\n",
    "        :param x: 输入特征 [batch_size, hidden_dim, seq_len]\n",
    "        :return: TDNN处理后的特征 [batch_size, hidden_dim, seq_len]\n",
    "        \"\"\"\n",
    "        x = self.prelu_tdnn1(self.bn_tdnn1(self.tdnn1(x)))\n",
    "        x = self.prelu_tdnn2(self.bn_tdnn2(self.tdnn2(x)))\n",
    "        x = self.prelu_tdnn3(self.bn_tdnn3(self.tdnn3(x)))\n",
    "        return x\n",
    "\n",
    "\n",
    "# T4模型：简化模型+复杂TDNN\n",
    "class CHiLAPModel_T4(nn.Module):\n",
    "    def __init__(self, input_dim=Config.INPUT_DIM, hidden_dim=Config.HIDDEN_DIM,\n",
    "                 embedding_dim=Config.EMBEDDING_DIM, num_classes=None):\n",
    "        \"\"\"\n",
    "        混沌层次吸引子传播(C-HiLAP)模型 - T4版本（简化模型+复杂TDNN）\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        # 若未传入num_classes，可设置一个默认值（但实际使用时必须从数据集获取后传入）\n",
    "        if num_classes is None:\n",
    "            raise ValueError(\"必须指定num_classes（说话人数量），请从数据集获取后传入\")\n",
    "\n",
    "        # 特征提取层\n",
    "        self.feature_extractor = nn.Sequential(\n",
    "            nn.Conv1d(input_dim, hidden_dim, kernel_size=5, stride=2, padding=2),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.PReLU(),\n",
    "            nn.Conv1d(hidden_dim, hidden_dim, kernel_size=5, stride=2, padding=2),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.PReLU(),\n",
    "            nn.Conv1d(hidden_dim, hidden_dim, kernel_size=5, stride=2, padding=2),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.PReLU()\n",
    "        )\n",
    "\n",
    "        # 混沌激励模块\n",
    "        self.chaos_layer = ChaoticStimulus(hidden_dim, hidden_dim)\n",
    "\n",
    "        # 注意力层\n",
    "        self.attention = SimpleAttention(hidden_dim)\n",
    "\n",
    "        # 复杂TDNN层（替换简化版的TDNN）\n",
    "        self.tdnn_block = ComplexTDNN(hidden_dim)\n",
    "\n",
    "        # 池化层\n",
    "        self.pooling = StatisticalPooling()\n",
    "\n",
    "        # 嵌入层\n",
    "        self.embedding = nn.Sequential(\n",
    "            nn.Linear(hidden_dim * 2, embedding_dim),  # 统计池化输出channels*2\n",
    "            nn.BatchNorm1d(embedding_dim),\n",
    "            nn.PReLU(),\n",
    "            nn.Dropout(0.2)\n",
    "        )\n",
    "\n",
    "        # 分类器\n",
    "        self.classifier = nn.Linear(embedding_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        前向传播\n",
    "        :param x: 输入特征 [batch_size, channels, seq_len] 或 [batch_size, seq_len, channels]\n",
    "        :return: 嵌入向量和分类结果\n",
    "        \"\"\"\n",
    "        # 检查输入维度并转换为正确的格式 [batch_size, channels, seq_len]\n",
    "        if x.dim() == 3:\n",
    "            # 如果是 [batch_size, seq_len, channels] 格式\n",
    "            if x.size(1) > x.size(2):  # 序列长度应该大于通道数\n",
    "                x = x.permute(0, 2, 1)  # 转换为 [batch_size, channels, seq_len]\n",
    "\n",
    "        # 限制序列长度防止内存溢出\n",
    "        seq_len = x.size(2)\n",
    "        if seq_len > Config.MAX_SEQ_LEN:\n",
    "            x = x[:, :, :Config.MAX_SEQ_LEN]\n",
    "\n",
    "        # 特征提取\n",
    "        x = self.feature_extractor(x)\n",
    "\n",
    "        # 混沌处理\n",
    "        x = self.chaos_layer(x)\n",
    "\n",
    "        # 注意力加权\n",
    "        x = self.attention(x)\n",
    "\n",
    "        # 复杂TDNN处理\n",
    "        x = self.tdnn_block(x)\n",
    "\n",
    "        # 池化\n",
    "        x = self.pooling(x)\n",
    "\n",
    "        # 嵌入向量\n",
    "        embedding = self.embedding(x)\n",
    "\n",
    "        # 分类\n",
    "        logits = self.classifier(embedding)\n",
    "\n",
    "        return embedding, logits\n",
    "\n",
    "\n",
    "# 测试代码\n",
    "if __name__ == \"__main__\":\n",
    "    # 创建模型实例\n",
    "    model = CHiLAPModel_T4(num_classes=10)  # 假设有10个说话人\n",
    "\n",
    "    print(\"T4模型结构:\")\n",
    "    print(model)\n",
    "\n",
    "    # 生成随机输入（使用较小的序列长度进行测试）\n",
    "    batch_size = 2\n",
    "    seq_len = Config.MAX_SEQ_LEN\n",
    "    # 正确的输入格式：[batch_size, channels, seq_len]\n",
    "    x = torch.randn(batch_size, 1, seq_len)\n",
    "\n",
    "    print(f\"\\n测试前向传播:\")\n",
    "    print(f\"输入形状: {x.shape}\")\n",
    "\n",
    "    # 前向传播\n",
    "    try:\n",
    "        embedding, logits = model(x)\n",
    "        print(f\"嵌入向量形状: {embedding.shape}\")\n",
    "        print(f\"分类输出形状: {logits.shape}\")\n",
    "        print(\"前向传播成功!\")\n",
    "    except Exception as e:\n",
    "        print(f\"前向传播错误: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771c9084-ca0d-4bb4-adca-d2d1b69ec106",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import os\n",
    "import gc  # 垃圾回收\n",
    "import math\n",
    "\n",
    "# 训练器类\n",
    "class Trainer:\n",
    "    def __init__(self, config=Config, model=None):\n",
    "        \"\"\"初始化训练器\"\"\"\n",
    "        self.config = config\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        print(f\"使用设备: {self.device}\")\n",
    "\n",
    "        # 创建模型\n",
    "        if model is None:\n",
    "            raise ValueError(\"初始化Trainer时必须传入model参数\")\n",
    "        self.model = model.to(self.device)  # 使用传入的模型\n",
    "\n",
    "        # 定义损失函数\n",
    "        self.ce_loss = nn.CrossEntropyLoss()\n",
    "\n",
    "        # 定义优化器\n",
    "        self.optimizer = optim.Adam(\n",
    "            self.model.parameters(),\n",
    "            lr=config.LR,\n",
    "            weight_decay=config.WEIGHT_DECAY\n",
    "        )\n",
    "\n",
    "        # 学习率调度器\n",
    "        self.scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            self.optimizer,\n",
    "            mode='min',\n",
    "            factor=0.5,\n",
    "            patience=3,\n",
    "        )\n",
    "\n",
    "        # 学习率预热调度器\n",
    "        self.warmup_scheduler = optim.lr_scheduler.LambdaLR(\n",
    "            self.optimizer,\n",
    "            lr_lambda=lambda epoch: min(1.0, epoch / config.WARMUP_EPOCHS)\n",
    "        )\n",
    "\n",
    "        # 混合精度训练\n",
    "        if config.ENABLE_MIXED_PRECISION and torch.cuda.is_available():\n",
    "            self.scaler = torch.cuda.amp.GradScaler()\n",
    "            print(\"启用混合精度训练\")\n",
    "        else:\n",
    "            self.scaler = None\n",
    "\n",
    "        # 创建检查点目录\n",
    "        os.makedirs(config.CHECKPOINT_DIR, exist_ok=True)\n",
    "\n",
    "        # 早停计数器\n",
    "        self.early_stop_counter = 0\n",
    "        self.best_val_accuracy = 0.0  # 改为基于准确率早停\n",
    "        print(f\"模型预期输入长度: {config.MAX_SEQ_LEN}\")\n",
    "\n",
    "    def train_one_epoch(self, dataloader, epoch):\n",
    "        \"\"\"\n",
    "        训练一个epoch\n",
    "        :param dataloader: 训练数据加载器\n",
    "        :param epoch: 当前epoch\n",
    "        :return: 平均训练损失和准确率\n",
    "        \"\"\"\n",
    "        self.model.train()\n",
    "        total_loss = 0.0\n",
    "        total_ce_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        # 梯度累积\n",
    "        accumulation_steps = self.config.GRADIENT_ACCUMULATION_STEPS\n",
    "        self.optimizer.zero_grad()\n",
    "\n",
    "        progress_bar = tqdm(enumerate(dataloader), total=len(dataloader))\n",
    "        for i, (inputs, labels) in progress_bar:\n",
    "            try:\n",
    "                inputs, labels = inputs.to(self.device), labels.to(self.device)\n",
    "\n",
    "                # 确保输入维度正确 [batch, 1, seq_len]\n",
    "                if inputs.dim() == 2:  # [batch, seq_len]\n",
    "                    inputs = inputs.unsqueeze(1)  # 添加通道维度 -> [batch, 1, seq_len]\n",
    "\n",
    "                # 确保音频长度正确\n",
    "                if inputs.size(2) > self.config.MAX_SEQ_LEN:\n",
    "                    inputs = inputs[:, :, :self.config.MAX_SEQ_LEN]\n",
    "                elif inputs.size(2) < self.config.MAX_SEQ_LEN:\n",
    "                    pad_len = self.config.MAX_SEQ_LEN - inputs.size(2)\n",
    "                    inputs = torch.nn.functional.pad(inputs, (0, pad_len), value=0.0)\n",
    "\n",
    "                # 使用混合精度训练\n",
    "                if self.scaler is not None:\n",
    "                    with torch.cuda.amp.autocast():\n",
    "                        # 前向传播\n",
    "                        embeddings, logits = self.model(inputs)\n",
    "\n",
    "                        # 计算损失\n",
    "                        ce = self.ce_loss(logits, labels)\n",
    "                        loss = self.config.CE_WEIGHT * ce\n",
    "\n",
    "                        # 梯度累积\n",
    "                        loss = loss / accumulation_steps\n",
    "\n",
    "                    # 反向传播\n",
    "                    self.scaler.scale(loss).backward()\n",
    "\n",
    "                    # 梯度裁剪\n",
    "                    self.scaler.unscale_(self.optimizer)\n",
    "                    torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.config.GRAD_CLIP)\n",
    "\n",
    "                    if (i + 1) % accumulation_steps == 0:\n",
    "                        self.scaler.step(self.optimizer)  # 优化器步骤\n",
    "                        self.scaler.update()\n",
    "                        # 2. 再调用预热调度器\n",
    "                        if epoch <= self.config.WARMUP_EPOCHS:\n",
    "                            self.warmup_scheduler.step()\n",
    "                        self.optimizer.zero_grad()\n",
    "\n",
    "                else:\n",
    "                    # 标准训练（不使用混合精度）\n",
    "                    embeddings, logits = self.model(inputs)\n",
    "\n",
    "                    # 计算损失\n",
    "                    ce = self.ce_loss(logits, labels)\n",
    "                    loss = self.config.CE_WEIGHT * ce\n",
    "\n",
    "                    # 梯度累积\n",
    "                    loss = loss / accumulation_steps\n",
    "                    loss.backward()\n",
    "\n",
    "                    # 梯度裁剪\n",
    "                    torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.config.GRAD_CLIP)\n",
    "\n",
    "                    if (i + 1) % accumulation_steps == 0:\n",
    "                        # 1. 先更新参数\n",
    "                        self.optimizer.step()\n",
    "                        # 2. 再调用学习率预热调度器（仅在预热阶段）\n",
    "                        if epoch <= self.config.WARMUP_EPOCHS:\n",
    "                            self.warmup_scheduler.step()  # 移动到optimizer.step()之后\n",
    "                        self.optimizer.zero_grad()\n",
    "\n",
    "                # 统计\n",
    "                total_loss += loss.item() * accumulation_steps\n",
    "                total_ce_loss += ce.item()\n",
    "                _, predicted = logits.max(1)\n",
    "                total += labels.size(0)\n",
    "                correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "                # 更新进度条\n",
    "                if i % 10 == 0:  # 减少更新频率\n",
    "                    accuracy = 100. * correct / total\n",
    "                    avg_loss = total_loss / (i + 1)\n",
    "                    progress_bar.set_description(\n",
    "                        f\"Epoch {epoch}, Loss: {avg_loss:.4f}, Acc: {accuracy:.2f}%\"\n",
    "                    )\n",
    "\n",
    "                # 手动垃圾回收\n",
    "                if i % 50 == 0:\n",
    "                    torch.cuda.empty_cache()\n",
    "                    gc.collect()\n",
    "\n",
    "            except RuntimeError as e:\n",
    "                if \"out of memory\" in str(e):\n",
    "                    print(f\"内存不足错误在批次 {i}: {e}\")\n",
    "                    torch.cuda.empty_cache()\n",
    "                    gc.collect()\n",
    "                    continue\n",
    "                else:\n",
    "                    raise e\n",
    "\n",
    "        avg_loss = total_loss / len(dataloader)\n",
    "        accuracy = 100. * correct / total\n",
    "        return avg_loss, accuracy\n",
    "\n",
    "    def validate(self, dataloader):\n",
    "        \"\"\"\n",
    "        验证模型性能\n",
    "        :param dataloader: 验证数据加载器\n",
    "        :return: 验证损失和准确率\n",
    "        \"\"\"\n",
    "        self.model.eval()\n",
    "        total_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for i, (inputs, labels) in enumerate(dataloader):\n",
    "                try:\n",
    "                    inputs, labels = inputs.to(self.device), labels.to(self.device)\n",
    "\n",
    "                    # 确保输入维度正确 [batch, 1, seq_len]\n",
    "                    if inputs.dim() == 2:  # [batch, seq_len]\n",
    "                        inputs = inputs.unsqueeze(1)  # 添加通道维度 -> [batch, 1, seq_len]\n",
    "\n",
    "                    # 确保音频长度正确\n",
    "                    if inputs.size(2) > self.config.MAX_SEQ_LEN:\n",
    "                        inputs = inputs[:, :, :self.config.MAX_SEQ_LEN]\n",
    "                    elif inputs.size(2) < self.config.MAX_SEQ_LEN:\n",
    "                        pad_len = self.config.MAX_SEQ_LEN - inputs.size(2)\n",
    "                        inputs = torch.nn.functional.pad(inputs, (0, pad_len), value=0.0)\n",
    "\n",
    "                    # 前向传播\n",
    "                    embeddings, logits = self.model(inputs)\n",
    "\n",
    "                    # 计算损失\n",
    "                    ce = self.ce_loss(logits, labels)\n",
    "                    loss = self.config.CE_WEIGHT * ce\n",
    "\n",
    "                    total_loss += loss.item()\n",
    "\n",
    "                    # 统计准确率\n",
    "                    _, predicted = logits.max(1)\n",
    "                    total += labels.size(0)\n",
    "                    correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "                    # 内存管理\n",
    "                    if i % 20 == 0:\n",
    "                        torch.cuda.empty_cache()\n",
    "                        gc.collect()\n",
    "\n",
    "                except RuntimeError as e:\n",
    "                    if \"out of memory\" in str(e):\n",
    "                        print(f\"验证时内存不足: {e}\")\n",
    "                        torch.cuda.empty_cache()\n",
    "                        gc.collect()\n",
    "                        continue\n",
    "                    else:\n",
    "                        raise e\n",
    "\n",
    "        avg_loss = total_loss / len(dataloader)\n",
    "        accuracy = 100. * correct / total\n",
    "        return avg_loss, accuracy\n",
    "\n",
    "    def train(self, train_dataloader, val_dataloader):\n",
    "        \"\"\"\n",
    "        完整训练流程\n",
    "        :param train_dataloader: 训练数据加载器\n",
    "        :param val_dataloader: 验证数据加载器\n",
    "        \"\"\"\n",
    "        print(\"开始训练...\")\n",
    "        print(f\"训练集批次: {len(train_dataloader)}, 验证集批次: {len(val_dataloader)}\")\n",
    "\n",
    "        for epoch in range(1, self.config.EPOCHS + 1):\n",
    "            try:\n",
    "                # 应用学习率预热\n",
    "                if epoch <= self.config.WARMUP_EPOCHS:\n",
    "                    self.warmup_scheduler.step()\n",
    "\n",
    "                # 训练一个epoch\n",
    "                train_loss, train_acc = self.train_one_epoch(train_dataloader, epoch)\n",
    "                print(f\"Epoch {epoch}/{self.config.EPOCHS}, Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%\")\n",
    "\n",
    "                # 验证\n",
    "                val_loss, val_acc = self.validate(val_dataloader)\n",
    "                print(f\"Epoch {epoch}, Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%\")\n",
    "\n",
    "                # 更新学习率\n",
    "                self.scheduler.step(val_loss)\n",
    "                current_lr = self.optimizer.param_groups[0]['lr']\n",
    "                print(f\"当前学习率: {current_lr:.6f}\")\n",
    "\n",
    "                # 早停检查 (基于验证准确率)\n",
    "                if val_acc > self.best_val_accuracy + self.config.MIN_DELTA:\n",
    "                    self.best_val_accuracy = val_acc\n",
    "                    self.early_stop_counter = 0\n",
    "                    # 保存最佳模型\n",
    "                    torch.save({\n",
    "                        'epoch': epoch,\n",
    "                        'model_state_dict': self.model.state_dict(),\n",
    "                        'optimizer_state_dict': self.optimizer.state_dict(),\n",
    "                        'val_loss': val_loss,\n",
    "                        'val_accuracy': val_acc\n",
    "                    }, os.path.join(self.config.CHECKPOINT_DIR, 'best_model.pth'))\n",
    "                    print(f\"保存最佳模型，验证准确率: {val_acc:.2f}%\")\n",
    "                else:\n",
    "                    self.early_stop_counter += 1\n",
    "                    if self.early_stop_counter >= self.config.PATIENCE:\n",
    "                        print(f\"早停于第 {epoch} 轮\")\n",
    "                        break\n",
    "\n",
    "                # 定期保存模型\n",
    "                if epoch % self.config.SAVE_INTERVAL == 0:\n",
    "                    torch.save({\n",
    "                        'epoch': epoch,\n",
    "                        'model_state_dict': self.model.state_dict(),\n",
    "                        'optimizer_state_dict': self.optimizer.state_dict(),\n",
    "                        'train_loss': train_loss,\n",
    "                        'train_accuracy': train_acc\n",
    "                    }, os.path.join(self.config.CHECKPOINT_DIR, f'model_epoch_{epoch}.pth'))\n",
    "\n",
    "                # 清理内存\n",
    "                torch.cuda.empty_cache()\n",
    "                gc.collect()\n",
    "\n",
    "            except KeyboardInterrupt:\n",
    "                print(\"训练被用户中断\")\n",
    "                break\n",
    "            except Exception as e:\n",
    "                print(f\"训练错误: {e}\")\n",
    "                torch.cuda.empty_cache()\n",
    "                gc.collect()\n",
    "                continue\n",
    "\n",
    "    def load_checkpoint(self, checkpoint_path):\n",
    "        \"\"\"\n",
    "        加载检查点\n",
    "        :param checkpoint_path: 检查点路径\n",
    "        \"\"\"\n",
    "        checkpoint = torch.load(checkpoint_path, map_location=self.device)\n",
    "        self.model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        if 'optimizer_state_dict' in checkpoint:\n",
    "            self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        epoch = checkpoint.get('epoch', 0)\n",
    "        print(f\"从第 {epoch} 轮加载检查点\")\n",
    "        return epoch\n",
    "\n",
    "# 评估器类\n",
    "class Evaluator:\n",
    "    def __init__(self, model, config=Config):\n",
    "        \"\"\"初始化评估器\"\"\"\n",
    "        self.model = model\n",
    "        self.config = config\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.model.to(self.device)\n",
    "        self.model.eval()\n",
    "\n",
    "    def evaluate_accuracy(self, dataloader):\n",
    "        \"\"\"\n",
    "        评估模型准确率\n",
    "        :param dataloader: 数据加载器\n",
    "        :return: 准确率\n",
    "        \"\"\"\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for i, (inputs, labels) in enumerate(dataloader):\n",
    "                try:\n",
    "                    inputs, labels = inputs.to(self.device), labels.to(self.device)\n",
    "\n",
    "                    # 确保输入维度正确\n",
    "                    if inputs.dim() == 2:  # [batch, seq_len]\n",
    "                        inputs = inputs.unsqueeze(1)  # 添加通道维度 -> [batch, 1, seq_len]\n",
    "\n",
    "                    # 截断过长的序列\n",
    "                    if inputs.size(2) > self.config.MAX_SEQ_LEN:\n",
    "                        inputs = inputs[:, :, :self.config.MAX_SEQ_LEN]\n",
    "\n",
    "                    _, logits = self.model(inputs)\n",
    "                    _, predicted = logits.max(1)\n",
    "                    total += labels.size(0)\n",
    "                    correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "                    # 内存管理\n",
    "                    if i % 20 == 0:\n",
    "                        torch.cuda.empty_cache()\n",
    "                        gc.collect()\n",
    "\n",
    "                except RuntimeError as e:\n",
    "                    if \"out of memory\" in str(e):\n",
    "                        print(f\"评估时内存不足: {e}\")\n",
    "                        torch.cuda.empty_cache()\n",
    "                        gc.collect()\n",
    "                        continue\n",
    "                    else:\n",
    "                        raise e\n",
    "\n",
    "        accuracy = 100. * correct / total\n",
    "        return accuracy\n",
    "\n",
    "# 测试代码\n",
    "if __name__ == \"__main__\":\n",
    "    # 设置较小的批次大小\n",
    "    batch_size = Config.BATCH_SIZE\n",
    "\n",
    "    print(\"创建数据加载器...\")\n",
    "    try:\n",
    "        dataloaders = get_dataloaders(batch_size=batch_size)\n",
    "\n",
    "        if dataloaders is None:\n",
    "            print(\"无法创建数据加载器，退出\")\n",
    "            exit(1)\n",
    "\n",
    "        print(f\"训练集批次数: {len(dataloaders['train'])}\")\n",
    "        print(f\"验证集批次数: {len(dataloaders['val'])}\")\n",
    "        print(f\"测试集批次数: {len(dataloaders['test'])}\")\n",
    "\n",
    "        # 关键修改：从训练集中获取实际说话人数量（类别数）\n",
    "        num_speakers = len(dataloaders[\"train\"].dataset.speaker_to_idx)\n",
    "        print(f\"数据集中实际说话人数量（类别数）: {num_speakers}\")\n",
    "\n",
    "        # 创建训练器前，先初始化模型并传入正确的num_classes\n",
    "        print(\"创建模型和训练器...\")\n",
    "        # 关键修改：确保在创建Trainer时使用正确的num_classes初始化模型\n",
    "        # 1. 初始化模型（传入正确的num_classes）\n",
    "        model = CHiLAPModel(num_classes=num_speakers)\n",
    "        # 2. 将模型传入Trainer，确保优化器初始化时模型已存在\n",
    "        trainer = Trainer(config=Config, model=model)  # 传入model参数\n",
    "\n",
    "        # 测试一个批次\n",
    "        print(\"测试前向传播...\")\n",
    "        try:\n",
    "            x, y = next(iter(dataloaders[\"train\"]))\n",
    "            print(f\"原始输入形状: {x.shape}, 标签形状: {y.shape}\")\n",
    "\n",
    "            # 处理输入维度\n",
    "            if x.dim() == 2:  # [batch, seq_len]\n",
    "                x = x.unsqueeze(1)  # 添加通道维度 -> [batch, 1, seq_len]\n",
    "\n",
    "            # 确保音频长度正确\n",
    "            if x.size(2) > Config.MAX_SEQ_LEN:\n",
    "                x = x[:, :, :Config.MAX_SEQ_LEN]\n",
    "            elif x.size(2) < Config.MAX_SEQ_LEN:\n",
    "                pad_len = Config.MAX_SEQ_LEN - x.size(2)\n",
    "                x = torch.nn.functional.pad(x, (0, pad_len), value=0.0)\n",
    "\n",
    "            print(f\"处理后输入形状: {x.shape}\")\n",
    "\n",
    "            x = x.to(trainer.device)\n",
    "            y = y.to(trainer.device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                embeddings, logits = trainer.model(x)\n",
    "                print(f\"嵌入形状: {embeddings.shape}, 输出形状: {logits.shape}\")\n",
    "                print(\"前向传播测试成功!\")\n",
    "        except Exception as e:\n",
    "            print(f\"前向传播测试失败: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            exit(1)\n",
    "\n",
    "        # 开始训练\n",
    "        print(\"开始训练...\")\n",
    "        trainer.train(dataloaders[\"train\"], dataloaders[\"val\"])\n",
    "\n",
    "        # 创建评估器\n",
    "        print(\"创建评估器...\")\n",
    "        evaluator = Evaluator(trainer.model)\n",
    "\n",
    "        # 评估模型\n",
    "        print(\"评估模型...\")\n",
    "        test_accuracy = evaluator.evaluate_accuracy(dataloaders[\"test\"])\n",
    "        print(f\"测试集准确率: {test_accuracy:.2f}%\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"程序执行错误: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
