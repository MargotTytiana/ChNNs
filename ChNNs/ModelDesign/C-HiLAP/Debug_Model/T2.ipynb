{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3c7a2e3-bdbf-4488-8e1b-ddff1bf32d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "class Config:\n",
    "    # 数据加载器配置\n",
    "    DEBUG_MODE = True\n",
    "    DEBUG_SAMPLE_SIZE = 5000\n",
    "    BASE_DIR = os.getcwd()\n",
    "    LIBRISPEECH_PATH = os.path.join(BASE_DIR, \"devDataset\", \"LibriSpeech\")\n",
    "    SAMPLE_RATE = 16000\n",
    "    DURATION = 1.0\n",
    "    MAX_SAMPLES = int(SAMPLE_RATE * DURATION)\n",
    "    NOISE_TYPES = [\"white\", \"babble\"]\n",
    "    SNR_LEVELS = [0, 5, 10]\n",
    "    NUM_WORKERS = 2\n",
    "    VALID_RATIO = 0.1\n",
    "    MAX_SEQ_LEN = 16000\n",
    "    \n",
    "    # 模型配置\n",
    "    INPUT_DIM = 1\n",
    "    HIDDEN_DIM = 256\n",
    "    EMBEDDING_DIM = 128\n",
    "    CHAOS_DIM = 64\n",
    "    CHAOS_TIME_STEPS = 5\n",
    "    ATTENTION_HEADS = 4\n",
    "    \n",
    "    # 训练配置\n",
    "    EPOCHS = 500\n",
    "    LR = 0.0008\n",
    "    LR_DECAY = 0.95\n",
    "    WEIGHT_DECAY = 1e-5\n",
    "    SAVE_INTERVAL = 10\n",
    "    VAL_INTERVAL = 1\n",
    "    CHECKPOINT_DIR = \"./checkpoints_T2\"\n",
    "\n",
    "    # 优化参数\n",
    "    WARMUP_EPOCHS = 5\n",
    "    GRAD_CLIP = 1.0\n",
    "\n",
    "    # 损失函数权重\n",
    "    CE_WEIGHT = 1.0\n",
    "    ATTENTION_REG_WEIGHT = 0.01  # 注意力正则化权重（新增）\n",
    "\n",
    "    # 早停参数\n",
    "    PATIENCE = 15\n",
    "    MIN_DELTA = 0.001\n",
    "\n",
    "    # 内存优化参数\n",
    "    GRADIENT_ACCUMULATION_STEPS = 4\n",
    "    BATCH_SIZE = 8     # 减小批次大小，复杂注意力需要更多内存\n",
    "    ENABLE_MIXED_PRECISION = False\n",
    "\n",
    "    # 注意力机制特定参数\n",
    "    ATTENTION_MAX_SEQ_LEN = 250  # 注意力机制处理的最大序列长度\n",
    "    ATTENTION_HEAD_DIM = 64       # 注意力头维度\n",
    "    ATTENTION_HEADS = 8           # 注意力头数量\n",
    "    \n",
    "    # 序列处理参数\n",
    "    PADDING_MODE = 'constant'     # 填充模式\n",
    "    PADDING_VALUE = 0.0           # 填充值\n",
    "    \n",
    "    BIFURCATION_THRESHOLD = 0.5  # 分岔阈值\n",
    "    ATTENTION_DROPOUT = 0.1  # 注意力dropout率\n",
    "\n",
    "    # 注意力监控参数\n",
    "    ATTENTION_VIZ_INTERVAL = 5  # 注意力可视化间隔（epoch）\n",
    "    ATTENTION_VIZ_DIR = \"./attention_viz\"  # 注意力可视化保存目录"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22157ffc-9e6a-4767-b76c-052b2d8d8604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "测试数据加载器...\n",
      "加载LibriSpeech数据集: /users/tianyuey/Project/devDataset/LibriSpeech\n",
      "处理子集: dev-clean\n",
      "在 dev-clean 中找到 2703 个.flac文件\n",
      "处理子集: dev-other\n",
      "在 dev-other 中找到 5567 个.flac文件\n",
      "找到 73 个不同的说话人\n",
      "有效文件: 5000/5000\n",
      "移除 0 个无效文件\n",
      "找到 73 个不同的说话人\n",
      "最终 train 数据集大小: 5000 个样本\n",
      "加载LibriSpeech数据集: /users/tianyuey/Project/devDataset/LibriSpeech\n",
      "处理子集: dev-clean\n",
      "在 dev-clean 中找到 2703 个.flac文件\n",
      "处理子集: dev-other\n",
      "在 dev-other 中找到 5567 个.flac文件\n",
      "找到 73 个不同的说话人\n",
      "有效文件: 557/557\n",
      "移除 0 个无效文件\n",
      "找到 73 个不同的说话人\n",
      "最终 val 数据集大小: 557 个样本\n",
      "加载LibriSpeech数据集: /users/tianyuey/Project/devDataset/LibriSpeech\n",
      "处理子集: dev-clean\n",
      "在 dev-clean 中找到 2703 个.flac文件\n",
      "处理子集: dev-other\n",
      "在 dev-other 中找到 5567 个.flac文件\n",
      "找到 73 个不同的说话人\n",
      "有效文件: 5567/5567\n",
      "移除 0 个无效文件\n",
      "找到 73 个不同的说话人\n",
      "最终 test 数据集大小: 5567 个样本\n",
      "加载LibriSpeech数据集: /users/tianyuey/Project/devDataset/LibriSpeech\n",
      "处理子集: dev-clean\n",
      "在 dev-clean 中找到 2703 个.flac文件\n",
      "处理子集: dev-other\n",
      "在 dev-other 中找到 5567 个.flac文件\n",
      "找到 73 个不同的说话人\n",
      "有效文件: 5567/5567\n",
      "移除 0 个无效文件\n",
      "找到 73 个不同的说话人\n",
      "最终 test 数据集大小: 5567 个样本\n",
      "训练集: 5000 样本\n",
      "验证集: 557 样本\n",
      "测试集: 5567 样本\n",
      "带噪声测试集: 5567 样本\n",
      "总说话人数: 73\n",
      "音频数据形状: torch.Size([8, 16000])\n",
      "标签数据形状: torch.Size([8])\n",
      "注意力掩码形状: torch.Size([8, 16000])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import librosa\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import librosa\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import soundfile as sf\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# 噪声生成与注入\n",
    "class NoiseInjector:\n",
    "    @staticmethod\n",
    "    def generate_white_noise(length):\n",
    "        return np.random.randn(length).astype(np.float32)\n",
    "\n",
    "    @staticmethod\n",
    "    def generate_babble_noise(length, num_speakers=3):\n",
    "        noise = np.zeros(length, dtype=np.float32)\n",
    "        for _ in range(num_speakers):\n",
    "            start = random.randint(0, max(0, length - Config.SAMPLE_RATE))\n",
    "            end = min(start + Config.SAMPLE_RATE, length)\n",
    "            noise[start:end] += np.random.randn(end - start).astype(np.float32)\n",
    "        return noise / num_speakers\n",
    "\n",
    "    @staticmethod\n",
    "    def add_noise(signal, noise_type=\"white\", snr_db=10):\n",
    "        if len(signal) == 0:\n",
    "            return signal\n",
    "\n",
    "        signal_power = np.mean(signal ** 2)\n",
    "        if signal_power < 1e-10:\n",
    "            return signal\n",
    "\n",
    "        signal_db = 10 * np.log10(signal_power)\n",
    "\n",
    "        if noise_type == \"white\":\n",
    "            noise = NoiseInjector.generate_white_noise(len(signal))\n",
    "        elif noise_type == \"babble\":\n",
    "            noise = NoiseInjector.generate_babble_noise(len(signal))\n",
    "        else:\n",
    "            raise ValueError(f\"不支持的噪声类型：{noise_type}\")\n",
    "\n",
    "        noise_power = np.mean(noise ** 2)\n",
    "        noise_db = -100 if noise_power < 1e-10 else 10 * np.log10(noise_power)\n",
    "\n",
    "        target_noise_db = signal_db - snr_db\n",
    "        noise_scale = 10 ** ((target_noise_db - noise_db) / 20)\n",
    "        noisy_signal = signal + noise * noise_scale\n",
    "\n",
    "        # 归一化\n",
    "        max_val = np.max(np.abs(noisy_signal))\n",
    "        if max_val > 1e-5:\n",
    "            noisy_signal = noisy_signal / max_val\n",
    "\n",
    "        return noisy_signal\n",
    "\n",
    "# 数据集类\n",
    "class SpeakerRecognitionDataset(Dataset):\n",
    "    def __init__(self, split=\"train\", add_noise=False, noise_type=\"white\", snr_db=10):\n",
    "        self.split = split\n",
    "        self.add_noise = add_noise\n",
    "        self.noise_type = noise_type\n",
    "        self.snr_db = snr_db\n",
    "\n",
    "        # 加载数据集\n",
    "        self.audio_paths, self.labels = self._load_dataset()\n",
    "        self.speaker_to_idx = self._build_speaker_map()\n",
    "\n",
    "        # 调试模式\n",
    "        if Config.DEBUG_MODE:\n",
    "            if split == \"train\":\n",
    "                self.audio_paths = self.audio_paths[:Config.DEBUG_SAMPLE_SIZE]\n",
    "                self.labels = self.labels[:Config.DEBUG_SAMPLE_SIZE]\n",
    "            elif split == \"val\":\n",
    "                self.audio_paths = self.audio_paths[:min(Config.DEBUG_SAMPLE_SIZE // 2, len(self.audio_paths))]\n",
    "                self.labels = self.labels[:min(Config.DEBUG_SAMPLE_SIZE // 2, len(self.labels))]\n",
    "\n",
    "        # 验证数据集\n",
    "        self._validate_dataset()\n",
    "        print(f\"最终 {split} 数据集大小: {len(self.audio_paths)} 个样本\")\n",
    "\n",
    "    def _load_dataset(self):\n",
    "        audio_paths = []\n",
    "        labels = []\n",
    "\n",
    "        root = Config.LIBRISPEECH_PATH\n",
    "        if not os.path.exists(root):\n",
    "            print(f\"错误: LibriSpeech路径不存在 - {root}\")\n",
    "            return [], []\n",
    "\n",
    "        print(f\"加载LibriSpeech数据集: {root}\")\n",
    "\n",
    "        # 只遍历 dev-clean 和 dev-other\n",
    "        for subset_dir in [\"dev-clean\", \"dev-other\"]:\n",
    "            subset_path = os.path.join(root, subset_dir)\n",
    "            if not os.path.isdir(subset_path):\n",
    "                continue\n",
    "\n",
    "            print(f\"处理子集: {subset_dir}\")\n",
    "            for speaker_dir in os.listdir(subset_path):\n",
    "                speaker_path = os.path.join(subset_path, speaker_dir)\n",
    "                if not os.path.isdir(speaker_path):\n",
    "                    continue\n",
    "\n",
    "                for chapter_dir in os.listdir(speaker_path):\n",
    "                    chapter_path = os.path.join(speaker_path, chapter_dir)\n",
    "                    if not os.path.isdir(chapter_path):\n",
    "                        continue\n",
    "\n",
    "                    for file in os.listdir(chapter_path):\n",
    "                        if file.endswith(\".flac\"):\n",
    "                            full_path = os.path.join(chapter_path, file)\n",
    "                            audio_paths.append(full_path)\n",
    "                            labels.append(speaker_dir)\n",
    "\n",
    "            print(f\"在 {subset_dir} 中找到 {len(audio_paths)} 个.flac文件\")\n",
    "\n",
    "        # 分割训练/验证\n",
    "        if self.split != \"test\" and len(audio_paths) > 0:\n",
    "            train_paths, val_paths, train_labels, val_labels = train_test_split(\n",
    "                audio_paths, labels, test_size=Config.VALID_RATIO, random_state=42\n",
    "            )\n",
    "            if self.split == \"train\":\n",
    "                return train_paths, train_labels\n",
    "            else:\n",
    "                return val_paths, val_labels\n",
    "\n",
    "        return audio_paths, labels\n",
    "\n",
    "    def _build_speaker_map(self):\n",
    "        unique_speakers = sorted(set(self.labels))\n",
    "        print(f\"找到 {len(unique_speakers)} 个不同的说话人\")\n",
    "        return {speaker: idx for idx, speaker in enumerate(unique_speakers)}\n",
    "\n",
    "    def _validate_dataset(self):\n",
    "        if len(self.audio_paths) == 0:\n",
    "            print(f\"警告: {self.split}数据集为空\")\n",
    "            return\n",
    "\n",
    "        valid_count = 0\n",
    "        invalid_indices = []\n",
    "        for i in range(len(self.audio_paths) - 1, -1, -1):\n",
    "            path = self.audio_paths[i]\n",
    "            try:\n",
    "                if not os.path.exists(path):\n",
    "                    raise FileNotFoundError(\"文件不存在\")\n",
    "\n",
    "                if os.path.getsize(path) < 1024:\n",
    "                    raise ValueError(\"文件太小可能已损坏\")\n",
    "\n",
    "                if path.endswith('.flac'):\n",
    "                    signal, sr = sf.read(path)\n",
    "                else:\n",
    "                    signal, sr = librosa.load(path, sr=Config.SAMPLE_RATE, mono=True)\n",
    "\n",
    "                if len(signal) < Config.SAMPLE_RATE // 2:\n",
    "                    raise ValueError(\"音频过短\")\n",
    "\n",
    "                if np.max(np.abs(signal)) < 1e-5:\n",
    "                    raise ValueError(\"接近静音\")\n",
    "\n",
    "                valid_count += 1\n",
    "            except Exception as e:\n",
    "                invalid_indices.append(i)\n",
    "                print(f\"无效文件: {path} - {str(e)}\")\n",
    "\n",
    "        for i in invalid_indices:\n",
    "            self.audio_paths.pop(i)\n",
    "            self.labels.pop(i)\n",
    "\n",
    "        print(f\"有效文件: {valid_count}/{len(self.audio_paths) + len(invalid_indices)}\")\n",
    "        print(f\"移除 {len(invalid_indices)} 个无效文件\")\n",
    "        self.speaker_to_idx = self._build_speaker_map()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.audio_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path = self.audio_paths[idx]\n",
    "        speaker_id = self.labels[idx]\n",
    "        label = self.speaker_to_idx[speaker_id]\n",
    "\n",
    "        try:\n",
    "            if path.endswith('.flac'):\n",
    "                signal, sr = sf.read(path)\n",
    "                if sr != Config.SAMPLE_RATE:\n",
    "                    signal = librosa.resample(signal, orig_sr=sr, target_sr=Config.SAMPLE_RATE)\n",
    "            else:\n",
    "                signal, sr = librosa.load(path, sr=Config.SAMPLE_RATE, mono=True)\n",
    "        except Exception as e:\n",
    "            print(f\"加载音频错误 {path}: {str(e)}\")\n",
    "            signal = np.zeros(Config.MAX_SAMPLES, dtype=np.float32)\n",
    "\n",
    "        # 确保音频长度正确\n",
    "        if len(signal) > Config.MAX_SAMPLES:\n",
    "            # 随机裁剪而不是固定裁剪开头\n",
    "            start = random.randint(0, len(signal) - Config.MAX_SAMPLES)\n",
    "            signal = signal[start:start + Config.MAX_SAMPLES]\n",
    "        elif len(signal) < Config.MAX_SAMPLES:\n",
    "            pad_len = Config.MAX_SAMPLES - len(signal)\n",
    "            signal = np.pad(signal, (0, pad_len), \n",
    "                           mode=Config.PADDING_MODE, \n",
    "                           constant_values=Config.PADDING_VALUE)\n",
    "        \n",
    "        # 为注意力机制创建长度掩码\n",
    "        seq_length = min(len(signal), Config.MAX_SAMPLES)\n",
    "        attention_mask = np.ones(Config.MAX_SAMPLES, dtype=np.float32)\n",
    "        if seq_length < Config.MAX_SAMPLES:\n",
    "            attention_mask[seq_length:] = 0.0\n",
    "        \n",
    "        # 归一化\n",
    "        max_val = np.max(np.abs(signal))\n",
    "        if max_val > 1e-5:\n",
    "            signal = signal / max_val\n",
    "        \n",
    "        # 添加噪声\n",
    "        if self.add_noise and self.split == \"train\":\n",
    "            noise_type = random.choice(Config.NOISE_TYPES)\n",
    "            snr_db = random.choice(Config.SNR_LEVELS)\n",
    "            signal = NoiseInjector.add_noise(signal, noise_type, snr_db)\n",
    "        \n",
    "        # 返回信号、标签和注意力掩码\n",
    "        return torch.FloatTensor(signal), label, torch.FloatTensor(attention_mask)\n",
    "\n",
    "# 数据加载器\n",
    "def get_dataloaders(batch_size=None):\n",
    "    if batch_size is None:\n",
    "        batch_size = Config.BATCH_SIZE\n",
    "\n",
    "    train_dataset = SpeakerRecognitionDataset(split=\"train\")\n",
    "    val_dataset = SpeakerRecognitionDataset(split=\"val\")\n",
    "    test_dataset = SpeakerRecognitionDataset(split=\"test\")\n",
    "\n",
    "    if len(train_dataset) == 0 and len(test_dataset) > 0:\n",
    "        print(\"警告: 训练集为空，使用测试集作为训练集\")\n",
    "        train_dataset = test_dataset\n",
    "\n",
    "    noisy_test_dataset = SpeakerRecognitionDataset(\n",
    "        split=\"test\", add_noise=True, noise_type=\"white\", snr_db=5\n",
    "    )\n",
    "\n",
    "    print(f\"训练集: {len(train_dataset)} 样本\")\n",
    "    print(f\"验证集: {len(val_dataset)} 样本\")\n",
    "    print(f\"测试集: {len(test_dataset)} 样本\")\n",
    "    print(f\"带噪声测试集: {len(noisy_test_dataset)} 样本\")\n",
    "    print(f\"总说话人数: {len(train_dataset.speaker_to_idx)}\")\n",
    "\n",
    "    # 创建自定义collate函数处理注意力掩码\n",
    "    def collate_fn(batch):\n",
    "        signals, labels, attention_masks = zip(*batch)\n",
    "        signals = torch.stack(signals)\n",
    "        labels = torch.tensor(labels)\n",
    "        attention_masks = torch.stack(attention_masks)\n",
    "        return signals, labels, attention_masks\n",
    "    \n",
    "    # 创建数据加载器时使用自定义collate函数\n",
    "    dataloaders = {\n",
    "        \"train\": DataLoader(train_dataset, batch_size=batch_size, shuffle=True,\n",
    "                           num_workers=Config.NUM_WORKERS, pin_memory=True,\n",
    "                           collate_fn=collate_fn),\n",
    "        \"val\": DataLoader(val_dataset, batch_size=batch_size, shuffle=False,\n",
    "                         num_workers=Config.NUM_WORKERS, pin_memory=True,\n",
    "                         collate_fn=collate_fn),\n",
    "        \"test\": DataLoader(test_dataset, batch_size=batch_size, shuffle=False,\n",
    "                          num_workers=Config.NUM_WORKERS, pin_memory=True,\n",
    "                          collate_fn=collate_fn),\n",
    "        \"noisy_test\": DataLoader(noisy_test_dataset, batch_size=batch_size, shuffle=False,\n",
    "                                num_workers=Config.NUM_WORKERS, pin_memory=True,\n",
    "                                collate_fn=collate_fn),\n",
    "    }\n",
    "    \n",
    "    return dataloaders\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"测试数据加载器...\")\n",
    "    dataloaders = get_dataloaders()\n",
    "    x, y, attention_mask = next(iter(dataloaders[\"train\"]))\n",
    "    print(f\"音频数据形状: {x.shape}\")\n",
    "    print(f\"标签数据形状: {y.shape}\")\n",
    "    print(f\"注意力掩码形状: {attention_mask.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1139fbf3-65d7-40ff-97c9-d96999a658e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型结构:\n",
      "CHiLAPModel(\n",
      "  (feature_extractor): Sequential(\n",
      "    (0): Conv1d(1, 256, kernel_size=(5,), stride=(2,), padding=(2,))\n",
      "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): PReLU(num_parameters=1)\n",
      "    (3): Conv1d(256, 256, kernel_size=(5,), stride=(2,), padding=(2,))\n",
      "    (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): PReLU(num_parameters=1)\n",
      "    (6): Conv1d(256, 256, kernel_size=(5,), stride=(2,), padding=(2,))\n",
      "    (7): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (8): PReLU(num_parameters=1)\n",
      "  )\n",
      "  (chaos_layer): ChaoticStimulus(\n",
      "    (chaos_transform): Sequential(\n",
      "      (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): PReLU(num_parameters=1)\n",
      "      (3): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "      (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): PReLU(num_parameters=1)\n",
      "    )\n",
      "  )\n",
      "  (attention): BifurcationAttention(\n",
      "    (query): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (key): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (value): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (tdnn_block): Sequential(\n",
      "    (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): PReLU(num_parameters=1)\n",
      "    (3): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
      "    (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): PReLU(num_parameters=1)\n",
      "  )\n",
      "  (pooling): StatisticalPooling()\n",
      "  (embedding): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=128, bias=True)\n",
      "    (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): PReLU(num_parameters=1)\n",
      "    (3): Dropout(p=0.2, inplace=False)\n",
      "  )\n",
      "  (classifier): Linear(in_features=128, out_features=10, bias=True)\n",
      ")\n",
      "\n",
      "测试前向传播:\n",
      "输入形状: torch.Size([2, 1, 16000])\n",
      "注意力掩码形状: torch.Size([2, 2000])\n",
      "嵌入向量形状: torch.Size([2, 128])\n",
      "分类输出形状: torch.Size([2, 10])\n",
      "注意力权重形状: torch.Size([2, 8, 250, 250])\n",
      "前向传播成功!\n",
      "前向传播错误: Must pass 2-d input. shape=(8, 250, 250)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/run/nvme/job_5060361/tmp/ipykernel_4099380/1893251236.py\", line 377, in <module>\n",
      "    visualizer.plot_attention_weights(attention_weights.unsqueeze(0), \"attention_heatmap.png\")\n",
      "  File \"/run/nvme/job_5060361/tmp/ipykernel_4099380/1893251236.py\", line 300, in plot_attention_weights\n",
      "    sns.heatmap(attn, cmap='viridis')\n",
      "  File \"/usr/local/lib/python3.12/site-packages/seaborn/matrix.py\", line 446, in heatmap\n",
      "    plotter = _HeatMapper(data, vmin, vmax, cmap, center, robust, annot, fmt,\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/site-packages/seaborn/matrix.py\", line 110, in __init__\n",
      "    data = pd.DataFrame(plot_data)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib64/python3.12/site-packages/pandas/core/frame.py\", line 827, in __init__\n",
      "    mgr = ndarray_to_mgr(\n",
      "          ^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib64/python3.12/site-packages/pandas/core/internals/construction.py\", line 314, in ndarray_to_mgr\n",
      "    values = _ensure_2d(values)\n",
      "             ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib64/python3.12/site-packages/pandas/core/internals/construction.py\", line 592, in _ensure_2d\n",
      "    raise ValueError(f\"Must pass 2-d input. shape={values.shape}\")\n",
      "ValueError: Must pass 2-d input. shape=(8, 250, 250)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# 简化混沌激励模块\n",
    "class ChaoticStimulus(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        \"\"\"\n",
    "        简化的混沌激励模块\n",
    "        :param input_dim: 输入维度\n",
    "        :param output_dim: 输出维度\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.chaos_transform = nn.Sequential(\n",
    "            nn.Conv1d(input_dim, output_dim, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(output_dim),\n",
    "            nn.PReLU(),\n",
    "            nn.Conv1d(output_dim, output_dim, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(output_dim),\n",
    "            nn.PReLU()\n",
    "        )\n",
    "\n",
    "        # 混沌扰动参数\n",
    "        self.chaos_factor = nn.Parameter(torch.tensor(0.1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        前向传播\n",
    "        :param x: 输入特征 [batch_size, channels, seq_len]\n",
    "        :return: 混沌处理后的特征 [batch_size, channels, seq_len]\n",
    "        \"\"\"\n",
    "        # 常规特征变换\n",
    "        transformed = self.chaos_transform(x)\n",
    "\n",
    "        # 添加混沌扰动\n",
    "        batch_size, channels, seq_len = transformed.size()\n",
    "        if self.training:  # 仅在训练时添加混沌扰动\n",
    "            # 生成与特征相同形状的混沌噪声\n",
    "            chaos_noise = torch.randn_like(transformed) * self.chaos_factor\n",
    "            # 应用非线性激活增强混沌特性\n",
    "            chaos_noise = torch.tanh(chaos_noise)\n",
    "            transformed = transformed + chaos_noise\n",
    "\n",
    "        return transformed\n",
    "\n",
    "\n",
    "# 复杂分岔注意力机制\n",
    "class BifurcationAttention(nn.Module):\n",
    "    def __init__(self, input_dim, num_heads=Config.ATTENTION_HEADS,\n",
    "                 threshold=Config.BIFURCATION_THRESHOLD):\n",
    "        \"\"\"\n",
    "        分岔注意力机制\n",
    "        :param input_dim: 输入维度\n",
    "        :param num_heads: 注意力头数\n",
    "        :param threshold: 分岔阈值\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.num_heads = num_heads\n",
    "\n",
    "        # 确保输入维度可以被头数整除\n",
    "        assert input_dim % num_heads == 0, f\"input_dim ({input_dim}) must be divisible by num_heads ({num_heads})\"\n",
    "        self.head_dim = input_dim // num_heads\n",
    "        self.threshold = threshold\n",
    "\n",
    "        # 注意力投影\n",
    "        self.query = nn.Linear(input_dim, input_dim)\n",
    "        self.key = nn.Linear(input_dim, input_dim)\n",
    "        self.value = nn.Linear(input_dim, input_dim)\n",
    "\n",
    "        # 输出投影\n",
    "        self.out_proj = nn.Linear(input_dim, input_dim)\n",
    "\n",
    "        # 分岔控制参数\n",
    "        self.bifurcation_param = nn.Parameter(torch.tensor(0.5))\n",
    "\n",
    "        # Dropout层\n",
    "        self.dropout = nn.Dropout(Config.ATTENTION_DROPOUT)\n",
    "\n",
    "        self.max_seq_len = Config.ATTENTION_MAX_SEQ_LEN\n",
    "\n",
    "    def forward(self, x, attention_mask=None):\n",
    "        \"\"\"\n",
    "        前向传播\n",
    "        :param x: 输入特征 [batch_size, seq_len, input_dim]\n",
    "        :param attention_mask: 注意力掩码 [batch_size, seq_len]\n",
    "        :return: 注意力加权后的特征 [batch_size, seq_len, input_dim]\n",
    "        \"\"\"\n",
    "        batch_size, seq_len, _ = x.size()\n",
    "\n",
    "        # 限制序列长度防止内存溢出\n",
    "        if seq_len > self.max_seq_len:\n",
    "            x = x[:, :self.max_seq_len, :]\n",
    "            seq_len = self.max_seq_len\n",
    "            if attention_mask is not None:\n",
    "                attention_mask = attention_mask[:, :self.max_seq_len]\n",
    "\n",
    "        # 线性投影\n",
    "        q = self.query(x)\n",
    "        k = self.key(x)\n",
    "        v = self.value(x)\n",
    "\n",
    "        # 分割头 [batch_size, num_heads, seq_len, head_dim]\n",
    "        q = q.view(batch_size, seq_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "        k = k.view(batch_size, seq_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "        v = v.view(batch_size, seq_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "\n",
    "        # 计算注意力分数\n",
    "        scores = torch.matmul(q, k.transpose(-2, -1)) / (self.head_dim ** 0.5)\n",
    "\n",
    "        # 应用注意力掩码（如果提供）\n",
    "        if attention_mask is not None:\n",
    "            # 将注意力掩码扩展到注意力头的维度\n",
    "            attention_mask = attention_mask.unsqueeze(1).unsqueeze(2)  # [batch_size, 1, 1, seq_len]\n",
    "            scores = scores.masked_fill(attention_mask == 0, -1e9)\n",
    "\n",
    "        # 应用分岔控制\n",
    "        # 分岔函数: f(r) = r * sin(π * r)\n",
    "        r = torch.sigmoid(self.bifurcation_param)\n",
    "        bifurcation_factor = r * torch.sin(np.pi * r)\n",
    "\n",
    "        # 当分岔因子接近阈值时，系统动态变化加剧\n",
    "        if torch.abs(bifurcation_factor - self.threshold) < 0.1:\n",
    "            # 添加随机扰动模拟混沌行为\n",
    "            scores = scores + 0.05 * torch.randn_like(scores, device=scores.device)\n",
    "\n",
    "        # 应用softmax获取注意力权重\n",
    "        attention_weights = F.softmax(scores, dim=-1)\n",
    "        attention_weights = self.dropout(attention_weights)\n",
    "\n",
    "        # 加权求和\n",
    "        context = torch.matmul(attention_weights, v)\n",
    "        context = context.transpose(1, 2).contiguous().view(batch_size, seq_len, self.input_dim)\n",
    "\n",
    "        # 输出投影\n",
    "        output = self.out_proj(context)\n",
    "\n",
    "        return output, attention_weights\n",
    "\n",
    "\n",
    "# 统计池化层\n",
    "class StatisticalPooling(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        前向传播\n",
    "        :param x: 输入特征 [batch_size, channels, seq_len]\n",
    "        :return: 池化后的特征 [batch_size, channels*2]\n",
    "        \"\"\"\n",
    "        # 计算均值和标准差\n",
    "        mean = torch.mean(x, dim=2)\n",
    "        std = torch.std(x, dim=2)\n",
    "\n",
    "        # 拼接均值和标准差\n",
    "        return torch.cat((mean, std), dim=1)\n",
    "\n",
    "\n",
    "# 完整的C-HiLAP模型（简化版+复杂注意力）\n",
    "class CHiLAPModel(nn.Module):\n",
    "    def __init__(self, input_dim=Config.INPUT_DIM, hidden_dim=Config.HIDDEN_DIM,\n",
    "                 embedding_dim=Config.EMBEDDING_DIM, num_classes=None):\n",
    "        \"\"\"\n",
    "        混沌层次吸引子传播(C-HiLAP)模型 - 简化版+复杂注意力\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        # 若未传入num_classes，可设置一个默认值（但实际使用时必须从数据集获取后传入）\n",
    "        if num_classes is None:\n",
    "            raise ValueError(\"必须指定num_classes（说话人数量），请从数据集获取后传入\")\n",
    "\n",
    "        # 特征提取层\n",
    "        self.feature_extractor = nn.Sequential(\n",
    "            nn.Conv1d(input_dim, hidden_dim, kernel_size=5, stride=2, padding=2),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.PReLU(),\n",
    "            nn.Conv1d(hidden_dim, hidden_dim, kernel_size=5, stride=2, padding=2),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.PReLU(),\n",
    "            nn.Conv1d(hidden_dim, hidden_dim, kernel_size=5, stride=2, padding=2),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.PReLU()\n",
    "        )\n",
    "\n",
    "        # 混沌激励模块\n",
    "        self.chaos_layer = ChaoticStimulus(hidden_dim, hidden_dim)\n",
    "\n",
    "        # 复杂注意力层\n",
    "        self.attention = BifurcationAttention(hidden_dim)\n",
    "\n",
    "        # TDNN层\n",
    "        self.tdnn_block = nn.Sequential(\n",
    "            nn.Conv1d(hidden_dim, hidden_dim, kernel_size=3, dilation=1, padding=1),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.PReLU(),\n",
    "            nn.Conv1d(hidden_dim, hidden_dim, kernel_size=3, dilation=2, padding=2),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.PReLU()\n",
    "        )\n",
    "\n",
    "        # 池化层\n",
    "        self.pooling = StatisticalPooling()\n",
    "\n",
    "        # 嵌入层\n",
    "        self.embedding = nn.Sequential(\n",
    "            nn.Linear(hidden_dim * 2, embedding_dim),  # 统计池化输出channels*2\n",
    "            nn.BatchNorm1d(embedding_dim),\n",
    "            nn.PReLU(),\n",
    "            nn.Dropout(0.2)\n",
    "        )\n",
    "\n",
    "        # 分类器\n",
    "        self.classifier = nn.Linear(embedding_dim, num_classes)\n",
    "\n",
    "    def forward(self, x, attention_mask=None):\n",
    "        \"\"\"\n",
    "        前向传播\n",
    "        :param x: 输入特征 [batch_size, channels, seq_len] 或 [batch_size, seq_len, channels]\n",
    "        :param attention_mask: 注意力掩码 [batch_size, seq_len]\n",
    "        :return: 嵌入向量和分类结果\n",
    "        \"\"\"\n",
    "        # 检查输入维度并转换为正确的格式 [batch_size, channels, seq_len]\n",
    "        if x.dim() == 3:\n",
    "            # 如果是 [batch_size, seq_len, channels] 格式\n",
    "            if x.size(1) > x.size(2):  # 序列长度应该大于通道数\n",
    "                x = x.permute(0, 2, 1)  # 转换为 [batch_size, channels, seq_len]\n",
    "\n",
    "        # 限制序列长度防止内存溢出\n",
    "        seq_len = x.size(2)\n",
    "        if seq_len > Config.MAX_SEQ_LEN:\n",
    "            x = x[:, :, :Config.MAX_SEQ_LEN]\n",
    "            if attention_mask is not None:\n",
    "                attention_mask = attention_mask[:, :Config.MAX_SEQ_LEN]\n",
    "\n",
    "        # 特征提取\n",
    "        x = self.feature_extractor(x)\n",
    "\n",
    "        # 混沌处理\n",
    "        x = self.chaos_layer(x)\n",
    "\n",
    "        # 转置维度以适应注意力模块 [batch_size, channels, seq_len] -> [batch_size, seq_len, channels]\n",
    "        x = x.permute(0, 2, 1)\n",
    "\n",
    "        # 调整注意力掩码的长度以匹配当前特征序列长度\n",
    "        if attention_mask is not None:\n",
    "            # 当前特征序列长度\n",
    "            current_seq_len = x.size(1)\n",
    "            # 原始注意力掩码的长度\n",
    "            original_seq_len = attention_mask.size(1)\n",
    "            if original_seq_len != current_seq_len:\n",
    "                # 使用自适应平均池化1d来调整掩码长度\n",
    "                attention_mask = attention_mask.unsqueeze(1)  # 添加通道维度\n",
    "                attention_mask = F.adaptive_avg_pool1d(attention_mask, current_seq_len)\n",
    "                attention_mask = attention_mask.squeeze(1)    # 移除通道维度\n",
    "\n",
    "        # 注意力加权\n",
    "        x, attention_weights = self.attention(x, attention_mask)\n",
    "\n",
    "        # 转置回原始维度 [batch_size, seq_len, channels] -> [batch_size, channels, seq_len]\n",
    "        x = x.permute(0, 2, 1)\n",
    "\n",
    "        # TDNN处理\n",
    "        x = self.tdnn_block(x)\n",
    "\n",
    "        # 池化\n",
    "        x = self.pooling(x)\n",
    "\n",
    "        # 嵌入向量\n",
    "        embedding = self.embedding(x)\n",
    "\n",
    "        # 分类\n",
    "        logits = self.classifier(embedding)\n",
    "\n",
    "        return embedding, logits, attention_weights\n",
    "\n",
    "\n",
    "# 注意力可视化工具\n",
    "class AttentionVisualizer:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    @staticmethod\n",
    "    def plot_attention_weights(attention_weights, save_path=None):\n",
    "        \"\"\"\n",
    "        绘制注意力权重热图\n",
    "        :param attention_weights: 注意力权重 [batch_size, num_heads, seq_len, seq_len]\n",
    "        :param save_path: 保存路径\n",
    "        \"\"\"\n",
    "        try:\n",
    "            import matplotlib.pyplot as plt\n",
    "            import seaborn as sns\n",
    "            \n",
    "            # 取第一个样本和第一个注意力头\n",
    "            attn = attention_weights[0, 0].detach().cpu().numpy()\n",
    "            \n",
    "            plt.figure(figsize=(10, 8))\n",
    "            sns.heatmap(attn, cmap='viridis')\n",
    "            plt.title(\"Attention Weights Heatmap\")\n",
    "            plt.xlabel(\"Key Position\")\n",
    "            plt.ylabel(\"Query Position\")\n",
    "            \n",
    "            if save_path:\n",
    "                plt.savefig(save_path)\n",
    "                print(f\"注意力权重热图已保存到: {save_path}\")\n",
    "            else:\n",
    "                plt.show()\n",
    "                \n",
    "        except ImportError:\n",
    "            print(\"无法导入matplotlib或seaborn，跳过注意力可视化\")\n",
    "    \n",
    "    @staticmethod\n",
    "    def plot_bifurcation_parameter(model, save_path=None):\n",
    "        \"\"\"\n",
    "        绘制分岔参数随时间的变化\n",
    "        :param model: 模型实例\n",
    "        :param save_path: 保存路径\n",
    "        \"\"\"\n",
    "        try:\n",
    "            import matplotlib.pyplot as plt\n",
    "            \n",
    "            # 获取分岔参数\n",
    "            bifurcation_param = model.attention.bifurcation_param.detach().cpu().numpy()\n",
    "            r = 1 / (1 + np.exp(-bifurcation_param))  # sigmoid逆变换\n",
    "            bifurcation_factor = r * np.sin(np.pi * r)\n",
    "            \n",
    "            plt.figure(figsize=(10, 6))\n",
    "            plt.plot([bifurcation_factor], 'ro-')\n",
    "            plt.axhline(y=model.attention.threshold, color='r', linestyle='--', label='Threshold')\n",
    "            plt.title(\"Bifurcation Parameter\")\n",
    "            plt.xlabel(\"Training Step\")\n",
    "            plt.ylabel(\"Bifurcation Factor\")\n",
    "            plt.legend()\n",
    "            \n",
    "            if save_path:\n",
    "                plt.savefig(save_path)\n",
    "                print(f\"分岔参数图已保存到: {save_path}\")\n",
    "            else:\n",
    "                plt.show()\n",
    "                \n",
    "        except ImportError:\n",
    "            print(\"无法导入matplotlib，跳过分岔参数可视化\")\n",
    "\n",
    "\n",
    "# 测试代码\n",
    "if __name__ == \"__main__\":\n",
    "    # 创建模型实例\n",
    "    model = CHiLAPModel(num_classes=10)  # 添加num_classes参数\n",
    "\n",
    "    print(\"模型结构:\")\n",
    "    print(model)\n",
    "\n",
    "    # 生成随机输入（使用较小的序列长度进行测试）\n",
    "    batch_size = 2\n",
    "    seq_len = Config.MAX_SEQ_LEN\n",
    "    # 正确的输入格式：[batch_size, channels, seq_len]\n",
    "    x = torch.randn(batch_size, 1, seq_len)\n",
    "    seq_len_feat = seq_len // 8  # feature extractor stride=2 x3\n",
    "    attention_mask = torch.ones(batch_size, seq_len_feat)\n",
    "\n",
    "    print(f\"\\n测试前向传播:\")\n",
    "    print(f\"输入形状: {x.shape}\")\n",
    "    print(f\"注意力掩码形状: {attention_mask.shape}\")\n",
    "\n",
    "    # 前向传播\n",
    "    try:\n",
    "        embedding, logits, attention_weights = model(x, attention_mask)\n",
    "        print(f\"嵌入向量形状: {embedding.shape}\")\n",
    "        print(f\"分类输出形状: {logits.shape}\")\n",
    "        print(f\"注意力权重形状: {attention_weights.shape}\")\n",
    "        print(\"前向传播成功!\")\n",
    "        \n",
    "        # 测试注意力可视化\n",
    "        visualizer = AttentionVisualizer()\n",
    "        visualizer.plot_attention_weights(attention_weights.unsqueeze(0), \"attention_heatmap.png\")\n",
    "        visualizer.plot_bifurcation_parameter(model, \"bifurcation_parameter.png\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"前向传播错误: {e}\")\n",
    "        import traceback\n",
    "\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04722cfc-bad3-4609-ad57-34d667601485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "创建数据加载器...\n",
      "加载LibriSpeech数据集: /users/tianyuey/Project/devDataset/LibriSpeech\n",
      "处理子集: dev-clean\n",
      "在 dev-clean 中找到 2703 个.flac文件\n",
      "处理子集: dev-other\n",
      "在 dev-other 中找到 5567 个.flac文件\n",
      "找到 73 个不同的说话人\n",
      "有效文件: 5000/5000\n",
      "移除 0 个无效文件\n",
      "找到 73 个不同的说话人\n",
      "最终 train 数据集大小: 5000 个样本\n",
      "加载LibriSpeech数据集: /users/tianyuey/Project/devDataset/LibriSpeech\n",
      "处理子集: dev-clean\n",
      "在 dev-clean 中找到 2703 个.flac文件\n",
      "处理子集: dev-other\n",
      "在 dev-other 中找到 5567 个.flac文件\n",
      "找到 73 个不同的说话人\n",
      "有效文件: 557/557\n",
      "移除 0 个无效文件\n",
      "找到 73 个不同的说话人\n",
      "最终 val 数据集大小: 557 个样本\n",
      "加载LibriSpeech数据集: /users/tianyuey/Project/devDataset/LibriSpeech\n",
      "处理子集: dev-clean\n",
      "在 dev-clean 中找到 2703 个.flac文件\n",
      "处理子集: dev-other\n",
      "在 dev-other 中找到 5567 个.flac文件\n",
      "找到 73 个不同的说话人\n",
      "有效文件: 5567/5567\n",
      "移除 0 个无效文件\n",
      "找到 73 个不同的说话人\n",
      "最终 test 数据集大小: 5567 个样本\n",
      "训练集批次数: 625\n",
      "验证集批次数: 70\n",
      "测试集批次数: 696\n",
      "数据集中实际说话人数量（类别数）: 73\n",
      "创建模型和训练器...\n",
      "使用设备: cuda\n",
      "模型预期输入长度: 16000\n",
      "测试前向传播...\n",
      "原始输入形状: torch.Size([8, 16000]), 标签形状: torch.Size([8]), 掩码形状: torch.Size([8, 16000])\n",
      "处理后输入形状: torch.Size([8, 1, 16000]), 掩码形状: torch.Size([8, 16000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib64/python3.12/site-packages/torch/optim/lr_scheduler.py:182: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "嵌入形状: torch.Size([8, 128]), 输出形状: torch.Size([8, 73]), 注意力权重形状: torch.Size([8, 8, 250, 250])\n",
      "前向传播测试成功!\n",
      "开始训练...\n",
      "开始训练T2模型（简化模型+复杂注意力）...\n",
      "训练集批次数: 625, 验证集批次数: 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 4.2342, Acc: 3.58%, CE: 4.1949, AttnReg: 3.9282: 100%|██████████| 625/625 [00:58<00:00, 10.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500, Train Loss: 4.2339, Train Acc: 3.58%\n",
      "Epoch 1, Val Loss: 4.0890, Val Acc: 4.67%\n",
      "当前学习率: 0.000800\n",
      "保存最佳模型，验证准确率: 4.67%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 3.9014, Acc: 6.72%, CE: 3.8817, AttnReg: 1.9697: 100%|██████████| 625/625 [00:57<00:00, 10.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/500, Train Loss: 3.8994, Train Acc: 6.74%\n",
      "Epoch 2, Val Loss: 3.6824, Val Acc: 11.49%\n",
      "当前学习率: 0.000800\n",
      "保存最佳模型，验证准确率: 11.49%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3, Loss: 3.6652, Acc: 10.19%, CE: 3.6505, AttnReg: 1.4632: 100%|██████████| 625/625 [00:57<00:00, 10.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/500, Train Loss: 3.6644, Train Acc: 10.16%\n",
      "Epoch 3, Val Loss: 3.4354, Val Acc: 14.72%\n",
      "当前学习率: 0.000800\n",
      "保存最佳模型，验证准确率: 14.72%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4, Loss: 3.5418, Acc: 11.63%, CE: 3.5300, AttnReg: 1.1738: 100%|██████████| 625/625 [00:57<00:00, 10.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/500, Train Loss: 3.5429, Train Acc: 11.62%\n",
      "Epoch 4, Val Loss: 3.3310, Val Acc: 16.88%\n",
      "当前学习率: 0.000800\n",
      "保存最佳模型，验证准确率: 16.88%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5, Loss: 3.4461, Acc: 13.29%, CE: 3.4365, AttnReg: 0.9625: 100%|██████████| 625/625 [00:57<00:00, 10.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/500, Train Loss: 3.4461, Train Acc: 13.24%\n",
      "Epoch 5, Val Loss: 3.2694, Val Acc: 16.34%\n",
      "当前学习率: 0.000800\n",
      "注意力权重可视化已保存到: ./attention_viz/attention_epoch_5.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6, Loss: 3.3360, Acc: 15.82%, CE: 3.3275, AttnReg: 0.8481: 100%|██████████| 625/625 [00:57<00:00, 10.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/500, Train Loss: 3.3353, Train Acc: 15.82%\n",
      "Epoch 6, Val Loss: 3.0644, Val Acc: 22.98%\n",
      "当前学习率: 0.000800\n",
      "保存最佳模型，验证准确率: 22.98%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7, Loss: 3.2936, Acc: 16.45%, CE: 3.2862, AttnReg: 0.7389: 100%|██████████| 625/625 [00:57<00:00, 10.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/500, Train Loss: 3.2938, Train Acc: 16.44%\n",
      "Epoch 7, Val Loss: 3.0683, Val Acc: 19.93%\n",
      "当前学习率: 0.000800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8, Loss: 3.2213, Acc: 17.98%, CE: 3.2136, AttnReg: 0.7708: 100%|██████████| 625/625 [00:57<00:00, 10.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/500, Train Loss: 3.2226, Train Acc: 17.96%\n",
      "Epoch 8, Val Loss: 2.9636, Val Acc: 25.85%\n",
      "当前学习率: 0.000800\n",
      "保存最佳模型，验证准确率: 25.85%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9, Loss: 3.1382, Acc: 19.30%, CE: 3.1313, AttnReg: 0.6865: 100%|██████████| 625/625 [00:59<00:00, 10.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/500, Train Loss: 3.1360, Train Acc: 19.32%\n",
      "Epoch 9, Val Loss: 2.9718, Val Acc: 25.49%\n",
      "当前学习率: 0.000800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10, Loss: 3.0647, Acc: 20.57%, CE: 3.0589, AttnReg: 0.5832: 100%|██████████| 625/625 [01:02<00:00, 10.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/500, Train Loss: 3.0638, Train Acc: 20.60%\n",
      "Epoch 10, Val Loss: 2.7731, Val Acc: 27.47%\n",
      "当前学习率: 0.000800\n",
      "注意力权重可视化已保存到: ./attention_viz/attention_epoch_10.png\n",
      "保存最佳模型，验证准确率: 27.47%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11, Loss: 3.0556, Acc: 21.22%, CE: 3.0502, AttnReg: 0.5411: 100%|██████████| 625/625 [01:01<00:00, 10.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/500, Train Loss: 3.0562, Train Acc: 21.28%\n",
      "Epoch 11, Val Loss: 2.8233, Val Acc: 25.67%\n",
      "当前学习率: 0.000800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12, Loss: 3.0021, Acc: 21.86%, CE: 2.9958, AttnReg: 0.6249: 100%|██████████| 625/625 [01:02<00:00, 10.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/500, Train Loss: 3.0019, Train Acc: 21.84%\n",
      "Epoch 12, Val Loss: 2.7916, Val Acc: 26.39%\n",
      "当前学习率: 0.000800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13, Loss: 2.9749, Acc: 22.46%, CE: 2.9686, AttnReg: 0.6275: 100%|██████████| 625/625 [01:02<00:00,  9.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/500, Train Loss: 2.9748, Train Acc: 22.44%\n",
      "Epoch 13, Val Loss: 2.7858, Val Acc: 27.29%\n",
      "当前学习率: 0.000800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14, Loss: 2.9147, Acc: 24.54%, CE: 2.9088, AttnReg: 0.5962: 100%|██████████| 625/625 [01:01<00:00, 10.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/500, Train Loss: 2.9134, Train Acc: 24.62%\n",
      "Epoch 14, Val Loss: 2.6714, Val Acc: 29.26%\n",
      "当前学习率: 0.000800\n",
      "保存最佳模型，验证准确率: 29.26%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15, Loss: 2.8515, Acc: 25.04%, CE: 2.8457, AttnReg: 0.5712: 100%|██████████| 625/625 [01:03<00:00,  9.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/500, Train Loss: 2.8536, Train Acc: 25.06%\n",
      "Epoch 15, Val Loss: 2.5783, Val Acc: 33.93%\n",
      "当前学习率: 0.000800\n",
      "注意力权重可视化已保存到: ./attention_viz/attention_epoch_15.png\n",
      "保存最佳模型，验证准确率: 33.93%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16, Loss: 2.8573, Acc: 25.54%, CE: 2.8518, AttnReg: 0.5440: 100%|██████████| 625/625 [01:01<00:00, 10.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/500, Train Loss: 2.8590, Train Acc: 25.48%\n",
      "Epoch 16, Val Loss: 2.6434, Val Acc: 30.52%\n",
      "当前学习率: 0.000800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17, Loss: 2.7976, Acc: 26.23%, CE: 2.7921, AttnReg: 0.5443: 100%|██████████| 625/625 [01:01<00:00, 10.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/500, Train Loss: 2.7985, Train Acc: 26.16%\n",
      "Epoch 17, Val Loss: 2.5877, Val Acc: 32.50%\n",
      "当前学习率: 0.000800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18, Loss: 2.8190, Acc: 26.77%, CE: 2.8133, AttnReg: 0.5633: 100%|██████████| 625/625 [01:02<00:00, 10.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/500, Train Loss: 2.8203, Train Acc: 26.74%\n",
      "Epoch 18, Val Loss: 2.4838, Val Acc: 32.85%\n",
      "当前学习率: 0.000800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19, Loss: 2.7478, Acc: 28.24%, CE: 2.7425, AttnReg: 0.5335: 100%|██████████| 625/625 [01:01<00:00, 10.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/500, Train Loss: 2.7461, Train Acc: 28.26%\n",
      "Epoch 19, Val Loss: 2.4131, Val Acc: 33.39%\n",
      "当前学习率: 0.000800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20, Loss: 2.7245, Acc: 29.93%, CE: 2.7191, AttnReg: 0.5417: 100%|██████████| 625/625 [01:02<00:00, 10.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/500, Train Loss: 2.7259, Train Acc: 29.94%\n",
      "Epoch 20, Val Loss: 2.3193, Val Acc: 37.70%\n",
      "当前学习率: 0.000800\n",
      "注意力权重可视化已保存到: ./attention_viz/attention_epoch_20.png\n",
      "保存最佳模型，验证准确率: 37.70%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21, Loss: 2.6658, Acc: 29.67%, CE: 2.6602, AttnReg: 0.5650: 100%|██████████| 625/625 [01:00<00:00, 10.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/500, Train Loss: 2.6681, Train Acc: 29.64%\n",
      "Epoch 21, Val Loss: 2.3934, Val Acc: 39.14%\n",
      "当前学习率: 0.000800\n",
      "保存最佳模型，验证准确率: 39.14%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22, Loss: 2.6564, Acc: 30.31%, CE: 2.6506, AttnReg: 0.5798: 100%|██████████| 625/625 [01:02<00:00, 10.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/500, Train Loss: 2.6594, Train Acc: 30.24%\n",
      "Epoch 22, Val Loss: 2.3863, Val Acc: 35.73%\n",
      "当前学习率: 0.000800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23, Loss: 2.6215, Acc: 31.48%, CE: 2.6160, AttnReg: 0.5404: 100%|██████████| 625/625 [01:00<00:00, 10.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/500, Train Loss: 2.6234, Train Acc: 31.44%\n",
      "Epoch 23, Val Loss: 2.4161, Val Acc: 34.47%\n",
      "当前学习率: 0.000800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24, Loss: 2.6309, Acc: 31.12%, CE: 2.6256, AttnReg: 0.5243: 100%|██████████| 625/625 [01:01<00:00, 10.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/500, Train Loss: 2.6331, Train Acc: 31.04%\n",
      "Epoch 24, Val Loss: 2.3870, Val Acc: 35.01%\n",
      "当前学习率: 0.000800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25, Loss: 2.5631, Acc: 32.93%, CE: 2.5581, AttnReg: 0.4943: 100%|██████████| 625/625 [00:57<00:00, 10.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/500, Train Loss: 2.5621, Train Acc: 32.94%\n",
      "Epoch 25, Val Loss: 2.3061, Val Acc: 40.22%\n",
      "当前学习率: 0.000800\n",
      "注意力权重可视化已保存到: ./attention_viz/attention_epoch_25.png\n",
      "保存最佳模型，验证准确率: 40.22%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26, Loss: 2.5537, Acc: 31.76%, CE: 2.5486, AttnReg: 0.5108: 100%|██████████| 625/625 [00:57<00:00, 10.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/500, Train Loss: 2.5536, Train Acc: 31.76%\n",
      "Epoch 26, Val Loss: 2.2504, Val Acc: 42.73%\n",
      "当前学习率: 0.000800\n",
      "保存最佳模型，验证准确率: 42.73%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27, Loss: 2.5250, Acc: 33.37%, CE: 2.5195, AttnReg: 0.5507: 100%|██████████| 625/625 [00:57<00:00, 10.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/500, Train Loss: 2.5216, Train Acc: 33.46%\n",
      "Epoch 27, Val Loss: 2.2780, Val Acc: 38.06%\n",
      "当前学习率: 0.000800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28, Loss: 2.4994, Acc: 33.62%, CE: 2.4943, AttnReg: 0.5096: 100%|██████████| 625/625 [00:57<00:00, 10.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/500, Train Loss: 2.4969, Train Acc: 33.72%\n",
      "Epoch 28, Val Loss: 2.1630, Val Acc: 43.27%\n",
      "当前学习率: 0.000800\n",
      "保存最佳模型，验证准确率: 43.27%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29, Loss: 2.4345, Acc: 35.12%, CE: 2.4291, AttnReg: 0.5466: 100%|██████████| 625/625 [00:57<00:00, 10.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/500, Train Loss: 2.4349, Train Acc: 35.14%\n",
      "Epoch 29, Val Loss: 2.1390, Val Acc: 42.01%\n",
      "当前学习率: 0.000800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30, Loss: 2.4749, Acc: 34.54%, CE: 2.4696, AttnReg: 0.5349: 100%|██████████| 625/625 [00:57<00:00, 10.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/500, Train Loss: 2.4730, Train Acc: 34.52%\n",
      "Epoch 30, Val Loss: 2.1167, Val Acc: 42.19%\n",
      "当前学习率: 0.000800\n",
      "注意力权重可视化已保存到: ./attention_viz/attention_epoch_30.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31, Loss: 2.4590, Acc: 35.06%, CE: 2.4535, AttnReg: 0.5481: 100%|██████████| 625/625 [00:57<00:00, 10.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/500, Train Loss: 2.4599, Train Acc: 35.06%\n",
      "Epoch 31, Val Loss: 2.2573, Val Acc: 41.83%\n",
      "当前学习率: 0.000800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32, Loss: 2.4180, Acc: 35.69%, CE: 2.4122, AttnReg: 0.5777: 100%|██████████| 625/625 [00:57<00:00, 10.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/500, Train Loss: 2.4178, Train Acc: 35.72%\n",
      "Epoch 32, Val Loss: 2.1262, Val Acc: 41.47%\n",
      "当前学习率: 0.000800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33, Loss: 2.3848, Acc: 36.43%, CE: 2.3793, AttnReg: 0.5540: 100%|██████████| 625/625 [00:57<00:00, 10.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/500, Train Loss: 2.3855, Train Acc: 36.44%\n",
      "Epoch 33, Val Loss: 2.1889, Val Acc: 41.29%\n",
      "当前学习率: 0.000800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34, Loss: 2.4009, Acc: 36.07%, CE: 2.3955, AttnReg: 0.5478: 100%|██████████| 625/625 [00:57<00:00, 10.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/500, Train Loss: 2.4002, Train Acc: 36.08%\n",
      "Epoch 34, Val Loss: 2.0857, Val Acc: 41.29%\n",
      "当前学习率: 0.000800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35, Loss: 2.3882, Acc: 36.88%, CE: 2.3828, AttnReg: 0.5487: 100%|██████████| 625/625 [00:57<00:00, 10.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/500, Train Loss: 2.3888, Train Acc: 36.90%\n",
      "Epoch 35, Val Loss: 2.0996, Val Acc: 42.19%\n",
      "当前学习率: 0.000800\n",
      "注意力权重可视化已保存到: ./attention_viz/attention_epoch_35.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36, Loss: 2.3471, Acc: 37.64%, CE: 2.3415, AttnReg: 0.5535: 100%|██████████| 625/625 [00:57<00:00, 10.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/500, Train Loss: 2.3511, Train Acc: 37.62%\n",
      "Epoch 36, Val Loss: 2.1240, Val Acc: 40.93%\n",
      "当前学习率: 0.000800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37, Loss: 2.3553, Acc: 38.02%, CE: 2.3493, AttnReg: 0.5981: 100%|██████████| 625/625 [00:57<00:00, 10.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/500, Train Loss: 2.3532, Train Acc: 38.08%\n",
      "Epoch 37, Val Loss: 2.0234, Val Acc: 45.60%\n",
      "当前学习率: 0.000800\n",
      "保存最佳模型，验证准确率: 45.60%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38, Loss: 2.3025, Acc: 38.87%, CE: 2.2968, AttnReg: 0.5646: 100%|██████████| 625/625 [00:57<00:00, 10.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/500, Train Loss: 2.3041, Train Acc: 38.80%\n",
      "Epoch 38, Val Loss: 1.9612, Val Acc: 45.42%\n",
      "当前学习率: 0.000800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39, Loss: 2.3110, Acc: 38.00%, CE: 2.3052, AttnReg: 0.5796: 100%|██████████| 625/625 [00:57<00:00, 10.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/500, Train Loss: 2.3128, Train Acc: 38.02%\n",
      "Epoch 39, Val Loss: 2.0015, Val Acc: 44.52%\n",
      "当前学习率: 0.000800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40, Loss: 2.2600, Acc: 39.55%, CE: 2.2545, AttnReg: 0.5524: 100%|██████████| 625/625 [00:57<00:00, 10.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/500, Train Loss: 2.2573, Train Acc: 39.62%\n",
      "Epoch 40, Val Loss: 1.9331, Val Acc: 46.32%\n",
      "当前学习率: 0.000800\n",
      "注意力权重可视化已保存到: ./attention_viz/attention_epoch_40.png\n",
      "保存最佳模型，验证准确率: 46.32%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41, Loss: 2.2728, Acc: 39.61%, CE: 2.2670, AttnReg: 0.5727: 100%|██████████| 625/625 [00:57<00:00, 10.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/500, Train Loss: 2.2734, Train Acc: 39.60%\n",
      "Epoch 41, Val Loss: 1.9429, Val Acc: 47.94%\n",
      "当前学习率: 0.000800\n",
      "保存最佳模型，验证准确率: 47.94%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42, Loss: 2.2470, Acc: 39.96%, CE: 2.2412, AttnReg: 0.5762: 100%|██████████| 625/625 [00:57<00:00, 10.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/500, Train Loss: 2.2470, Train Acc: 39.96%\n",
      "Epoch 42, Val Loss: 1.9363, Val Acc: 47.76%\n",
      "当前学习率: 0.000800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43, Loss: 2.2183, Acc: 40.98%, CE: 2.2128, AttnReg: 0.5495: 100%|██████████| 625/625 [00:57<00:00, 10.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/500, Train Loss: 2.2171, Train Acc: 40.96%\n",
      "Epoch 43, Val Loss: 1.8461, Val Acc: 49.55%\n",
      "当前学习率: 0.000800\n",
      "保存最佳模型，验证准确率: 49.55%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44, Loss: 2.2377, Acc: 40.44%, CE: 2.2318, AttnReg: 0.5898: 100%|██████████| 625/625 [00:57<00:00, 10.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/500, Train Loss: 2.2348, Train Acc: 40.50%\n",
      "Epoch 44, Val Loss: 2.0995, Val Acc: 40.57%\n",
      "当前学习率: 0.000800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45, Loss: 2.2052, Acc: 41.67%, CE: 2.1996, AttnReg: 0.5603: 100%|██████████| 625/625 [00:57<00:00, 10.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/500, Train Loss: 2.2051, Train Acc: 41.62%\n",
      "Epoch 45, Val Loss: 1.9144, Val Acc: 48.83%\n",
      "当前学习率: 0.000800\n",
      "注意力权重可视化已保存到: ./attention_viz/attention_epoch_45.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46, Loss: 2.1668, Acc: 41.65%, CE: 2.1614, AttnReg: 0.5384: 100%|██████████| 625/625 [00:57<00:00, 10.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/500, Train Loss: 2.1672, Train Acc: 41.66%\n",
      "Epoch 46, Val Loss: 1.9136, Val Acc: 46.50%\n",
      "当前学习率: 0.000800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47, Loss: 2.1449, Acc: 42.59%, CE: 2.1395, AttnReg: 0.5431: 100%|██████████| 625/625 [00:57<00:00, 10.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/500, Train Loss: 2.1440, Train Acc: 42.58%\n",
      "Epoch 47, Val Loss: 1.8094, Val Acc: 49.55%\n",
      "当前学习率: 0.000800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48, Loss: 2.1439, Acc: 41.81%, CE: 2.1380, AttnReg: 0.5875: 100%|██████████| 625/625 [00:57<00:00, 10.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/500, Train Loss: 2.1463, Train Acc: 41.80%\n",
      "Epoch 48, Val Loss: 1.9198, Val Acc: 47.58%\n",
      "当前学习率: 0.000800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49, Loss: 2.1324, Acc: 42.83%, CE: 2.1270, AttnReg: 0.5449: 100%|██████████| 625/625 [00:57<00:00, 10.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/500, Train Loss: 2.1315, Train Acc: 42.82%\n",
      "Epoch 49, Val Loss: 1.9069, Val Acc: 47.58%\n",
      "当前学习率: 0.000800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50, Loss: 2.1807, Acc: 42.45%, CE: 2.1753, AttnReg: 0.5445: 100%|██████████| 625/625 [00:57<00:00, 10.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/500, Train Loss: 2.1809, Train Acc: 42.48%\n",
      "Epoch 50, Val Loss: 1.9032, Val Acc: 46.50%\n",
      "当前学习率: 0.000800\n",
      "注意力权重可视化已保存到: ./attention_viz/attention_epoch_50.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 51, Loss: 2.0909, Acc: 44.40%, CE: 2.0853, AttnReg: 0.5557: 100%|██████████| 625/625 [00:57<00:00, 10.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/500, Train Loss: 2.0919, Train Acc: 44.42%\n",
      "Epoch 51, Val Loss: 1.7638, Val Acc: 50.09%\n",
      "当前学习率: 0.000800\n",
      "保存最佳模型，验证准确率: 50.09%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 52, Loss: 2.1607, Acc: 42.57%, CE: 2.1550, AttnReg: 0.5718: 100%|██████████| 625/625 [00:57<00:00, 10.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/500, Train Loss: 2.1600, Train Acc: 42.56%\n",
      "Epoch 52, Val Loss: 1.8406, Val Acc: 50.63%\n",
      "当前学习率: 0.000800\n",
      "保存最佳模型，验证准确率: 50.63%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 53, Loss: 2.1417, Acc: 42.23%, CE: 2.1361, AttnReg: 0.5589: 100%|██████████| 625/625 [00:57<00:00, 10.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/500, Train Loss: 2.1414, Train Acc: 42.26%\n",
      "Epoch 53, Val Loss: 1.8220, Val Acc: 49.01%\n",
      "当前学习率: 0.000800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 54, Loss: 2.1467, Acc: 42.61%, CE: 2.1409, AttnReg: 0.5889: 100%|██████████| 625/625 [00:57<00:00, 10.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/500, Train Loss: 2.1448, Train Acc: 42.66%\n",
      "Epoch 54, Val Loss: 1.8691, Val Acc: 47.04%\n",
      "当前学习率: 0.000800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 55, Loss: 2.0949, Acc: 44.24%, CE: 2.0891, AttnReg: 0.5820: 100%|██████████| 625/625 [00:57<00:00, 10.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/500, Train Loss: 2.0987, Train Acc: 44.20%\n",
      "Epoch 55, Val Loss: 1.8847, Val Acc: 48.83%\n",
      "当前学习率: 0.000800\n",
      "注意力权重可视化已保存到: ./attention_viz/attention_epoch_55.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 56, Loss: 2.0963, Acc: 44.16%, CE: 2.0904, AttnReg: 0.5963: 100%|██████████| 625/625 [00:57<00:00, 10.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/500, Train Loss: 2.0953, Train Acc: 44.16%\n",
      "Epoch 56, Val Loss: 1.7805, Val Acc: 51.71%\n",
      "当前学习率: 0.000800\n",
      "保存最佳模型，验证准确率: 51.71%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 57, Loss: 2.0506, Acc: 44.24%, CE: 2.0446, AttnReg: 0.5969: 100%|██████████| 625/625 [00:57<00:00, 10.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/500, Train Loss: 2.0509, Train Acc: 44.26%\n",
      "Epoch 57, Val Loss: 1.7929, Val Acc: 52.06%\n",
      "当前学习率: 0.000400\n",
      "保存最佳模型，验证准确率: 52.06%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 58, Loss: 2.0336, Acc: 45.29%, CE: 2.0276, AttnReg: 0.6013: 100%|██████████| 625/625 [00:57<00:00, 10.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/500, Train Loss: 2.0341, Train Acc: 45.30%\n",
      "Epoch 58, Val Loss: 1.6416, Val Acc: 56.73%\n",
      "当前学习率: 0.000400\n",
      "保存最佳模型，验证准确率: 56.73%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 59, Loss: 1.9845, Acc: 46.40%, CE: 1.9783, AttnReg: 0.6200: 100%|██████████| 625/625 [00:57<00:00, 10.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/500, Train Loss: 1.9837, Train Acc: 46.38%\n",
      "Epoch 59, Val Loss: 1.7016, Val Acc: 51.35%\n",
      "当前学习率: 0.000400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 60, Loss: 1.9738, Acc: 46.54%, CE: 1.9676, AttnReg: 0.6167: 100%|██████████| 625/625 [00:57<00:00, 10.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/500, Train Loss: 1.9706, Train Acc: 46.68%\n",
      "Epoch 60, Val Loss: 1.7076, Val Acc: 52.06%\n",
      "当前学习率: 0.000400\n",
      "注意力权重可视化已保存到: ./attention_viz/attention_epoch_60.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 61, Loss: 1.9181, Acc: 47.60%, CE: 1.9120, AttnReg: 0.6075: 100%|██████████| 625/625 [00:57<00:00, 10.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/500, Train Loss: 1.9256, Train Acc: 47.50%\n",
      "Epoch 61, Val Loss: 1.5845, Val Acc: 59.43%\n",
      "当前学习率: 0.000400\n",
      "保存最佳模型，验证准确率: 59.43%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 62, Loss: 1.8923, Acc: 48.41%, CE: 1.8861, AttnReg: 0.6158: 100%|██████████| 625/625 [00:57<00:00, 10.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/500, Train Loss: 1.8906, Train Acc: 48.46%\n",
      "Epoch 62, Val Loss: 1.6352, Val Acc: 52.42%\n",
      "当前学习率: 0.000400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 63, Loss: 1.9004, Acc: 50.14%, CE: 1.8940, AttnReg: 0.6379: 100%|██████████| 625/625 [00:57<00:00, 10.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63/500, Train Loss: 1.9017, Train Acc: 50.04%\n",
      "Epoch 63, Val Loss: 1.7019, Val Acc: 52.96%\n",
      "当前学习率: 0.000400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 64, Loss: 1.8867, Acc: 48.39%, CE: 1.8802, AttnReg: 0.6424: 100%|██████████| 625/625 [00:57<00:00, 10.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64/500, Train Loss: 1.8857, Train Acc: 48.38%\n",
      "Epoch 64, Val Loss: 1.6462, Val Acc: 53.14%\n",
      "当前学习率: 0.000400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 65, Loss: 1.8756, Acc: 49.36%, CE: 1.8693, AttnReg: 0.6318: 100%|██████████| 625/625 [00:57<00:00, 10.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65/500, Train Loss: 1.8728, Train Acc: 49.46%\n",
      "Epoch 65, Val Loss: 1.5944, Val Acc: 54.94%\n",
      "当前学习率: 0.000400\n",
      "注意力权重可视化已保存到: ./attention_viz/attention_epoch_65.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 66, Loss: 1.8941, Acc: 49.21%, CE: 1.8878, AttnReg: 0.6301: 100%|██████████| 625/625 [00:57<00:00, 10.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66/500, Train Loss: 1.8935, Train Acc: 49.24%\n",
      "Epoch 66, Val Loss: 1.6325, Val Acc: 53.50%\n",
      "当前学习率: 0.000400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 67, Loss: 1.9132, Acc: 48.37%, CE: 1.9067, AttnReg: 0.6450: 100%|██████████| 625/625 [00:57<00:00, 10.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67/500, Train Loss: 1.9117, Train Acc: 48.42%\n",
      "Epoch 67, Val Loss: 1.6447, Val Acc: 56.73%\n",
      "当前学习率: 0.000200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 68, Loss: 1.8375, Acc: 50.10%, CE: 1.8313, AttnReg: 0.6259: 100%|██████████| 625/625 [00:57<00:00, 10.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68/500, Train Loss: 1.8392, Train Acc: 50.08%\n",
      "Epoch 68, Val Loss: 1.5375, Val Acc: 56.73%\n",
      "当前学习率: 0.000200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 69, Loss: 1.8295, Acc: 50.58%, CE: 1.8229, AttnReg: 0.6556: 100%|██████████| 625/625 [00:57<00:00, 10.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69/500, Train Loss: 1.8273, Train Acc: 50.62%\n",
      "Epoch 69, Val Loss: 1.4909, Val Acc: 59.07%\n",
      "当前学习率: 0.000200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 70, Loss: 1.7663, Acc: 52.05%, CE: 1.7599, AttnReg: 0.6391: 100%|██████████| 625/625 [00:57<00:00, 10.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70/500, Train Loss: 1.7661, Train Acc: 52.02%\n",
      "Epoch 70, Val Loss: 1.6113, Val Acc: 53.68%\n",
      "当前学习率: 0.000200\n",
      "注意力权重可视化已保存到: ./attention_viz/attention_epoch_70.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 71, Loss: 1.8060, Acc: 50.99%, CE: 1.7995, AttnReg: 0.6564: 100%|██████████| 625/625 [00:58<00:00, 10.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/500, Train Loss: 1.8088, Train Acc: 50.94%\n",
      "Epoch 71, Val Loss: 1.4632, Val Acc: 59.96%\n",
      "当前学习率: 0.000200\n",
      "保存最佳模型，验证准确率: 59.96%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 72, Loss: 1.7989, Acc: 51.99%, CE: 1.7924, AttnReg: 0.6434: 100%|██████████| 625/625 [00:57<00:00, 10.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/500, Train Loss: 1.7974, Train Acc: 52.04%\n",
      "Epoch 72, Val Loss: 1.6409, Val Acc: 53.68%\n",
      "当前学习率: 0.000200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 73, Loss: 1.7730, Acc: 52.36%, CE: 1.7662, AttnReg: 0.6855: 100%|██████████| 625/625 [00:57<00:00, 10.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/500, Train Loss: 1.7783, Train Acc: 52.26%\n",
      "Epoch 73, Val Loss: 1.5379, Val Acc: 54.40%\n",
      "当前学习率: 0.000200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 74, Loss: 1.7543, Acc: 51.59%, CE: 1.7475, AttnReg: 0.6788: 100%|██████████| 625/625 [00:57<00:00, 10.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74/500, Train Loss: 1.7560, Train Acc: 51.56%\n",
      "Epoch 74, Val Loss: 1.5071, Val Acc: 57.63%\n",
      "当前学习率: 0.000200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 75, Loss: 1.7580, Acc: 51.57%, CE: 1.7513, AttnReg: 0.6743: 100%|██████████| 625/625 [00:57<00:00, 10.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75/500, Train Loss: 1.7585, Train Acc: 51.52%\n",
      "Epoch 75, Val Loss: 1.4991, Val Acc: 59.25%\n",
      "当前学习率: 0.000200\n",
      "注意力权重可视化已保存到: ./attention_viz/attention_epoch_75.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 76, Loss: 1.8024, Acc: 51.45%, CE: 1.7956, AttnReg: 0.6813: 100%|██████████| 625/625 [01:00<00:00, 10.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76/500, Train Loss: 1.8013, Train Acc: 51.50%\n",
      "Epoch 76, Val Loss: 1.4953, Val Acc: 57.99%\n",
      "当前学习率: 0.000200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 77, Loss: 1.7757, Acc: 51.99%, CE: 1.7688, AttnReg: 0.6881: 100%|██████████| 625/625 [00:57<00:00, 10.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77/500, Train Loss: 1.7747, Train Acc: 52.02%\n",
      "Epoch 77, Val Loss: 1.4489, Val Acc: 58.17%\n",
      "当前学习率: 0.000200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 78, Loss: 1.7751, Acc: 52.03%, CE: 1.7684, AttnReg: 0.6702: 100%|██████████| 625/625 [00:57<00:00, 10.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/500, Train Loss: 1.7744, Train Acc: 52.08%\n",
      "Epoch 78, Val Loss: 1.5143, Val Acc: 57.99%\n",
      "当前学习率: 0.000200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 79, Loss: 1.7381, Acc: 53.02%, CE: 1.7312, AttnReg: 0.6890: 100%|██████████| 625/625 [00:57<00:00, 10.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79/500, Train Loss: 1.7362, Train Acc: 53.04%\n",
      "Epoch 79, Val Loss: 1.5328, Val Acc: 56.37%\n",
      "当前学习率: 0.000200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 80, Loss: 1.7594, Acc: 52.13%, CE: 1.7524, AttnReg: 0.6903: 100%|██████████| 625/625 [00:57<00:00, 10.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/500, Train Loss: 1.7590, Train Acc: 52.18%\n",
      "Epoch 80, Val Loss: 1.3988, Val Acc: 60.68%\n",
      "当前学习率: 0.000200\n",
      "注意力权重可视化已保存到: ./attention_viz/attention_epoch_80.png\n",
      "保存最佳模型，验证准确率: 60.68%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 81, Loss: 1.7165, Acc: 53.42%, CE: 1.7096, AttnReg: 0.6861: 100%|██████████| 625/625 [01:03<00:00,  9.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/500, Train Loss: 1.7187, Train Acc: 53.34%\n",
      "Epoch 81, Val Loss: 1.4355, Val Acc: 59.43%\n",
      "当前学习率: 0.000200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 82, Loss: 1.7210, Acc: 53.70%, CE: 1.7141, AttnReg: 0.6857: 100%|██████████| 625/625 [00:59<00:00, 10.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82/500, Train Loss: 1.7204, Train Acc: 53.68%\n",
      "Epoch 82, Val Loss: 1.5482, Val Acc: 56.73%\n",
      "当前学习率: 0.000200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 83, Loss: 1.7024, Acc: 54.43%, CE: 1.6954, AttnReg: 0.6952: 100%|██████████| 625/625 [00:58<00:00, 10.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/500, Train Loss: 1.7007, Train Acc: 54.44%\n",
      "Epoch 83, Val Loss: 1.4442, Val Acc: 57.99%\n",
      "当前学习率: 0.000200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 84, Loss: 1.7371, Acc: 52.70%, CE: 1.7301, AttnReg: 0.7092: 100%|██████████| 625/625 [00:58<00:00, 10.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84/500, Train Loss: 1.7357, Train Acc: 52.74%\n",
      "Epoch 84, Val Loss: 1.6399, Val Acc: 56.19%\n",
      "当前学习率: 0.000200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 85, Loss: 1.7094, Acc: 53.70%, CE: 1.7023, AttnReg: 0.7081: 100%|██████████| 625/625 [00:57<00:00, 10.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/500, Train Loss: 1.7064, Train Acc: 53.76%\n",
      "Epoch 85, Val Loss: 1.4580, Val Acc: 60.50%\n",
      "当前学习率: 0.000200\n",
      "注意力权重可视化已保存到: ./attention_viz/attention_epoch_85.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 86, Loss: 1.7487, Acc: 52.70%, CE: 1.7416, AttnReg: 0.7099: 100%|██████████| 625/625 [01:05<00:00,  9.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86/500, Train Loss: 1.7463, Train Acc: 52.70%\n",
      "Epoch 86, Val Loss: 1.3705, Val Acc: 60.50%\n",
      "当前学习率: 0.000200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 87, Loss: 1.7140, Acc: 53.48%, CE: 1.7068, AttnReg: 0.7249: 100%|██████████| 625/625 [00:59<00:00, 10.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87/500, Train Loss: 1.7136, Train Acc: 53.52%\n",
      "Epoch 87, Val Loss: 1.3854, Val Acc: 61.76%\n",
      "当前学习率: 0.000200\n",
      "保存最佳模型，验证准确率: 61.76%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 88, Loss: 1.7190, Acc: 53.64%, CE: 1.7118, AttnReg: 0.7243: 100%|██████████| 625/625 [00:57<00:00, 10.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88/500, Train Loss: 1.7186, Train Acc: 53.66%\n",
      "Epoch 88, Val Loss: 1.4973, Val Acc: 57.99%\n",
      "当前学习率: 0.000200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 89, Loss: 1.7293, Acc: 53.48%, CE: 1.7219, AttnReg: 0.7387: 100%|██████████| 625/625 [00:57<00:00, 10.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89/500, Train Loss: 1.7300, Train Acc: 53.50%\n",
      "Epoch 89, Val Loss: 1.5469, Val Acc: 54.94%\n",
      "当前学习率: 0.000200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 90, Loss: 1.7076, Acc: 54.23%, CE: 1.7001, AttnReg: 0.7472: 100%|██████████| 625/625 [00:58<00:00, 10.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90/500, Train Loss: 1.7054, Train Acc: 54.20%\n",
      "Epoch 90, Val Loss: 1.4043, Val Acc: 58.89%\n",
      "当前学习率: 0.000200\n",
      "注意力权重可视化已保存到: ./attention_viz/attention_epoch_90.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 91, Loss: 1.6974, Acc: 53.66%, CE: 1.6899, AttnReg: 0.7447: 100%|██████████| 625/625 [01:09<00:00,  8.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91/500, Train Loss: 1.6938, Train Acc: 53.76%\n",
      "Epoch 91, Val Loss: 1.4112, Val Acc: 58.35%\n",
      "当前学习率: 0.000200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 92, Loss: 1.6910, Acc: 54.17%, CE: 1.6835, AttnReg: 0.7457: 100%|██████████| 625/625 [01:01<00:00, 10.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92/500, Train Loss: 1.6905, Train Acc: 54.14%\n",
      "Epoch 92, Val Loss: 1.4557, Val Acc: 57.63%\n",
      "当前学习率: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 93, Loss: 1.6498, Acc: 55.86%, CE: 1.6423, AttnReg: 0.7489: 100%|██████████| 625/625 [00:58<00:00, 10.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93/500, Train Loss: 1.6508, Train Acc: 55.84%\n",
      "Epoch 93, Val Loss: 1.3097, Val Acc: 59.96%\n",
      "当前学习率: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 94, Loss: 1.6649, Acc: 54.63%, CE: 1.6574, AttnReg: 0.7494: 100%|██████████| 625/625 [00:58<00:00, 10.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94/500, Train Loss: 1.6666, Train Acc: 54.58%\n",
      "Epoch 94, Val Loss: 1.3219, Val Acc: 61.94%\n",
      "当前学习率: 0.000100\n",
      "保存最佳模型，验证准确率: 61.94%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 95, Loss: 1.6629, Acc: 54.75%, CE: 1.6553, AttnReg: 0.7592: 100%|██████████| 625/625 [00:58<00:00, 10.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95/500, Train Loss: 1.6613, Train Acc: 54.86%\n",
      "Epoch 95, Val Loss: 1.5209, Val Acc: 56.91%\n",
      "当前学习率: 0.000100\n",
      "注意力权重可视化已保存到: ./attention_viz/attention_epoch_95.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 96, Loss: 1.6534, Acc: 54.95%, CE: 1.6459, AttnReg: 0.7517: 100%|██████████| 625/625 [00:57<00:00, 10.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96/500, Train Loss: 1.6542, Train Acc: 54.94%\n",
      "Epoch 96, Val Loss: 1.3890, Val Acc: 60.86%\n",
      "当前学习率: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 97, Loss: 1.6312, Acc: 55.70%, CE: 1.6238, AttnReg: 0.7488: 100%|██████████| 625/625 [00:57<00:00, 10.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97/500, Train Loss: 1.6337, Train Acc: 55.64%\n",
      "Epoch 97, Val Loss: 1.3640, Val Acc: 62.66%\n",
      "当前学习率: 0.000100\n",
      "保存最佳模型，验证准确率: 62.66%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 98, Loss: 1.6547, Acc: 55.35%, CE: 1.6470, AttnReg: 0.7680: 100%|██████████| 625/625 [00:57<00:00, 10.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98/500, Train Loss: 1.6524, Train Acc: 55.38%\n",
      "Epoch 98, Val Loss: 1.3329, Val Acc: 62.12%\n",
      "当前学习率: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 99, Loss: 1.6229, Acc: 54.51%, CE: 1.6152, AttnReg: 0.7751: 100%|██████████| 625/625 [00:57<00:00, 10.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99/500, Train Loss: 1.6237, Train Acc: 54.48%\n",
      "Epoch 99, Val Loss: 1.4090, Val Acc: 64.81%\n",
      "当前学习率: 0.000050\n",
      "保存最佳模型，验证准确率: 64.81%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 100, Loss: 1.6224, Acc: 55.39%, CE: 1.6147, AttnReg: 0.7697: 100%|██████████| 625/625 [00:57<00:00, 10.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/500, Train Loss: 1.6232, Train Acc: 55.42%\n",
      "Epoch 100, Val Loss: 1.3686, Val Acc: 63.02%\n",
      "当前学习率: 0.000050\n",
      "注意力权重可视化已保存到: ./attention_viz/attention_epoch_100.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 101, Loss: 1.5757, Acc: 57.29%, CE: 1.5681, AttnReg: 0.7589: 100%|██████████| 625/625 [00:57<00:00, 10.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 101/500, Train Loss: 1.5753, Train Acc: 57.32%\n",
      "Epoch 101, Val Loss: 1.5030, Val Acc: 58.17%\n",
      "当前学习率: 0.000050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 102, Loss: 1.5948, Acc: 56.20%, CE: 1.5871, AttnReg: 0.7710: 100%|██████████| 625/625 [00:57<00:00, 10.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 102/500, Train Loss: 1.5960, Train Acc: 56.18%\n",
      "Epoch 102, Val Loss: 1.4514, Val Acc: 58.35%\n",
      "当前学习率: 0.000050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 103, Loss: 1.6142, Acc: 56.14%, CE: 1.6065, AttnReg: 0.7647: 100%|██████████| 625/625 [00:57<00:00, 10.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 103/500, Train Loss: 1.6139, Train Acc: 56.12%\n",
      "Epoch 103, Val Loss: 1.3217, Val Acc: 62.12%\n",
      "当前学习率: 0.000050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 104, Loss: 1.5786, Acc: 57.25%, CE: 1.5708, AttnReg: 0.7798: 100%|██████████| 625/625 [00:58<00:00, 10.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 104/500, Train Loss: 1.5807, Train Acc: 57.22%\n",
      "Epoch 104, Val Loss: 1.3462, Val Acc: 62.12%\n",
      "当前学习率: 0.000050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 105, Loss: 1.6116, Acc: 56.02%, CE: 1.6038, AttnReg: 0.7815: 100%|██████████| 625/625 [00:58<00:00, 10.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 105/500, Train Loss: 1.6120, Train Acc: 55.98%\n",
      "Epoch 105, Val Loss: 1.3496, Val Acc: 61.76%\n",
      "当前学习率: 0.000025\n",
      "注意力权重可视化已保存到: ./attention_viz/attention_epoch_105.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 106, Loss: 1.6162, Acc: 55.84%, CE: 1.6082, AttnReg: 0.7962: 100%|██████████| 625/625 [00:57<00:00, 10.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 106/500, Train Loss: 1.6162, Train Acc: 55.86%\n",
      "Epoch 106, Val Loss: 1.4227, Val Acc: 58.53%\n",
      "当前学习率: 0.000025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 107, Loss: 1.5919, Acc: 56.52%, CE: 1.5840, AttnReg: 0.7851: 100%|██████████| 625/625 [00:57<00:00, 10.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 107/500, Train Loss: 1.5928, Train Acc: 56.48%\n",
      "Epoch 107, Val Loss: 1.4070, Val Acc: 58.71%\n",
      "当前学习率: 0.000025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 108, Loss: 1.6129, Acc: 55.68%, CE: 1.6049, AttnReg: 0.8004: 100%|██████████| 625/625 [00:57<00:00, 10.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 108/500, Train Loss: 1.6133, Train Acc: 55.68%\n",
      "Epoch 108, Val Loss: 1.3856, Val Acc: 62.12%\n",
      "当前学习率: 0.000025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 109, Loss: 1.5847, Acc: 55.78%, CE: 1.5768, AttnReg: 0.7901: 100%|██████████| 625/625 [00:57<00:00, 10.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 109/500, Train Loss: 1.5863, Train Acc: 55.74%\n",
      "Epoch 109, Val Loss: 1.2740, Val Acc: 63.20%\n",
      "当前学习率: 0.000025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 110, Loss: 1.5832, Acc: 57.02%, CE: 1.5753, AttnReg: 0.7954: 100%|██████████| 625/625 [01:09<00:00,  9.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 110/500, Train Loss: 1.5810, Train Acc: 57.06%\n",
      "Epoch 110, Val Loss: 1.4691, Val Acc: 58.17%\n",
      "当前学习率: 0.000025\n",
      "注意力权重可视化已保存到: ./attention_viz/attention_epoch_110.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 111, Loss: 1.5488, Acc: 58.15%, CE: 1.5409, AttnReg: 0.7898: 100%|██████████| 625/625 [00:58<00:00, 10.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 111/500, Train Loss: 1.5495, Train Acc: 58.06%\n",
      "Epoch 111, Val Loss: 1.2864, Val Acc: 61.76%\n",
      "当前学习率: 0.000025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 112, Loss: 1.6282, Acc: 55.84%, CE: 1.6201, AttnReg: 0.8134: 100%|██████████| 625/625 [00:57<00:00, 10.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/500, Train Loss: 1.6296, Train Acc: 55.80%\n",
      "Epoch 112, Val Loss: 1.5091, Val Acc: 58.53%\n",
      "当前学习率: 0.000025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 113, Loss: 1.6147, Acc: 55.90%, CE: 1.6067, AttnReg: 0.8010: 100%|██████████| 625/625 [00:58<00:00, 10.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 113/500, Train Loss: 1.6148, Train Acc: 55.94%\n",
      "Epoch 113, Val Loss: 1.2805, Val Acc: 64.09%\n",
      "当前学习率: 0.000025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 114, Loss: 1.6136, Acc: 56.10%, CE: 1.6057, AttnReg: 0.7920: 100%|██████████| 625/625 [00:58<00:00, 10.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 114/500, Train Loss: 1.6129, Train Acc: 56.18%\n",
      "Epoch 114, Val Loss: 1.3716, Val Acc: 63.55%\n",
      "当前学习率: 0.000025\n",
      "早停于第 114 轮\n",
      "训练历史可视化已保存到: ./checkpoints_T2/training_history.png\n",
      "创建评估器...\n",
      "评估模型...\n",
      "测试集准确率: 64.83%\n",
      "分析注意力模式...\n",
      "样本 0 (标签: 51): 平均熵=0.7785, 对角线强度=0.0020\n",
      "样本 1 (标签: 51): 平均熵=0.5801, 对角线强度=0.0016\n",
      "样本 2 (标签: 51): 平均熵=0.4537, 对角线强度=0.0023\n",
      "样本 3 (标签: 51): 平均熵=0.4665, 对角线强度=0.0023\n",
      "样本 4 (标签: 51): 平均熵=3.0330, 对角线强度=0.0036\n",
      "样本 5 (标签: 51): 平均熵=0.7846, 对角线强度=0.0021\n",
      "样本 6 (标签: 51): 平均熵=0.7193, 对角线强度=0.0040\n",
      "样本 7 (标签: 51): 平均熵=0.3430, 对角线强度=0.0037\n",
      "样本 8 (标签: 51): 平均熵=0.3234, 对角线强度=0.0015\n",
      "样本 9 (标签: 51): 平均熵=0.8505, 对角线强度=0.0026\n",
      "样本 10 (标签: 51): 平均熵=0.4510, 对角线强度=0.0022\n",
      "样本 11 (标签: 51): 平均熵=2.4415, 对角线强度=0.0033\n",
      "样本 12 (标签: 51): 平均熵=0.5113, 对角线强度=0.0016\n",
      "样本 13 (标签: 51): 平均熵=0.4706, 对角线强度=0.0026\n",
      "样本 14 (标签: 51): 平均熵=0.4680, 对角线强度=0.0027\n",
      "样本 15 (标签: 51): 平均熵=0.4532, 对角线强度=0.0044\n",
      "样本 16 (标签: 51): 平均熵=0.9774, 对角线强度=0.0020\n",
      "样本 17 (标签: 51): 平均熵=0.4740, 对角线强度=0.0026\n",
      "样本 18 (标签: 51): 平均熵=0.2884, 对角线强度=0.0030\n",
      "样本 19 (标签: 51): 平均熵=2.5718, 对角线强度=0.0038\n",
      "样本 20 (标签: 51): 平均熵=0.5861, 对角线强度=0.0014\n",
      "样本 21 (标签: 51): 平均熵=0.3658, 对角线强度=0.0025\n",
      "样本 22 (标签: 51): 平均熵=0.4294, 对角线强度=0.0019\n",
      "样本 23 (标签: 51): 平均熵=0.7894, 对角线强度=0.0030\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import os\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "# 训练器类\n",
    "class Trainer:\n",
    "    def __init__(self, config=Config, model=None):\n",
    "        \"\"\"初始化训练器\"\"\"\n",
    "        self.config = config\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        print(f\"使用设备: {self.device}\")\n",
    "\n",
    "        # 创建模型\n",
    "        if model is None:\n",
    "            raise ValueError(\"初始化Trainer时必须传入model参数\")\n",
    "        self.model = model.to(self.device)  # 使用传入的模型\n",
    "\n",
    "        # 定义损失函数\n",
    "        self.ce_loss = nn.CrossEntropyLoss()\n",
    "\n",
    "        # 定义优化器\n",
    "        self.optimizer = optim.Adam(\n",
    "            self.model.parameters(),\n",
    "            lr=config.LR,\n",
    "            weight_decay=config.WEIGHT_DECAY\n",
    "        )\n",
    "\n",
    "        # 学习率调度器\n",
    "        self.scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            self.optimizer,\n",
    "            mode='min',\n",
    "            factor=0.5,\n",
    "            patience=5,\n",
    "        )\n",
    "\n",
    "        # 学习率预热调度器\n",
    "        self.warmup_scheduler = optim.lr_scheduler.LambdaLR(\n",
    "            self.optimizer,\n",
    "            lr_lambda=lambda epoch: min(1.0, epoch / config.WARMUP_EPOCHS)\n",
    "        )\n",
    "\n",
    "        # 混合精度训练\n",
    "        if config.ENABLE_MIXED_PRECISION and torch.cuda.is_available():\n",
    "            self.scaler = torch.cuda.amp.GradScaler()\n",
    "            print(\"启用混合精度训练\")\n",
    "        else:\n",
    "            self.scaler = None\n",
    "\n",
    "        # 创建检查点目录和注意力可视化目录\n",
    "        os.makedirs(config.CHECKPOINT_DIR, exist_ok=True)\n",
    "        os.makedirs(config.ATTENTION_VIZ_DIR, exist_ok=True)\n",
    "\n",
    "        # 早停计数器\n",
    "        self.early_stop_counter = 0\n",
    "        self.best_val_accuracy = 0.0\n",
    "        print(f\"模型预期输入长度: {config.MAX_SEQ_LEN}\")\n",
    "\n",
    "        # 训练历史记录\n",
    "        self.train_history = {\n",
    "            'loss': [],\n",
    "            'accuracy': [],\n",
    "            'val_loss': [],\n",
    "            'val_accuracy': [],\n",
    "            'attention_entropy': []  # 新增：注意力熵记录\n",
    "        }\n",
    "\n",
    "    def attention_regularization(self, attention_weights):\n",
    "        \"\"\"\n",
    "        注意力正则化损失 - 鼓励注意力分布更加集中\n",
    "        :param attention_weights: 注意力权重 [batch_size, num_heads, seq_len, seq_len]\n",
    "        :return: 正则化损失\n",
    "        \"\"\"\n",
    "        # 计算注意力分布的熵\n",
    "        entropy = -torch.sum(attention_weights * torch.log(attention_weights + 1e-10), dim=-1)\n",
    "        mean_entropy = torch.mean(entropy)\n",
    "        \n",
    "        # 记录注意力熵\n",
    "        self.train_history['attention_entropy'].append(mean_entropy.item())\n",
    "        \n",
    "        return mean_entropy\n",
    "\n",
    "    def train_one_epoch(self, dataloader, epoch):\n",
    "        \"\"\"\n",
    "        训练一个epoch\n",
    "        :param dataloader: 训练数据加载器\n",
    "        :param epoch: 当前epoch\n",
    "        :return: 平均训练损失和准确率\n",
    "        \"\"\"\n",
    "        self.model.train()\n",
    "        total_loss = 0.0\n",
    "        total_ce_loss = 0.0\n",
    "        total_attn_reg_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        # 梯度累积\n",
    "        accumulation_steps = self.config.GRADIENT_ACCUMULATION_STEPS\n",
    "        self.optimizer.zero_grad()\n",
    "\n",
    "        progress_bar = tqdm(enumerate(dataloader), total=len(dataloader))\n",
    "        for i, (inputs, labels, attention_mask) in progress_bar:\n",
    "            try:\n",
    "                inputs, labels, attention_mask = inputs.to(self.device), labels.to(self.device), attention_mask.to(self.device)\n",
    "\n",
    "                # 确保输入维度正确 [batch, 1, seq_len]\n",
    "                if inputs.dim() == 2:  # [batch, seq_len]\n",
    "                    inputs = inputs.unsqueeze(1)  # 添加通道维度 -> [batch, 1, seq_len]\n",
    "\n",
    "                # 确保音频长度正确\n",
    "                if inputs.size(2) > self.config.MAX_SEQ_LEN:\n",
    "                    inputs = inputs[:, :, :self.config.MAX_SEQ_LEN]\n",
    "                    attention_mask = attention_mask[:, :self.config.MAX_SEQ_LEN]\n",
    "                elif inputs.size(2) < self.config.MAX_SEQ_LEN:\n",
    "                    pad_len = self.config.MAX_SEQ_LEN - inputs.size(2)\n",
    "                    inputs = torch.nn.functional.pad(inputs, (0, pad_len), value=0.0)\n",
    "                    # 更新注意力掩码\n",
    "                    attention_mask_padded = torch.ones(\n",
    "                        inputs.size(0), self.config.MAX_SEQ_LEN, \n",
    "                        device=inputs.device\n",
    "                    )\n",
    "                    attention_mask_padded[:, :attention_mask.size(1)] = attention_mask\n",
    "                    attention_mask = attention_mask_padded\n",
    "\n",
    "                # 使用混合精度训练\n",
    "                if self.scaler is not None:\n",
    "                    with torch.cuda.amp.autocast():\n",
    "                        # 前向传播 - 注意：复杂注意力模型返回三个值\n",
    "                        embeddings, logits, attention_weights = self.model(inputs, attention_mask)\n",
    "\n",
    "                        # 计算损失\n",
    "                        ce = self.ce_loss(logits, labels)\n",
    "                        attn_reg = self.attention_regularization(attention_weights)\n",
    "                        loss = (self.config.CE_WEIGHT * ce + \n",
    "                               self.config.ATTENTION_REG_WEIGHT * attn_reg)\n",
    "\n",
    "                        # 梯度累积\n",
    "                        loss = loss / accumulation_steps\n",
    "\n",
    "                    # 反向传播\n",
    "                    self.scaler.scale(loss).backward()\n",
    "\n",
    "                    # 梯度裁剪\n",
    "                    self.scaler.unscale_(self.optimizer)\n",
    "                    torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.config.GRAD_CLIP)\n",
    "\n",
    "                    if (i + 1) % accumulation_steps == 0:\n",
    "                        self.scaler.step(self.optimizer)  # 优化器步骤\n",
    "                        self.scaler.update()\n",
    "                        # 2. 再调用预热调度器\n",
    "                        if epoch <= self.config.WARMUP_EPOCHS:\n",
    "                            self.warmup_scheduler.step()\n",
    "                        self.optimizer.zero_grad()\n",
    "\n",
    "                else:\n",
    "                    # 标准训练（不使用混合精度）\n",
    "                    # 前向传播 - 注意：复杂注意力模型返回三个值\n",
    "                    embeddings, logits, attention_weights = self.model(inputs, attention_mask)\n",
    "\n",
    "                    # 计算损失\n",
    "                    ce = self.ce_loss(logits, labels)\n",
    "                    attn_reg = self.attention_regularization(attention_weights)\n",
    "                    loss = (self.config.CE_WEIGHT * ce + \n",
    "                           self.config.ATTENTION_REG_WEIGHT * attn_reg)\n",
    "\n",
    "                    # 梯度累积\n",
    "                    loss = loss / accumulation_steps\n",
    "                    loss.backward()\n",
    "\n",
    "                    # 梯度裁剪\n",
    "                    torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.config.GRAD_CLIP)\n",
    "\n",
    "                    if (i + 1) % accumulation_steps == 0:\n",
    "                        # 1. 先更新参数\n",
    "                        self.optimizer.step()\n",
    "                        # 2. 再调用学习率预热调度器（仅在预热阶段）\n",
    "                        if epoch <= self.config.WARMUP_EPOCHS:\n",
    "                            self.warmup_scheduler.step()  # 移动到optimizer.step()之后\n",
    "                        self.optimizer.zero_grad()\n",
    "\n",
    "                # 统计\n",
    "                total_loss += loss.item() * accumulation_steps\n",
    "                total_ce_loss += ce.item()\n",
    "                total_attn_reg_loss += attn_reg.item()\n",
    "                _, predicted = logits.max(1)\n",
    "                total += labels.size(0)\n",
    "                correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "                # 更新进度条\n",
    "                if i % 10 == 0:  # 减少更新频率\n",
    "                    accuracy = 100. * correct / total\n",
    "                    avg_loss = total_loss / (i + 1)\n",
    "                    progress_bar.set_description(\n",
    "                        f\"Epoch {epoch}, Loss: {avg_loss:.4f}, Acc: {accuracy:.2f}%, \"\n",
    "                        f\"CE: {total_ce_loss/(i+1):.4f}, AttnReg: {total_attn_reg_loss/(i+1):.4f}\"\n",
    "                    )\n",
    "\n",
    "                # 手动垃圾回收\n",
    "                if i % 50 == 0:\n",
    "                    torch.cuda.empty_cache()\n",
    "                    gc.collect()\n",
    "\n",
    "            except RuntimeError as e:\n",
    "                if \"out of memory\" in str(e):\n",
    "                    print(f\"内存不足错误在批次 {i}: {e}\")\n",
    "                    torch.cuda.empty_cache()\n",
    "                    gc.collect()\n",
    "                    continue\n",
    "                else:\n",
    "                    raise e\n",
    "\n",
    "        avg_loss = total_loss / len(dataloader)\n",
    "        accuracy = 100. * correct / total\n",
    "        return avg_loss, accuracy\n",
    "\n",
    "    def validate(self, dataloader):\n",
    "        \"\"\"\n",
    "        验证模型性能\n",
    "        :param dataloader: 验证数据加载器\n",
    "        :return: 验证损失和准确率\n",
    "        \"\"\"\n",
    "        self.model.eval()\n",
    "        total_loss = 0.0\n",
    "        total_ce_loss = 0.0\n",
    "        total_attn_reg_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        all_labels = []\n",
    "        all_predictions = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for i, (inputs, labels, attention_mask) in enumerate(dataloader):\n",
    "                try:\n",
    "                    inputs, labels, attention_mask = inputs.to(self.device), labels.to(self.device), attention_mask.to(self.device)\n",
    "\n",
    "                    # 确保输入维度正确 [batch, 1, seq_len]\n",
    "                    if inputs.dim() == 2:  # [batch, seq_len]\n",
    "                        inputs = inputs.unsqueeze(1)  # 添加通道维度 -> [batch, 1, seq_len]\n",
    "\n",
    "                    # 确保音频长度正确\n",
    "                    if inputs.size(2) > self.config.MAX_SEQ_LEN:\n",
    "                        inputs = inputs[:, :, :self.config.MAX_SEQ_LEN]\n",
    "                        attention_mask = attention_mask[:, :self.config.MAX_SEQ_LEN]\n",
    "                    elif inputs.size(2) < self.config.MAX_SEQ_LEN:\n",
    "                        pad_len = self.config.MAX_SEQ_LEN - inputs.size(2)\n",
    "                        inputs = torch.nn.functional.pad(inputs, (0, pad_len), value=0.0)\n",
    "                        # 更新注意力掩码\n",
    "                        attention_mask_padded = torch.ones(inputs.size(0), self.config.MAX_SEQ_LEN, device=inputs.device)\n",
    "                        attention_mask_padded[:, :attention_mask.size(1)] = attention_mask\n",
    "                        attention_mask = attention_mask_padded\n",
    "\n",
    "                    # 前向传播 - 注意：复杂注意力模型返回三个值\n",
    "                    embeddings, logits, attention_weights = self.model(inputs, attention_mask)\n",
    "\n",
    "                    # 计算损失\n",
    "                    ce = self.ce_loss(logits, labels)\n",
    "                    attn_reg = self.attention_regularization(attention_weights)\n",
    "                    loss = (self.config.CE_WEIGHT * ce + \n",
    "                           self.config.ATTENTION_REG_WEIGHT * attn_reg)\n",
    "\n",
    "                    total_loss += loss.item()\n",
    "                    total_ce_loss += ce.item()\n",
    "                    total_attn_reg_loss += attn_reg.item()\n",
    "\n",
    "                    # 统计准确率\n",
    "                    _, predicted = logits.max(1)\n",
    "                    total += labels.size(0)\n",
    "                    correct += predicted.eq(labels).sum().item()\n",
    "                    \n",
    "                    # 收集所有预测和标签用于混淆矩阵\n",
    "                    all_labels.extend(labels.cpu().numpy())\n",
    "                    all_predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "                    # 内存管理\n",
    "                    if i % 20 == 0:\n",
    "                        torch.cuda.empty_cache()\n",
    "                        gc.collect()\n",
    "\n",
    "                except RuntimeError as e:\n",
    "                    if \"out of memory\" in str(e):\n",
    "                        print(f\"验证时内存不足: {e}\")\n",
    "                        torch.cuda.empty_cache()\n",
    "                        gc.collect()\n",
    "                        continue\n",
    "                    else:\n",
    "                        raise e\n",
    "\n",
    "        avg_loss = total_loss / len(dataloader)\n",
    "        accuracy = 100. * correct / total\n",
    "        \n",
    "        # 计算混淆矩阵\n",
    "        cm = confusion_matrix(all_labels, all_predictions)\n",
    "        \n",
    "        return avg_loss, accuracy, cm\n",
    "\n",
    "    def visualize_attention(self, dataloader, epoch):\n",
    "        \"\"\"\n",
    "        可视化注意力权重\n",
    "        :param dataloader: 数据加载器\n",
    "        :param epoch: 当前epoch\n",
    "        \"\"\"\n",
    "        self.model.eval()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            # 获取一个批次的数据\n",
    "            inputs, labels, attention_mask = next(iter(dataloader))\n",
    "            inputs, labels, attention_mask = inputs.to(self.device), labels.to(self.device), attention_mask.to(self.device)\n",
    "            \n",
    "            # 确保输入维度正确\n",
    "            if inputs.dim() == 2:\n",
    "                inputs = inputs.unsqueeze(1)\n",
    "                \n",
    "            # 前向传播获取注意力权重\n",
    "            _, _, attention_weights = self.model(inputs, attention_mask)\n",
    "            \n",
    "            # 可视化注意力权重\n",
    "            try:\n",
    "                # 取第一个样本和第一个注意力头\n",
    "                attn = attention_weights[0, 0].cpu().numpy()\n",
    "                \n",
    "                plt.figure(figsize=(10, 8))\n",
    "                sns.heatmap(attn, cmap='viridis')\n",
    "                plt.title(f\"Attention Weights - Epoch {epoch}\")\n",
    "                plt.xlabel(\"Key Position\")\n",
    "                plt.ylabel(\"Query Position\")\n",
    "                \n",
    "                # 保存图像\n",
    "                save_path = os.path.join(self.config.ATTENTION_VIZ_DIR, f\"attention_epoch_{epoch}.png\")\n",
    "                plt.savefig(save_path)\n",
    "                plt.close()\n",
    "                \n",
    "                print(f\"注意力权重可视化已保存到: {save_path}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"注意力可视化失败: {e}\")\n",
    "\n",
    "    def plot_training_history(self):\n",
    "        \"\"\"绘制训练历史\"\"\"\n",
    "        try:\n",
    "            # 创建子图\n",
    "            fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "            \n",
    "            # 绘制损失曲线\n",
    "            axes[0, 0].plot(self.train_history['loss'], label='Training Loss')\n",
    "            axes[0, 0].plot(self.train_history['val_loss'], label='Validation Loss')\n",
    "            axes[0, 0].set_title('Loss Curve')\n",
    "            axes[0, 0].set_xlabel('Epoch')\n",
    "            axes[0, 0].set_ylabel('Loss')\n",
    "            axes[0, 0].legend()\n",
    "            axes[0, 0].grid(True)\n",
    "            \n",
    "            # 绘制准确率曲线\n",
    "            axes[0, 1].plot(self.train_history['accuracy'], label='Training Accuracy')\n",
    "            axes[0, 1].plot(self.train_history['val_accuracy'], label='Validation Accuracy')\n",
    "            axes[0, 1].set_title('Accuracy Curve')\n",
    "            axes[0, 1].set_xlabel('Epoch')\n",
    "            axes[0, 1].set_ylabel('Accuracy (%)')\n",
    "            axes[0, 1].legend()\n",
    "            axes[0, 1].grid(True)\n",
    "            \n",
    "            # 绘制注意力熵曲线\n",
    "            axes[1, 0].plot(self.train_history['attention_entropy'])\n",
    "            axes[1, 0].set_title('Attention Entropy')\n",
    "            axes[1, 0].set_xlabel('Epoch')\n",
    "            axes[1, 0].set_ylabel('Entropy')\n",
    "            axes[1, 0].grid(True)\n",
    "            \n",
    "            # 留空用于其他可视化\n",
    "            axes[1, 1].axis('off')\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            \n",
    "            # 保存图像\n",
    "            save_path = os.path.join(self.config.CHECKPOINT_DIR, \"training_history.png\")\n",
    "            plt.savefig(save_path)\n",
    "            plt.close()\n",
    "            \n",
    "            print(f\"训练历史可视化已保存到: {save_path}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"训练历史可视化失败: {e}\")\n",
    "\n",
    "    def train(self, train_dataloader, val_dataloader):\n",
    "        \"\"\"\n",
    "        完整训练流程\n",
    "        :param train_dataloader: 训练数据加载器\n",
    "        :param val_dataloader: 验证数据加载器\n",
    "        \"\"\"\n",
    "        print(\"开始训练T2模型（简化模型+复杂注意力）...\")\n",
    "        print(f\"训练集批次数: {len(train_dataloader)}, 验证集批次数: {len(val_dataloader)}\")\n",
    "\n",
    "        for epoch in range(1, self.config.EPOCHS + 1):\n",
    "            try:\n",
    "                # 应用学习率预热\n",
    "                if epoch <= self.config.WARMUP_EPOCHS:\n",
    "                    self.warmup_scheduler.step()\n",
    "\n",
    "                # 训练一个epoch\n",
    "                train_loss, train_acc = self.train_one_epoch(train_dataloader, epoch)\n",
    "                self.train_history['loss'].append(train_loss)\n",
    "                self.train_history['accuracy'].append(train_acc)\n",
    "                \n",
    "                print(f\"Epoch {epoch}/{self.config.EPOCHS}, Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%\")\n",
    "\n",
    "                # 验证\n",
    "                val_loss, val_acc, val_cm = self.validate(val_dataloader)\n",
    "                self.train_history['val_loss'].append(val_loss)\n",
    "                self.train_history['val_accuracy'].append(val_acc)\n",
    "                \n",
    "                print(f\"Epoch {epoch}, Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%\")\n",
    "\n",
    "                # 更新学习率\n",
    "                self.scheduler.step(val_loss)\n",
    "                current_lr = self.optimizer.param_groups[0]['lr']\n",
    "                print(f\"当前学习率: {current_lr:.6f}\")\n",
    "\n",
    "                # 定期可视化注意力权重\n",
    "                if epoch % self.config.ATTENTION_VIZ_INTERVAL == 0:\n",
    "                    self.visualize_attention(val_dataloader, epoch)\n",
    "\n",
    "                # 早停检查 (基于验证准确率)\n",
    "                if val_acc > self.best_val_accuracy + self.config.MIN_DELTA:\n",
    "                    self.best_val_accuracy = val_acc\n",
    "                    self.early_stop_counter = 0\n",
    "                    # 保存最佳模型\n",
    "                    torch.save({\n",
    "                        'epoch': epoch,\n",
    "                        'model_state_dict': self.model.state_dict(),\n",
    "                        'optimizer_state_dict': self.optimizer.state_dict(),\n",
    "                        'val_loss': val_loss,\n",
    "                        'val_accuracy': val_acc,\n",
    "                        'confusion_matrix': val_cm\n",
    "                    }, os.path.join(self.config.CHECKPOINT_DIR, 'best_model.pth'))\n",
    "                    print(f\"保存最佳模型，验证准确率: {val_acc:.2f}%\")\n",
    "                else:\n",
    "                    self.early_stop_counter += 1\n",
    "                    if self.early_stop_counter >= self.config.PATIENCE:\n",
    "                        print(f\"早停于第 {epoch} 轮\")\n",
    "                        break\n",
    "\n",
    "                # 定期保存模型\n",
    "                if epoch % self.config.SAVE_INTERVAL == 0:\n",
    "                    torch.save({\n",
    "                        'epoch': epoch,\n",
    "                        'model_state_dict': self.model.state_dict(),\n",
    "                        'optimizer_state_dict': self.optimizer.state_dict(),\n",
    "                        'train_loss': train_loss,\n",
    "                        'train_accuracy': train_acc,\n",
    "                        'confusion_matrix': val_cm\n",
    "                    }, os.path.join(self.config.CHECKPOINT_DIR, f'model_epoch_{epoch}.pth'))\n",
    "\n",
    "                # 清理内存\n",
    "                torch.cuda.empty_cache()\n",
    "                gc.collect()\n",
    "\n",
    "            except KeyboardInterrupt:\n",
    "                print(\"训练被用户中断\")\n",
    "                break\n",
    "            except Exception as e:\n",
    "                print(f\"训练错误: {e}\")\n",
    "                torch.cuda.empty_cache()\n",
    "                gc.collect()\n",
    "                continue\n",
    "\n",
    "        # 训练完成后绘制训练历史\n",
    "        self.plot_training_history()\n",
    "\n",
    "    def load_checkpoint(self, checkpoint_path):\n",
    "        \"\"\"\n",
    "        加载检查点\n",
    "        :param checkpoint_path: 检查点路径\n",
    "        \"\"\"\n",
    "        checkpoint = torch.load(checkpoint_path, map_location=self.device)\n",
    "        self.model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        if 'optimizer_state_dict' in checkpoint:\n",
    "            self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        epoch = checkpoint.get('epoch', 0)\n",
    "        print(f\"从第 {epoch} 轮加载检查点\")\n",
    "        return epoch\n",
    "\n",
    "\n",
    "# 评估器类\n",
    "class Evaluator:\n",
    "    def __init__(self, model, config=Config):\n",
    "        \"\"\"初始化评估器\"\"\"\n",
    "        self.model = model\n",
    "        self.config = config\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.model.to(self.device)\n",
    "        self.model.eval()\n",
    "\n",
    "    def evaluate_accuracy(self, dataloader):\n",
    "        \"\"\"\n",
    "        评估模型准确率\n",
    "        :param dataloader: 数据加载器\n",
    "        :return: 准确率\n",
    "        \"\"\"\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for i, (inputs, labels, attention_mask) in enumerate(dataloader):\n",
    "                try:\n",
    "                    inputs, labels, attention_mask = inputs.to(self.device), labels.to(self.device), attention_mask.to(self.device)\n",
    "\n",
    "                    # 确保输入维度正确\n",
    "                    if inputs.dim() == 2:  # [batch, seq_len]\n",
    "                        inputs = inputs.unsqueeze(1)  # 添加通道维度 -> [batch, 1, seq_len]\n",
    "\n",
    "                    # 截断过长的序列\n",
    "                    if inputs.size(2) > self.config.MAX_SEQ_LEN:\n",
    "                        inputs = inputs[:, :, :self.config.MAX_SEQ_LEN]\n",
    "                        attention_mask = attention_mask[:, :self.config.MAX_SEQ_LEN]\n",
    "\n",
    "                    # 前向传播 - 注意：复杂注意力模型返回三个值\n",
    "                    _, logits, _ = self.model(inputs, attention_mask)\n",
    "                    _, predicted = logits.max(1)\n",
    "                    total += labels.size(0)\n",
    "                    correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "                    # 内存管理\n",
    "                    if i % 20 == 0:\n",
    "                        torch.cuda.empty_cache()\n",
    "                        gc.collect()\n",
    "\n",
    "                except RuntimeError as e:\n",
    "                    if \"out of memory\" in str(e):\n",
    "                        print(f\"评估时内存不足: {e}\")\n",
    "                        torch.cuda.empty_cache()\n",
    "                        gc.collect()\n",
    "                        continue\n",
    "                    else:\n",
    "                        raise e\n",
    "\n",
    "        accuracy = 100. * correct / total\n",
    "        return accuracy\n",
    "\n",
    "    def analyze_attention_patterns(self, dataloader, num_samples=5):\n",
    "        \"\"\"\n",
    "        分析注意力模式\n",
    "        :param dataloader: 数据加载器\n",
    "        :param num_samples: 分析的样本数量\n",
    "        :return: 注意力模式分析结果\n",
    "        \"\"\"\n",
    "        self.model.eval()\n",
    "        attention_patterns = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for i, (inputs, labels, attention_mask) in enumerate(dataloader):\n",
    "                if i >= num_samples:\n",
    "                    break\n",
    "                    \n",
    "                inputs, labels, attention_mask = inputs.to(self.device), labels.to(self.device), attention_mask.to(self.device)\n",
    "                \n",
    "                # 确保输入维度正确\n",
    "                if inputs.dim() == 2:\n",
    "                    inputs = inputs.unsqueeze(1)\n",
    "                    \n",
    "                # 前向传播获取注意力权重\n",
    "                _, _, attention_weights = self.model(inputs, attention_mask)\n",
    "                \n",
    "                # 分析注意力模式\n",
    "                for j in range(attention_weights.size(0)):  # 遍历批次中的每个样本\n",
    "                    sample_attention = attention_weights[j]\n",
    "                    \n",
    "                    # 计算注意力集中度（每个头的平均熵）\n",
    "                    attention_entropy = -torch.sum(sample_attention * torch.log(sample_attention + 1e-10), dim=-1)\n",
    "                    mean_entropy = torch.mean(attention_entropy).item()\n",
    "                    \n",
    "                    # 计算注意力对角线强度（关注局部模式的程度）\n",
    "                    diag_strength = torch.mean(torch.diagonal(sample_attention, dim1=-2, dim2=-1)).item()\n",
    "                    \n",
    "                    attention_patterns.append({\n",
    "                        'sample_id': i * self.config.BATCH_SIZE + j,\n",
    "                        'label': labels[j].item(),\n",
    "                        'mean_entropy': mean_entropy,\n",
    "                        'diag_strength': diag_strength,\n",
    "                        'attention_weights': sample_attention.cpu().numpy()\n",
    "                    })\n",
    "        \n",
    "        return attention_patterns\n",
    "\n",
    "\n",
    "# 内存友好的数据加载器创建函数\n",
    "def create_small_dataloaders(dataset_name, batch_size=4):\n",
    "    \"\"\"创建小批次的数据加载器以节省内存\"\"\"\n",
    "    try:\n",
    "        train_dataset = SpeakerRecognitionDataset(split=\"train\")\n",
    "        val_dataset = SpeakerRecognitionDataset(split=\"val\")\n",
    "        test_dataset = SpeakerRecognitionDataset(split=\"test\")\n",
    "\n",
    "        return {\n",
    "            \"train\": DataLoader(train_dataset, batch_size=batch_size, shuffle=True,\n",
    "                                num_workers=0, pin_memory=False),\n",
    "            \"val\": DataLoader(val_dataset, batch_size=batch_size, shuffle=False,\n",
    "                              num_workers=0, pin_memory=False),\n",
    "            \"test\": DataLoader(test_dataset, batch_size=batch_size, shuffle=False,\n",
    "                               num_workers=0, pin_memory=False),\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"数据加载器创建错误: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# 测试代码\n",
    "if __name__ == \"__main__\":\n",
    "    # 设置较小的批次大小\n",
    "    batch_size = Config.BATCH_SIZE\n",
    "\n",
    "    print(\"创建数据加载器...\")\n",
    "    try:\n",
    "        # 使用内存友好的数据加载器\n",
    "        dataloaders = create_small_dataloaders(\"librispeech\", batch_size=batch_size)\n",
    "\n",
    "        if dataloaders is None:\n",
    "            print(\"无法创建数据加载器，退出\")\n",
    "            exit(1)\n",
    "\n",
    "        print(f\"训练集批次数: {len(dataloaders['train'])}\")\n",
    "        print(f\"验证集批次数: {len(dataloaders['val'])}\")\n",
    "        print(f\"测试集批次数: {len(dataloaders['test'])}\")\n",
    "\n",
    "        # 关键修改：从训练集中获取实际说话人数量（类别数）\n",
    "        num_speakers = len(dataloaders[\"train\"].dataset.speaker_to_idx)\n",
    "        print(f\"数据集中实际说话人数量（类别数）: {num_speakers}\")\n",
    "\n",
    "        # 创建训练器前，先初始化模型并传入正确的num_classes\n",
    "        print(\"创建模型和训练器...\")\n",
    "        \n",
    "        config = Config()\n",
    "        # 1. 初始化模型（传入正确的num_classes）\n",
    "        model = CHiLAPModel(num_classes=num_speakers)\n",
    "        # 2. 将模型传入Trainer，确保优化器初始化时模型已存在\n",
    "        trainer = Trainer(config=config, model=model)  # 传入model参数\n",
    "\n",
    "        # 测试一个批次\n",
    "        print(\"测试前向传播...\")\n",
    "        try:\n",
    "            # 注意：现在数据加载器返回三个值（输入、标签、注意力掩码）\n",
    "            x, y, mask = next(iter(dataloaders[\"train\"]))\n",
    "            print(f\"原始输入形状: {x.shape}, 标签形状: {y.shape}, 掩码形状: {mask.shape}\")\n",
    "\n",
    "            # 处理输入维度\n",
    "            if x.dim() == 2:  # [batch, seq_len]\n",
    "                x = x.unsqueeze(1)  # 添加通道维度 -> [batch, 1, seq_len]\n",
    "\n",
    "            # 确保音频长度正确\n",
    "            if x.size(2) > Config.MAX_SEQ_LEN:\n",
    "                x = x[:, :, :Config.MAX_SEQ_LEN]\n",
    "                mask = mask[:, :Config.MAX_SEQ_LEN]\n",
    "            elif x.size(2) < Config.MAX_SEQ_LEN:\n",
    "                pad_len = Config.MAX_SEQ_LEN - x.size(2)\n",
    "                x = torch.nn.functional.pad(x, (0, pad_len), value=0.0)\n",
    "                # 更新注意力掩码\n",
    "                mask_padded = torch.ones(x.size(0), Config.MAX_SEQ_LEN)\n",
    "                mask_padded[:, :mask.size(1)] = mask\n",
    "                mask = mask_padded\n",
    "\n",
    "            print(f\"处理后输入形状: {x.shape}, 掩码形状: {mask.shape}\")\n",
    "\n",
    "            x = x.to(trainer.device)\n",
    "            y = y.to(trainer.device)\n",
    "            mask = mask.to(trainer.device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                embeddings, logits, attention_weights = trainer.model(x, mask)\n",
    "                print(f\"嵌入形状: {embeddings.shape}, 输出形状: {logits.shape}, 注意力权重形状: {attention_weights.shape}\")\n",
    "                print(\"前向传播测试成功!\")\n",
    "        except Exception as e:\n",
    "            print(f\"前向传播测试失败: {e}\")\n",
    "            import traceback\n",
    "\n",
    "            traceback.print_exc()\n",
    "            exit(1)\n",
    "\n",
    "        # 开始训练\n",
    "        print(\"开始训练...\")\n",
    "        trainer.train(dataloaders[\"train\"], dataloaders[\"val\"])\n",
    "\n",
    "        # 创建评估器\n",
    "        print(\"创建评估器...\")\n",
    "        evaluator = Evaluator(trainer.model)\n",
    "\n",
    "        # 评估模型\n",
    "        print(\"评估模型...\")\n",
    "        test_accuracy = evaluator.evaluate_accuracy(dataloaders[\"test\"])\n",
    "        print(f\"测试集准确率: {test_accuracy:.2f}%\")\n",
    "        \n",
    "        # 分析注意力模式\n",
    "        print(\"分析注意力模式...\")\n",
    "        attention_patterns = evaluator.analyze_attention_patterns(dataloaders[\"test\"], num_samples=3)\n",
    "        for pattern in attention_patterns:\n",
    "            print(f\"样本 {pattern['sample_id']} (标签: {pattern['label']}): \"\n",
    "                  f\"平均熵={pattern['mean_entropy']:.4f}, 对角线强度={pattern['diag_strength']:.4f}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"程序执行错误: {e}\")\n",
    "        import traceback\n",
    "\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3704e3-e638-414e-9e15-e24cee0f78e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
