{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02affe59-bed6-439e-a391-fa972bb92cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "class Config:\n",
    "    # 数据加载器配置\n",
    "    DEBUG_MODE = True\n",
    "    DEBUG_SAMPLE_SIZE = 5000\n",
    "    BASE_DIR = os.getcwd()\n",
    "    LIBRISPEECH_PATH = os.path.join(BASE_DIR, \"devDataset\", \"LibriSpeech\")\n",
    "    SAMPLE_RATE = 16000\n",
    "    DURATION = 1.0\n",
    "    MAX_SAMPLES = int(SAMPLE_RATE * DURATION)\n",
    "    NOISE_TYPES = [\"white\", \"babble\"]\n",
    "    SNR_LEVELS = [0, 5, 10]\n",
    "    BATCH_SIZE = 16\n",
    "    NUM_WORKERS = 2\n",
    "    VALID_RATIO = 0.1\n",
    "    MAX_SEQ_LEN = 16000\n",
    "    \n",
    "    # 模型配置\n",
    "    INPUT_DIM = 1\n",
    "    HIDDEN_DIM = 256\n",
    "    EMBEDDING_DIM = 128\n",
    "    CHAOS_DIM = 64\n",
    "    CHAOS_TIME_STEPS = 5\n",
    "    ATTENTION_HEADS = 4\n",
    "    \n",
    "    # 训练配置\n",
    "    EPOCHS = 500\n",
    "    LR = 0.01\n",
    "    LR_DECAY = 0.95\n",
    "    WEIGHT_DECAY = 1e-5\n",
    "    SAVE_INTERVAL = 10\n",
    "    VAL_INTERVAL = 1\n",
    "    CHECKPOINT_DIR = \"../checkpoints_T3\"\n",
    "    WARMUP_EPOCHS = 5\n",
    "    GRAD_CLIP = 1.0\n",
    "    CE_WEIGHT = 1.0\n",
    "    PATIENCE = 10\n",
    "    MIN_DELTA = 0.001\n",
    "    GRADIENT_ACCUMULATION_STEPS = 4\n",
    "    ENABLE_MIXED_PRECISION = False\n",
    "\n",
    "    # 池化机制特定参数\n",
    "    POOLING_OUTPUT_DIM = 128  # 池化后的输出维度\n",
    "    POOLING_ATTRACTOR_DIM = 3  # 吸引子空间维度\n",
    "    POOLING_MIN_SEQ_LEN = 100  # 池化要求的最小序列长度\n",
    "    \n",
    "    # 特征提取参数\n",
    "    FEATURE_SCALES = [1, 2, 4]  # 多尺度特征提取\n",
    "    FEATURE_DIM = 64  # 特征维度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65b17bbb-0d7d-4a8a-8c59-996b138267b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "测试数据加载器...\n",
      "加载LibriSpeech数据集: /users/tianyuey/Project/devDataset/LibriSpeech\n",
      "处理子集: dev-clean\n",
      "在 dev-clean 中找到 2703 个.flac文件\n",
      "处理子集: dev-other\n",
      "在 dev-other 中找到 5567 个.flac文件\n",
      "找到 73 个不同的说话人\n",
      "有效文件: 5000/5000\n",
      "移除 0 个无效文件\n",
      "找到 73 个不同的说话人\n",
      "最终 train 数据集大小: 5000 个样本\n",
      "加载LibriSpeech数据集: /users/tianyuey/Project/devDataset/LibriSpeech\n",
      "处理子集: dev-clean\n",
      "在 dev-clean 中找到 2703 个.flac文件\n",
      "处理子集: dev-other\n",
      "在 dev-other 中找到 5567 个.flac文件\n",
      "找到 73 个不同的说话人\n",
      "有效文件: 557/557\n",
      "移除 0 个无效文件\n",
      "找到 73 个不同的说话人\n",
      "最终 val 数据集大小: 557 个样本\n",
      "加载LibriSpeech数据集: /users/tianyuey/Project/devDataset/LibriSpeech\n",
      "处理子集: dev-clean\n",
      "在 dev-clean 中找到 2703 个.flac文件\n",
      "处理子集: dev-other\n",
      "在 dev-other 中找到 5567 个.flac文件\n",
      "找到 73 个不同的说话人\n",
      "有效文件: 5567/5567\n",
      "移除 0 个无效文件\n",
      "找到 73 个不同的说话人\n",
      "最终 test 数据集大小: 5567 个样本\n",
      "加载LibriSpeech数据集: /users/tianyuey/Project/devDataset/LibriSpeech\n",
      "处理子集: dev-clean\n",
      "在 dev-clean 中找到 2703 个.flac文件\n",
      "处理子集: dev-other\n",
      "在 dev-other 中找到 5567 个.flac文件\n",
      "找到 73 个不同的说话人\n",
      "有效文件: 5567/5567\n",
      "移除 0 个无效文件\n",
      "找到 73 个不同的说话人\n",
      "最终 test 数据集大小: 5567 个样本\n",
      "训练集: 5000 样本\n",
      "验证集: 557 样本\n",
      "测试集: 5567 样本\n",
      "带噪声测试集: 5567 样本\n",
      "总说话人数: 73\n",
      "音频数据形状: torch.Size([16, 16000])\n",
      "标签数据形状: torch.Size([16])\n",
      "多尺度特征形状: torch.Size([16, 128])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import librosa\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import librosa\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import soundfile as sf\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# 噪声生成与注入\n",
    "class NoiseInjector:\n",
    "    @staticmethod\n",
    "    def generate_white_noise(length):\n",
    "        return np.random.randn(length).astype(np.float32)\n",
    "\n",
    "    @staticmethod\n",
    "    def generate_babble_noise(length, num_speakers=3):\n",
    "        noise = np.zeros(length, dtype=np.float32)\n",
    "        for _ in range(num_speakers):\n",
    "            start = random.randint(0, max(0, length - Config.SAMPLE_RATE))\n",
    "            end = min(start + Config.SAMPLE_RATE, length)\n",
    "            noise[start:end] += np.random.randn(end - start).astype(np.float32)\n",
    "        return noise / num_speakers\n",
    "\n",
    "    @staticmethod\n",
    "    def add_noise(signal, noise_type=\"white\", snr_db=10):\n",
    "        if len(signal) == 0:\n",
    "            return signal\n",
    "\n",
    "        signal_power = np.mean(signal ** 2)\n",
    "        if signal_power < 1e-10:\n",
    "            return signal\n",
    "\n",
    "        signal_db = 10 * np.log10(signal_power)\n",
    "\n",
    "        if noise_type == \"white\":\n",
    "            noise = NoiseInjector.generate_white_noise(len(signal))\n",
    "        elif noise_type == \"babble\":\n",
    "            noise = NoiseInjector.generate_babble_noise(len(signal))\n",
    "        else:\n",
    "            raise ValueError(f\"不支持的噪声类型：{noise_type}\")\n",
    "\n",
    "        noise_power = np.mean(noise ** 2)\n",
    "        noise_db = -100 if noise_power < 1e-10 else 10 * np.log10(noise_power)\n",
    "\n",
    "        target_noise_db = signal_db - snr_db\n",
    "        noise_scale = 10 ** ((target_noise_db - noise_db) / 20)\n",
    "        noisy_signal = signal + noise * noise_scale\n",
    "\n",
    "        # 归一化\n",
    "        max_val = np.max(np.abs(noisy_signal))\n",
    "        if max_val > 1e-5:\n",
    "            noisy_signal = noisy_signal / max_val\n",
    "\n",
    "        return noisy_signal\n",
    "\n",
    "# 数据集类\n",
    "class SpeakerRecognitionDataset(Dataset):\n",
    "    def __init__(self, split=\"train\", add_noise=False, noise_type=\"white\", snr_db=10):\n",
    "        self.split = split\n",
    "        self.add_noise = add_noise\n",
    "        self.noise_type = noise_type\n",
    "        self.snr_db = snr_db\n",
    "\n",
    "        # 加载数据集\n",
    "        self.audio_paths, self.labels = self._load_dataset()\n",
    "        self.speaker_to_idx = self._build_speaker_map()\n",
    "\n",
    "        # 调试模式\n",
    "        if Config.DEBUG_MODE:\n",
    "            if split == \"train\":\n",
    "                self.audio_paths = self.audio_paths[:Config.DEBUG_SAMPLE_SIZE]\n",
    "                self.labels = self.labels[:Config.DEBUG_SAMPLE_SIZE]\n",
    "            elif split == \"val\":\n",
    "                self.audio_paths = self.audio_paths[:min(Config.DEBUG_SAMPLE_SIZE // 2, len(self.audio_paths))]\n",
    "                self.labels = self.labels[:min(Config.DEBUG_SAMPLE_SIZE // 2, len(self.labels))]\n",
    "\n",
    "        # 验证数据集\n",
    "        self._validate_dataset()\n",
    "        print(f\"最终 {split} 数据集大小: {len(self.audio_paths)} 个样本\")\n",
    "\n",
    "    def _load_dataset(self):\n",
    "        audio_paths = []\n",
    "        labels = []\n",
    "\n",
    "        root = Config.LIBRISPEECH_PATH\n",
    "        if not os.path.exists(root):\n",
    "            print(f\"错误: LibriSpeech路径不存在 - {root}\")\n",
    "            return [], []\n",
    "\n",
    "        print(f\"加载LibriSpeech数据集: {root}\")\n",
    "\n",
    "        # 只遍历 dev-clean 和 dev-other\n",
    "        for subset_dir in [\"dev-clean\", \"dev-other\"]:\n",
    "            subset_path = os.path.join(root, subset_dir)\n",
    "            if not os.path.isdir(subset_path):\n",
    "                continue\n",
    "\n",
    "            print(f\"处理子集: {subset_dir}\")\n",
    "            for speaker_dir in os.listdir(subset_path):\n",
    "                speaker_path = os.path.join(subset_path, speaker_dir)\n",
    "                if not os.path.isdir(speaker_path):\n",
    "                    continue\n",
    "\n",
    "                for chapter_dir in os.listdir(speaker_path):\n",
    "                    chapter_path = os.path.join(speaker_path, chapter_dir)\n",
    "                    if not os.path.isdir(chapter_path):\n",
    "                        continue\n",
    "\n",
    "                    for file in os.listdir(chapter_path):\n",
    "                        if file.endswith(\".flac\"):\n",
    "                            full_path = os.path.join(chapter_path, file)\n",
    "                            audio_paths.append(full_path)\n",
    "                            labels.append(speaker_dir)\n",
    "\n",
    "            print(f\"在 {subset_dir} 中找到 {len(audio_paths)} 个.flac文件\")\n",
    "\n",
    "        # 分割训练/验证\n",
    "        if self.split != \"test\" and len(audio_paths) > 0:\n",
    "            train_paths, val_paths, train_labels, val_labels = train_test_split(\n",
    "                audio_paths, labels, test_size=Config.VALID_RATIO, random_state=42\n",
    "            )\n",
    "            if self.split == \"train\":\n",
    "                return train_paths, train_labels\n",
    "            else:\n",
    "                return val_paths, val_labels\n",
    "\n",
    "        return audio_paths, labels\n",
    "\n",
    "    def _build_speaker_map(self):\n",
    "        unique_speakers = sorted(set(self.labels))\n",
    "        print(f\"找到 {len(unique_speakers)} 个不同的说话人\")\n",
    "        return {speaker: idx for idx, speaker in enumerate(unique_speakers)}\n",
    "\n",
    "    def _validate_dataset(self):\n",
    "        if len(self.audio_paths) == 0:\n",
    "            print(f\"警告: {self.split}数据集为空\")\n",
    "            return\n",
    "\n",
    "        valid_count = 0\n",
    "        invalid_indices = []\n",
    "        for i in range(len(self.audio_paths) - 1, -1, -1):\n",
    "            path = self.audio_paths[i]\n",
    "            try:\n",
    "                if not os.path.exists(path):\n",
    "                    raise FileNotFoundError(\"文件不存在\")\n",
    "\n",
    "                if os.path.getsize(path) < 1024:\n",
    "                    raise ValueError(\"文件太小可能已损坏\")\n",
    "\n",
    "                if path.endswith('.flac'):\n",
    "                    signal, sr = sf.read(path)\n",
    "                else:\n",
    "                    signal, sr = librosa.load(path, sr=Config.SAMPLE_RATE, mono=True)\n",
    "\n",
    "                if len(signal) < Config.SAMPLE_RATE // 2:\n",
    "                    raise ValueError(\"音频过短\")\n",
    "\n",
    "                if np.max(np.abs(signal)) < 1e-5:\n",
    "                    raise ValueError(\"接近静音\")\n",
    "\n",
    "                valid_count += 1\n",
    "            except Exception as e:\n",
    "                invalid_indices.append(i)\n",
    "                print(f\"无效文件: {path} - {str(e)}\")\n",
    "\n",
    "        for i in invalid_indices:\n",
    "            self.audio_paths.pop(i)\n",
    "            self.labels.pop(i)\n",
    "\n",
    "        print(f\"有效文件: {valid_count}/{len(self.audio_paths) + len(invalid_indices)}\")\n",
    "        print(f\"移除 {len(invalid_indices)} 个无效文件\")\n",
    "        self.speaker_to_idx = self._build_speaker_map()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.audio_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path = self.audio_paths[idx]\n",
    "        speaker_id = self.labels[idx]\n",
    "        label = self.speaker_to_idx[speaker_id]\n",
    "    \n",
    "        try:\n",
    "            # 优先使用soundfile加载.flac文件\n",
    "            if path.endswith('.flac'):\n",
    "                try:\n",
    "                    signal, sr = sf.read(path)\n",
    "                    if sr != Config.SAMPLE_RATE:\n",
    "                        signal = librosa.resample(signal, orig_sr=sr, target_sr=Config.SAMPLE_RATE)\n",
    "                except Exception as e:\n",
    "                    print(f\"SoundFile加载失败 {path}: {e}, 尝试Librosa\")\n",
    "                    signal, sr = librosa.load(path, sr=Config.SAMPLE_RATE, mono=True)\n",
    "            else:\n",
    "                signal, sr = librosa.load(path, sr=Config.SAMPLE_RATE, mono=True)\n",
    "        except Exception as e:\n",
    "            print(f\"加载音频错误 {path}: {str(e)}, 使用静音替代\")\n",
    "            signal = np.zeros(Config.MAX_SAMPLES, dtype=np.float32)\n",
    "    \n",
    "        # 确保音频长度正确\n",
    "        if len(signal) > Config.MAX_SAMPLES:\n",
    "            # 改为固定裁剪开头部分（确保一致性）\n",
    "            signal = signal[:Config.MAX_SAMPLES]\n",
    "        elif len(signal) < Config.MAX_SAMPLES:\n",
    "            pad_len = Config.MAX_SAMPLES - len(signal)\n",
    "            signal = np.pad(signal, (0, pad_len), mode='constant')\n",
    "    \n",
    "        # 归一化\n",
    "        max_val = np.max(np.abs(signal))\n",
    "        if max_val > 1e-5:\n",
    "            signal = signal / max_val\n",
    "    \n",
    "        # 添加噪声\n",
    "        if self.add_noise and self.split == \"train\":\n",
    "            noise_type = random.choice(Config.NOISE_TYPES)\n",
    "            snr_db = random.choice(Config.SNR_LEVELS)\n",
    "            signal = NoiseInjector.add_noise(signal, noise_type, snr_db)\n",
    "    \n",
    "        # 为复杂池化提取多尺度特征\n",
    "        multi_scale_features = self.extract_multi_scale_features(signal)\n",
    "        \n",
    "        return torch.FloatTensor(signal), label, torch.FloatTensor(multi_scale_features)\n",
    "\n",
    "    def extract_multi_scale_features(self, signal):\n",
    "        \"\"\"\n",
    "        提取多尺度特征以供复杂池化使用\n",
    "        :param signal: 音频信号\n",
    "        :return: 多尺度特征\n",
    "        \"\"\"\n",
    "        features = []\n",
    "        \n",
    "        for scale in Config.FEATURE_SCALES:\n",
    "            if scale > 1:\n",
    "                # 降采样\n",
    "                scaled_signal = signal[::scale]\n",
    "            else:\n",
    "                scaled_signal = signal\n",
    "                \n",
    "            # 提取MFCC特征\n",
    "            mfcc = librosa.feature.mfcc(\n",
    "                y=scaled_signal, \n",
    "                sr=Config.SAMPLE_RATE, \n",
    "                n_mfcc=Config.FEATURE_DIM\n",
    "            )\n",
    "            \n",
    "            # 计算统计特征\n",
    "            mean = np.mean(mfcc, axis=1)\n",
    "            std = np.std(mfcc, axis=1)\n",
    "            \n",
    "            # 组合特征\n",
    "            scale_features = np.concatenate([mean, std])\n",
    "            features.append(scale_features)\n",
    "        \n",
    "        # 将所有尺度的特征拼接\n",
    "        all_features = np.concatenate(features)\n",
    "        \n",
    "        # 如果特征维度不匹配，进行截断或填充\n",
    "        if len(all_features) > Config.POOLING_OUTPUT_DIM:\n",
    "            all_features = all_features[:Config.POOLING_OUTPUT_DIM]\n",
    "        elif len(all_features) < Config.POOLING_OUTPUT_DIM:\n",
    "            pad_len = Config.POOLING_OUTPUT_DIM - len(all_features)\n",
    "            all_features = np.pad(all_features, (0, pad_len), mode='constant')\n",
    "        \n",
    "        return all_features\n",
    "    \n",
    "# 数据加载器\n",
    "def get_dataloaders(batch_size=None):\n",
    "    if batch_size is None:\n",
    "        batch_size = Config.BATCH_SIZE\n",
    "\n",
    "    train_dataset = SpeakerRecognitionDataset(split=\"train\")\n",
    "    val_dataset = SpeakerRecognitionDataset(split=\"val\")\n",
    "    test_dataset = SpeakerRecognitionDataset(split=\"test\")\n",
    "\n",
    "    if len(train_dataset) == 0 and len(test_dataset) > 0:\n",
    "        print(\"警告: 训练集为空，使用测试集作为训练集\")\n",
    "        train_dataset = test_dataset\n",
    "\n",
    "    noisy_test_dataset = SpeakerRecognitionDataset(\n",
    "        split=\"test\", add_noise=True, noise_type=\"white\", snr_db=5\n",
    "    )\n",
    "\n",
    "    print(f\"训练集: {len(train_dataset)} 样本\")\n",
    "    print(f\"验证集: {len(val_dataset)} 样本\")\n",
    "    print(f\"测试集: {len(test_dataset)} 样本\")\n",
    "    print(f\"带噪声测试集: {len(noisy_test_dataset)} 样本\")\n",
    "    print(f\"总说话人数: {len(train_dataset.speaker_to_idx)}\")\n",
    "\n",
    "    # 创建自定义collate函数处理多尺度特征\n",
    "    def collate_fn(batch):\n",
    "        signals, labels, multi_scale_features = zip(*batch)\n",
    "        signals = torch.stack(signals)\n",
    "        labels = torch.tensor(labels)\n",
    "        multi_scale_features = torch.stack(multi_scale_features)\n",
    "        return signals, labels, multi_scale_features\n",
    "    \n",
    "    # 创建数据加载器时使用自定义collate函数\n",
    "    dataloaders = {\n",
    "        \"train\": DataLoader(train_dataset, batch_size=batch_size, shuffle=True,\n",
    "                           num_workers=Config.NUM_WORKERS, pin_memory=True,\n",
    "                           collate_fn=collate_fn),\n",
    "        \"val\": DataLoader(val_dataset, batch_size=batch_size, shuffle=False,\n",
    "                         num_workers=Config.NUM_WORKERS, pin_memory=True,\n",
    "                         collate_fn=collate_fn),\n",
    "        \"test\": DataLoader(test_dataset, batch_size=batch_size, shuffle=False,\n",
    "                          num_workers=Config.NUM_WORKERS, pin_memory=True,\n",
    "                          collate_fn=collate_fn),\n",
    "        \"noisy_test\": DataLoader(noisy_test_dataset, batch_size=batch_size, shuffle=False,\n",
    "                                num_workers=Config.NUM_WORKERS, pin_memory=True,\n",
    "                                collate_fn=collate_fn),\n",
    "    }\n",
    "    \n",
    "    return dataloaders\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    print(\"测试数据加载器...\")\n",
    "    dataloaders = get_dataloaders()\n",
    "    # 数据加载器返回三个值，需要三个变量来接收\n",
    "    x, y, multi_scale_features = next(iter(dataloaders[\"train\"]))\n",
    "    print(f\"音频数据形状: {x.shape}\")\n",
    "    print(f\"标签数据形状: {y.shape}\")\n",
    "    print(f\"多尺度特征形状: {multi_scale_features.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0e047b4-9887-4167-a2cb-efff71beeb7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型结构:\n",
      "CHiLAPModel(\n",
      "  (feature_extractor): Sequential(\n",
      "    (0): Conv1d(1, 256, kernel_size=(5,), stride=(2,), padding=(2,))\n",
      "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): PReLU(num_parameters=1)\n",
      "    (3): Conv1d(256, 256, kernel_size=(5,), stride=(2,), padding=(2,))\n",
      "    (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): PReLU(num_parameters=1)\n",
      "    (6): Conv1d(256, 256, kernel_size=(5,), stride=(2,), padding=(2,))\n",
      "    (7): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (8): PReLU(num_parameters=1)\n",
      "  )\n",
      "  (chaos_layer): ChaoticStimulus(\n",
      "    (chaos_transform): Sequential(\n",
      "      (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): PReLU(num_parameters=1)\n",
      "      (3): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "      (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): PReLU(num_parameters=1)\n",
      "    )\n",
      "  )\n",
      "  (attention): SimpleAttention(\n",
      "    (attention): Sequential(\n",
      "      (0): Conv1d(256, 1, kernel_size=(1,), stride=(1,))\n",
      "      (1): Softmax(dim=2)\n",
      "    )\n",
      "  )\n",
      "  (tdnn_block): Sequential(\n",
      "    (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): PReLU(num_parameters=1)\n",
      "    (3): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
      "    (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): PReLU(num_parameters=1)\n",
      "  )\n",
      "  (pooling): StrangeAttractorPooling(\n",
      "    (projection): Linear(in_features=256, out_features=128, bias=True)\n",
      "  )\n",
      "  (embedding): Sequential(\n",
      "    (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): PReLU(num_parameters=1)\n",
      "    (3): Dropout(p=0.2, inplace=False)\n",
      "  )\n",
      "  (classifier): Linear(in_features=128, out_features=10, bias=True)\n",
      ")\n",
      "加载LibriSpeech数据集: /users/tianyuey/Project/devDataset/LibriSpeech\n",
      "处理子集: dev-clean\n",
      "在 dev-clean 中找到 2703 个.flac文件\n",
      "处理子集: dev-other\n",
      "在 dev-other 中找到 5567 个.flac文件\n",
      "找到 73 个不同的说话人\n",
      "有效文件: 5000/5000\n",
      "移除 0 个无效文件\n",
      "找到 73 个不同的说话人\n",
      "最终 train 数据集大小: 5000 个样本\n",
      "加载LibriSpeech数据集: /users/tianyuey/Project/devDataset/LibriSpeech\n",
      "处理子集: dev-clean\n",
      "在 dev-clean 中找到 2703 个.flac文件\n",
      "处理子集: dev-other\n",
      "在 dev-other 中找到 5567 个.flac文件\n",
      "找到 73 个不同的说话人\n",
      "有效文件: 557/557\n",
      "移除 0 个无效文件\n",
      "找到 73 个不同的说话人\n",
      "最终 val 数据集大小: 557 个样本\n",
      "加载LibriSpeech数据集: /users/tianyuey/Project/devDataset/LibriSpeech\n",
      "处理子集: dev-clean\n",
      "在 dev-clean 中找到 2703 个.flac文件\n",
      "处理子集: dev-other\n",
      "在 dev-other 中找到 5567 个.flac文件\n",
      "找到 73 个不同的说话人\n",
      "有效文件: 5567/5567\n",
      "移除 0 个无效文件\n",
      "找到 73 个不同的说话人\n",
      "最终 test 数据集大小: 5567 个样本\n",
      "加载LibriSpeech数据集: /users/tianyuey/Project/devDataset/LibriSpeech\n",
      "处理子集: dev-clean\n",
      "在 dev-clean 中找到 2703 个.flac文件\n",
      "处理子集: dev-other\n",
      "在 dev-other 中找到 5567 个.flac文件\n",
      "找到 73 个不同的说话人\n",
      "有效文件: 5567/5567\n",
      "移除 0 个无效文件\n",
      "找到 73 个不同的说话人\n",
      "最终 test 数据集大小: 5567 个样本\n",
      "训练集: 5000 样本\n",
      "验证集: 557 样本\n",
      "测试集: 5567 样本\n",
      "带噪声测试集: 5567 样本\n",
      "总说话人数: 73\n",
      "从 dataloader 获取到: signals torch.Size([2, 16000]), labels torch.Size([2]), multi_scale_features torch.Size([2, 128])\n",
      "Input x shape: torch.Size([2, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([2, 128])\n",
      "嵌入向量形状: torch.Size([2, 128])\n",
      "分类输出形状: torch.Size([2, 10])\n",
      "前向传播成功!\n",
      "吸引子空间可视化已保存到: attractor_space.png\n",
      "动态系统参数可视化已保存到: dynamics_parameters.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# 简化混沌激励模块\n",
    "class ChaoticStimulus(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        \"\"\"\n",
    "        简化的混沌激励模块\n",
    "        :param input_dim: 输入维度\n",
    "        :param output_dim: 输出维度\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.chaos_transform = nn.Sequential(\n",
    "            nn.Conv1d(input_dim, output_dim, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(output_dim),\n",
    "            nn.PReLU(),\n",
    "            nn.Conv1d(output_dim, output_dim, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(output_dim),\n",
    "            nn.PReLU()\n",
    "        )\n",
    "\n",
    "        # 混沌扰动参数\n",
    "        self.chaos_factor = nn.Parameter(torch.tensor(0.1))\n",
    "\n",
    "    def forward(self, x, multi_scale_features=None):\n",
    "        \"\"\"\n",
    "        前向传播\n",
    "        :param x: 输入特征 [batch_size, channels, seq_len] 或 [batch_size, seq_len, channels]\n",
    "        :param multi_scale_features: 来自 DataLoader 的多尺度特征 [batch_size, POOLING_OUTPUT_DIM]\n",
    "        :return: 嵌入向量和分类结果 \n",
    "        \"\"\"\n",
    "        # 常规特征变换\n",
    "        transformed = self.chaos_transform(x)\n",
    "\n",
    "        # 添加混沌扰动\n",
    "        batch_size, channels, seq_len = transformed.size()\n",
    "        if self.training:  # 仅在训练时添加混沌扰动\n",
    "            # 生成与特征相同形状的混沌噪声\n",
    "            chaos_noise = torch.randn_like(transformed) * self.chaos_factor\n",
    "            # 应用非线性激活增强混沌特性\n",
    "            chaos_noise = torch.tanh(chaos_noise)\n",
    "            transformed = transformed + chaos_noise\n",
    "\n",
    "        return transformed\n",
    "\n",
    "\n",
    "# 简化注意力机制\n",
    "class SimpleAttention(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        \"\"\"\n",
    "        简化的注意力机制\n",
    "        :param input_dim: 输入维度\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Conv1d(input_dim, 1, kernel_size=1),\n",
    "            nn.Softmax(dim=2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, multi_scale_features=None):\n",
    "        \"\"\"\n",
    "        前向传播\n",
    "        :param x: 输入特征 [batch_size, channels, seq_len] 或 [batch_size, seq_len, channels]\n",
    "        :param multi_scale_features: 来自 DataLoader 的多尺度特征 [batch_size, POOLING_OUTPUT_DIM]\n",
    "        :return: 嵌入向量和分类结果\n",
    "        \"\"\"\n",
    "        # 计算注意力权重 [batch_size, 1, seq_len]\n",
    "        attn_weights = self.attention(x)\n",
    "\n",
    "        # 应用注意力权重\n",
    "        return x * attn_weights\n",
    "\n",
    "\n",
    "# 复杂奇异吸引子池化层\n",
    "class StrangeAttractorPooling(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, attractor_dim=Config.POOLING_ATTRACTOR_DIM):\n",
    "        \"\"\"\n",
    "        奇异吸引子池化层 - 将时序特征映射到吸引子空间\n",
    "        :param input_dim: 输入维度\n",
    "        :param output_dim: 输出维度\n",
    "        :param attractor_dim: 吸引子空间维度\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.attractor_dim = attractor_dim\n",
    "\n",
    "        # 投影层\n",
    "        self.projection = nn.Linear(input_dim, output_dim)\n",
    "\n",
    "        # 吸引子参数\n",
    "        self.attractor_weights = nn.Parameter(torch.randn(output_dim, attractor_dim) * 0.1)\n",
    "\n",
    "        # 动态系统参数\n",
    "        self.dynamics_alpha = nn.Parameter(torch.tensor(0.1))\n",
    "        self.dynamics_beta = nn.Parameter(torch.tensor(0.1))\n",
    "        self.dynamics_gamma = nn.Parameter(torch.tensor(0.1))\n",
    "\n",
    "    def dynamic_system_step(self, positions, attractors):\n",
    "        \"\"\"\n",
    "        动态系统演化步骤\n",
    "        :param positions: 当前位置 [batch_size, seq_len, attractor_dim]\n",
    "        :param attractors: 吸引子位置 [batch_size, output_dim, attractor_dim]\n",
    "        :return: 更新后的位置\n",
    "        \"\"\"\n",
    "        batch_size, seq_len, _ = positions.size()\n",
    "        _, num_attractors, _ = attractors.size()\n",
    "\n",
    "        # 扩展维度以计算所有位置和吸引子之间的距离\n",
    "        positions_expanded = positions.unsqueeze(2)  # [batch_size, seq_len, 1, attractor_dim]\n",
    "        attractors_expanded = attractors.unsqueeze(1)  # [batch_size, 1, num_attractors, attractor_dim]\n",
    "\n",
    "        # 计算距离\n",
    "        distances = torch.norm(positions_expanded - attractors_expanded, dim=-1)  # [batch_size, seq_len, num_attractors]\n",
    "\n",
    "        # 计算吸引力（距离越近，吸引力越大）\n",
    "        attractions = torch.exp(-self.dynamics_alpha * distances)\n",
    "\n",
    "        # 计算合力方向\n",
    "        direction_vectors = attractors_expanded - positions_expanded  # [batch_size, seq_len, num_attractors, attractor_dim]\n",
    "        direction_vectors = F.normalize(direction_vectors, p=2, dim=-1)\n",
    "\n",
    "        # 计算合力\n",
    "        forces = torch.sum(attractions.unsqueeze(-1) * direction_vectors, dim=2)  # [batch_size, seq_len, attractor_dim]\n",
    "\n",
    "        # 添加混沌扰动\n",
    "        if self.training:\n",
    "            chaos = torch.randn_like(forces) * self.dynamics_beta\n",
    "            forces = forces + chaos\n",
    "\n",
    "        # 更新位置\n",
    "        new_positions = positions + self.dynamics_gamma * forces\n",
    "\n",
    "        return new_positions\n",
    "\n",
    "    def forward(self, x, multi_scale_features):\n",
    "        \"\"\"\n",
    "        前向传播\n",
    "        :param x: 输入特征 [batch_size, seq_len, input_dim]\n",
    "        :return: 池化后的特征 [batch_size, output_dim]\n",
    "        \"\"\"\n",
    "        print(f\"Input x shape: {x.shape}\")  # 调试信息\n",
    "        print(f\"Multi-scale features shape: {multi_scale_features.shape if multi_scale_features is not None else 'None'}\")  # 调试信息\n",
    "        \n",
    "        batch_size, seq_len, _ = x.size()\n",
    "\n",
    "        # 确保序列长度足够\n",
    "        if seq_len < Config.POOLING_MIN_SEQ_LEN:\n",
    "            # 如果序列太短，使用简单池化\n",
    "            return torch.mean(x, dim=1)\n",
    "\n",
    "        # 投影到吸引子空间\n",
    "        projected = self.projection(x)  # [batch_size, seq_len, output_dim]\n",
    "\n",
    "        if multi_scale_features is not None:\n",
    "            # 投影到与 projected 相同维度\n",
    "            cond_proj = nn.Linear(multi_scale_features.size(1), self.output_dim).to(x.device)\n",
    "            cond = cond_proj(multi_scale_features).unsqueeze(1).expand(-1, projected.size(1), -1)\n",
    "            projected = projected + cond  # 使用加法而不是拼接\n",
    "\n",
    "        # 扩展吸引子参数以匹配批次大小\n",
    "        attractors = self.attractor_weights.unsqueeze(0).expand(batch_size, -1, -1)  # [batch_size, output_dim, attractor_dim]\n",
    "\n",
    "        # 初始化位置为投影特征的均值\n",
    "        initial_positions = torch.mean(projected, dim=1, keepdim=True)  # [batch_size, 1, output_dim]\n",
    "        \n",
    "        # 扩展初始位置到吸引子维度\n",
    "        if self.output_dim != self.attractor_dim:\n",
    "            # 使用线性变换将output_dim映射到attractor_dim\n",
    "            position_mapping = nn.Linear(self.output_dim, self.attractor_dim).to(x.device)\n",
    "            initial_positions = position_mapping(initial_positions)\n",
    "        else:\n",
    "            initial_positions = initial_positions.expand(-1, seq_len, -1)  # [batch_size, seq_len, attractor_dim]\n",
    "\n",
    "        # 动态系统演化\n",
    "        positions = initial_positions\n",
    "        for _ in range(5):  # 演化5步\n",
    "            positions = self.dynamic_system_step(positions, attractors)\n",
    "\n",
    "        # 计算每个维度与吸引子的最终距离\n",
    "        positions_expanded = positions.unsqueeze(2)  # [batch_size, seq_len, 1, attractor_dim]\n",
    "        attractors_expanded = attractors.unsqueeze(1)  # [batch_size, 1, output_dim, attractor_dim]\n",
    "        \n",
    "        final_distances = torch.norm(positions_expanded - attractors_expanded, dim=-1)  # [batch_size, seq_len, output_dim]\n",
    "\n",
    "        # 使用距离作为权重进行加权池化\n",
    "        weights = F.softmax(-final_distances, dim=1)  # [batch_size, seq_len, output_dim]\n",
    "        pooled = torch.sum(projected.unsqueeze(2) * weights.unsqueeze(-1), dim=1)  # [batch_size, output_dim, output_dim]\n",
    "\n",
    "        # 取对角线元素作为最终输出\n",
    "        pooled = torch.diagonal(pooled, dim1=1, dim2=2)  # [batch_size, output_dim]\n",
    "\n",
    "        return pooled\n",
    "\n",
    "\n",
    "# 完整的C-HiLAP模型（简化版+复杂池化）\n",
    "class CHiLAPModel(nn.Module):\n",
    "    def __init__(self, input_dim=Config.INPUT_DIM, hidden_dim=Config.HIDDEN_DIM,\n",
    "                 embedding_dim=Config.EMBEDDING_DIM, num_classes=None):\n",
    "        \"\"\"\n",
    "        混沌层次吸引子传播(C-HiLAP)模型 - 简化版+复杂池化\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        # 若未传入num_classes，可设置一个默认值（但实际使用时必须从数据集获取后传入）\n",
    "        if num_classes is None:\n",
    "            raise ValueError(\"必须指定num_classes（说话人数量），请从数据集获取后传入\")\n",
    "\n",
    "        # 特征提取层\n",
    "        self.feature_extractor = nn.Sequential(\n",
    "            nn.Conv1d(input_dim, hidden_dim, kernel_size=5, stride=2, padding=2),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.PReLU(),\n",
    "            nn.Conv1d(hidden_dim, hidden_dim, kernel_size=5, stride=2, padding=2),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.PReLU(),\n",
    "            nn.Conv1d(hidden_dim, hidden_dim, kernel_size=5, stride=2, padding=2),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.PReLU()\n",
    "        )\n",
    "\n",
    "        # 混沌激励模块\n",
    "        self.chaos_layer = ChaoticStimulus(hidden_dim, hidden_dim)\n",
    "\n",
    "        # 注意力层\n",
    "        self.attention = SimpleAttention(hidden_dim)\n",
    "\n",
    "        # TDNN层\n",
    "        self.tdnn_block = nn.Sequential(\n",
    "            nn.Conv1d(hidden_dim, hidden_dim, kernel_size=3, dilation=1, padding=1),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.PReLU(),\n",
    "            nn.Conv1d(hidden_dim, hidden_dim, kernel_size=3, dilation=2, padding=2),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.PReLU()\n",
    "        )\n",
    "\n",
    "        # 复杂池化层\n",
    "        self.pooling = StrangeAttractorPooling(hidden_dim, Config.POOLING_OUTPUT_DIM)\n",
    "\n",
    "        # 嵌入层\n",
    "        self.embedding = nn.Sequential(\n",
    "            nn.Linear(Config.POOLING_OUTPUT_DIM, embedding_dim),  # 使用池化输出维度\n",
    "            nn.BatchNorm1d(embedding_dim),\n",
    "            nn.PReLU(),\n",
    "            nn.Dropout(0.2)\n",
    "        )\n",
    "\n",
    "        # 分类器\n",
    "        self.classifier = nn.Linear(embedding_dim, num_classes)\n",
    "\n",
    "    def forward(self, x, multi_scale_features=None):\n",
    "        \"\"\"\n",
    "        前向传播\n",
    "        :param x: 输入特征 [batch_size, channels, seq_len] 或 [batch_size, seq_len, channels]\n",
    "        :return: 嵌入向量和分类结果\n",
    "        \"\"\"\n",
    "        # 检查输入维度并转换为正确的格式 [batch_size, channels, seq_len]\n",
    "        if x.dim() == 3:\n",
    "            # 如果是 [batch_size, seq_len, channels] 格式\n",
    "            if x.size(1) > x.size(2):  # 序列长度应该大于通道数\n",
    "                x = x.permute(0, 2, 1)  # 转换为 [batch_size, channels, seq_len]\n",
    "\n",
    "        # 限制序列长度防止内存溢出\n",
    "        seq_len = x.size(2)\n",
    "        if seq_len > Config.MAX_SEQ_LEN:\n",
    "            x = x[:, :, :Config.MAX_SEQ_LEN]\n",
    "\n",
    "        # 特征提取\n",
    "        x = self.feature_extractor(x)\n",
    "\n",
    "        # 混沌处理\n",
    "        x = self.chaos_layer(x)\n",
    "\n",
    "        # 注意力机制\n",
    "        attn_weights = self.attention(x)\n",
    "        x = x * attn_weights\n",
    "\n",
    "        # TDNN处理\n",
    "        x = self.tdnn_block(x)\n",
    "\n",
    "        # 转换维度: [batch_size, channels, seq_len] -> [batch_size, seq_len, channels]\n",
    "        x = x.permute(0, 2, 1)\n",
    "\n",
    "        # 使用多尺度特征的奇怪吸引子池化\n",
    "        x = self.pooling(x, multi_scale_features)\n",
    "\n",
    "        # 嵌入向量\n",
    "        embedding = self.embedding(x)\n",
    "\n",
    "        # 分类\n",
    "        logits = self.classifier(embedding)\n",
    "\n",
    "        return embedding, logits\n",
    "\n",
    "\n",
    "# 吸引子可视化工具\n",
    "class AttractorVisualizer:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    @staticmethod\n",
    "    def plot_attractor_space(attractor_weights, save_path=None):\n",
    "        \"\"\"\n",
    "        绘制吸引子空间\n",
    "        :param attractor_weights: 吸引子权重 [output_dim, attractor_dim]\n",
    "        :param save_path: 保存路径\n",
    "        \"\"\"\n",
    "        try:\n",
    "            attractor_weights = attractor_weights.detach().cpu().numpy()\n",
    "            \n",
    "            if attractor_weights.shape[1] == 3:\n",
    "                # 3D可视化\n",
    "                fig = plt.figure(figsize=(10, 8))\n",
    "                ax = fig.add_subplot(111, projection='3d')\n",
    "                \n",
    "                ax.scatter(attractor_weights[:, 0], attractor_weights[:, 1], attractor_weights[:, 2], \n",
    "                          c=range(attractor_weights.shape[0]), cmap='viridis', s=100)\n",
    "                \n",
    "                ax.set_title(\"Attractor Space\")\n",
    "                ax.set_xlabel(\"Dimension 1\")\n",
    "                ax.set_ylabel(\"Dimension 2\")\n",
    "                ax.set_zlabel(\"Dimension 3\")\n",
    "                \n",
    "            elif attractor_weights.shape[1] == 2:\n",
    "                # 2D可视化\n",
    "                plt.figure(figsize=(10, 8))\n",
    "                plt.scatter(attractor_weights[:, 0], attractor_weights[:, 1], \n",
    "                           c=range(attractor_weights.shape[0]), cmap='viridis', s=100)\n",
    "                \n",
    "                plt.title(\"Attractor Space\")\n",
    "                plt.xlabel(\"Dimension 1\")\n",
    "                plt.ylabel(\"Dimension 2\")\n",
    "                plt.colorbar(label='Attractor Index')\n",
    "                \n",
    "            else:\n",
    "                print(f\"无法可视化 {attractor_weights.shape[1]} 维吸引子空间\")\n",
    "                return\n",
    "                \n",
    "            if save_path:\n",
    "                plt.savefig(save_path)\n",
    "                print(f\"吸引子空间可视化已保存到: {save_path}\")\n",
    "            else:\n",
    "                plt.show()\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"吸引子空间可视化失败: {e}\")\n",
    "    \n",
    "    @staticmethod\n",
    "    def plot_dynamics_parameters(model, save_path=None):\n",
    "        \"\"\"\n",
    "        绘制动态系统参数\n",
    "        :param model: 模型实例\n",
    "        :param save_path: 保存路径\n",
    "        \"\"\"\n",
    "        try:\n",
    "            alpha = model.pooling.dynamics_alpha.detach().cpu().item()\n",
    "            beta = model.pooling.dynamics_beta.detach().cpu().item()\n",
    "            gamma = model.pooling.dynamics_gamma.detach().cpu().item()\n",
    "            \n",
    "            parameters = [alpha, beta, gamma]\n",
    "            param_names = ['Alpha', 'Beta', 'Gamma']\n",
    "            \n",
    "            plt.figure(figsize=(10, 6))\n",
    "            plt.bar(param_names, parameters)\n",
    "            plt.title(\"Dynamics System Parameters\")\n",
    "            plt.ylabel(\"Value\")\n",
    "            \n",
    "            for i, v in enumerate(parameters):\n",
    "                plt.text(i, v + 0.01, f\"{v:.4f}\", ha='center')\n",
    "                \n",
    "            if save_path:\n",
    "                plt.savefig(save_path)\n",
    "                print(f\"动态系统参数可视化已保存到: {save_path}\")\n",
    "            else:\n",
    "                plt.show()\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"动态系统参数可视化失败: {e}\")\n",
    "\n",
    "\n",
    "# 测试代码\n",
    "if __name__ == \"__main__\":\n",
    "    # 创建模型实例（示例 num_classes）\n",
    "    model = CHiLAPModel(num_classes=10)  # 保持不变\n",
    "\n",
    "    print(\"模型结构:\")\n",
    "    print(model)\n",
    "\n",
    "    # 从 dataloader 获取一个 batch 来测试前向传播（使用你之前实现的 get_dataloaders）\n",
    "    try:\n",
    "        dataloaders = get_dataloaders(batch_size=2)\n",
    "        signals, labels, multi_scale_features = next(iter(dataloaders[\"train\"]))\n",
    "        print(f\"从 dataloader 获取到: signals {signals.shape}, labels {labels.shape}, multi_scale_features {multi_scale_features.shape}\")\n",
    "\n",
    "        # signals: [B, MAX_SAMPLES] -> 转为 [B, 1, MAX_SAMPLES] 符合模型输入\n",
    "        signals = signals.unsqueeze(1)\n",
    "\n",
    "        # 将 multi_scale_features 转为 float tensor（通常已是 float）\n",
    "        multi_scale_features = multi_scale_features.float()\n",
    "\n",
    "        # 前向传播（将 multi_scale_features 传入）\n",
    "        embedding, logits = model(signals, multi_scale_features)\n",
    "\n",
    "        print(f\"嵌入向量形状: {embedding.shape}\")\n",
    "        print(f\"分类输出形状: {logits.shape}\")\n",
    "        print(\"前向传播成功!\")\n",
    "\n",
    "        # 测试吸引子可视化（可选）\n",
    "        visualizer = AttractorVisualizer()\n",
    "        visualizer.plot_attractor_space(model.pooling.attractor_weights, \"attractor_space.png\")\n",
    "        visualizer.plot_dynamics_parameters(model, \"dynamics_parameters.png\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"前向传播/测试 出错: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2f4b6f-c59f-410d-9bc0-3897af570ff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "创建数据加载器...\n",
      "加载LibriSpeech数据集: /users/tianyuey/Project/devDataset/LibriSpeech\n",
      "处理子集: dev-clean\n",
      "在 dev-clean 中找到 2703 个.flac文件\n",
      "处理子集: dev-other\n",
      "在 dev-other 中找到 5567 个.flac文件\n",
      "找到 73 个不同的说话人\n",
      "有效文件: 5000/5000\n",
      "移除 0 个无效文件\n",
      "找到 73 个不同的说话人\n",
      "最终 train 数据集大小: 5000 个样本\n",
      "加载LibriSpeech数据集: /users/tianyuey/Project/devDataset/LibriSpeech\n",
      "处理子集: dev-clean\n",
      "在 dev-clean 中找到 2703 个.flac文件\n",
      "处理子集: dev-other\n",
      "在 dev-other 中找到 5567 个.flac文件\n",
      "找到 73 个不同的说话人\n",
      "有效文件: 557/557\n",
      "移除 0 个无效文件\n",
      "找到 73 个不同的说话人\n",
      "最终 val 数据集大小: 557 个样本\n",
      "加载LibriSpeech数据集: /users/tianyuey/Project/devDataset/LibriSpeech\n",
      "处理子集: dev-clean\n",
      "在 dev-clean 中找到 2703 个.flac文件\n",
      "处理子集: dev-other\n",
      "在 dev-other 中找到 5567 个.flac文件\n",
      "找到 73 个不同的说话人\n",
      "有效文件: 5567/5567\n",
      "移除 0 个无效文件\n",
      "找到 73 个不同的说话人\n",
      "最终 test 数据集大小: 5567 个样本\n",
      "加载LibriSpeech数据集: /users/tianyuey/Project/devDataset/LibriSpeech\n",
      "处理子集: dev-clean\n",
      "在 dev-clean 中找到 2703 个.flac文件\n",
      "处理子集: dev-other\n",
      "在 dev-other 中找到 5567 个.flac文件\n",
      "找到 73 个不同的说话人\n",
      "有效文件: 5567/5567\n",
      "移除 0 个无效文件\n",
      "找到 73 个不同的说话人\n",
      "最终 test 数据集大小: 5567 个样本\n",
      "训练集: 5000 样本\n",
      "验证集: 557 样本\n",
      "测试集: 5567 样本\n",
      "带噪声测试集: 5567 样本\n",
      "总说话人数: 73\n",
      "训练集批次数: 313\n",
      "验证集批次数: 35\n",
      "测试集批次数: 348\n",
      "数据集中实际说话人数量（类别数）: 73\n",
      "创建模型和训练器...\n",
      "使用设备: cuda\n",
      "模型预期输入长度: 16000\n",
      "测试前向传播...\n",
      "原始输入形状: torch.Size([16, 16000]), 标签形状: torch.Size([16]), 多尺度特征形状: torch.Size([16, 128])\n",
      "处理后输入形状: torch.Size([16, 1, 16000])\n",
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "嵌入形状: torch.Size([16, 128]), 输出形状: torch.Size([16, 73])\n",
      "前向传播测试成功!\n",
      "开始训练...\n",
      "开始训练...\n",
      "训练集批次: 313, 验证集批次: 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib64/python3.12/site-packages/torch/optim/lr_scheduler.py:182: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\n",
      "  0%|          | 0/313 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 0: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 340.50 MiB is free. Including non-PyTorch memory, this process has 4.41 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1.18 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/313 [00:01<09:48,  1.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 1: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 576.50 MiB is free. Including non-PyTorch memory, this process has 4.18 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 973.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 2/313 [00:02<05:02,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 2: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 366.50 MiB is free. Including non-PyTorch memory, this process has 4.38 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 3/313 [00:02<03:30,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 3: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 544.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 4/313 [00:02<02:57,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 4: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 398.50 MiB is free. Including non-PyTorch memory, this process has 4.35 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 5/313 [00:03<02:28,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 5: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 544.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 6/313 [00:03<02:13,  2.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 6: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 398.50 MiB is free. Including non-PyTorch memory, this process has 4.35 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 7/313 [00:03<01:55,  2.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 7: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 544.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 8/313 [00:04<01:49,  2.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 8: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 398.50 MiB is free. Including non-PyTorch memory, this process has 4.35 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 9/313 [00:04<01:38,  3.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 9: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 544.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 10/313 [00:04<01:31,  3.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 10: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 398.50 MiB is free. Including non-PyTorch memory, this process has 4.35 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 11/313 [00:04<01:26,  3.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 11: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 544.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 12/313 [00:05<01:33,  3.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 12: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 398.50 MiB is free. Including non-PyTorch memory, this process has 4.35 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 13/313 [00:05<01:43,  2.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 13: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 544.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 14/313 [00:06<01:37,  3.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 14: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 398.50 MiB is free. Including non-PyTorch memory, this process has 4.35 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 15/313 [00:06<01:31,  3.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 15: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 544.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 16/313 [00:06<01:27,  3.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 16: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 398.50 MiB is free. Including non-PyTorch memory, this process has 4.35 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 17/313 [00:06<01:22,  3.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 17: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 544.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 18/313 [00:07<01:20,  3.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 18: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 398.50 MiB is free. Including non-PyTorch memory, this process has 4.35 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 19/313 [00:07<01:24,  3.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 19: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 544.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 20/313 [00:07<01:21,  3.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 20: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 398.50 MiB is free. Including non-PyTorch memory, this process has 4.35 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 21/313 [00:07<01:18,  3.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 21: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 544.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 22/313 [00:08<01:17,  3.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 22: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 398.50 MiB is free. Including non-PyTorch memory, this process has 4.35 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 23/313 [00:08<01:15,  3.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 23: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 544.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 24/313 [00:08<01:15,  3.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 24: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 398.50 MiB is free. Including non-PyTorch memory, this process has 4.35 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 25/313 [00:08<01:13,  3.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 25: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 544.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 26/313 [00:09<01:13,  3.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 26: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 398.50 MiB is free. Including non-PyTorch memory, this process has 4.35 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▊         | 27/313 [00:09<01:12,  3.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 27: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 544.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 28/313 [00:09<01:12,  3.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 28: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 398.50 MiB is free. Including non-PyTorch memory, this process has 4.35 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 29/313 [00:09<01:11,  3.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 29: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 544.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 30/313 [00:10<01:11,  3.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 30: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 398.50 MiB is free. Including non-PyTorch memory, this process has 4.35 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 31/313 [00:10<01:11,  3.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 31: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 544.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 32/313 [00:10<01:13,  3.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 32: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 398.50 MiB is free. Including non-PyTorch memory, this process has 4.35 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 33/313 [00:11<01:19,  3.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 33: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 544.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 34/313 [00:11<01:16,  3.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 34: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 398.50 MiB is free. Including non-PyTorch memory, this process has 4.35 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 35/313 [00:11<01:13,  3.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 35: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 544.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 36/313 [00:12<01:35,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 36: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 398.50 MiB is free. Including non-PyTorch memory, this process has 4.35 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 37/313 [00:12<01:32,  2.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 37: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 544.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 38/313 [00:12<01:38,  2.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 38: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 398.50 MiB is free. Including non-PyTorch memory, this process has 4.35 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 39/313 [00:13<01:32,  2.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 39: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 544.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 40/313 [00:13<01:33,  2.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 40: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 398.50 MiB is free. Including non-PyTorch memory, this process has 4.35 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 41/313 [00:13<01:38,  2.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 41: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 544.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▎        | 43/313 [00:14<01:30,  2.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 42: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 398.50 MiB is free. Including non-PyTorch memory, this process has 4.35 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 43: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 544.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 44/313 [00:14<01:27,  3.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 44: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 398.50 MiB is free. Including non-PyTorch memory, this process has 4.35 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 45/313 [00:15<01:24,  3.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 45: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 544.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 46/313 [00:15<01:24,  3.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 46: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 398.50 MiB is free. Including non-PyTorch memory, this process has 4.35 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 47/313 [00:15<01:32,  2.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 47: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 544.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 48/313 [00:16<01:25,  3.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 48: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 398.50 MiB is free. Including non-PyTorch memory, this process has 4.35 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 49/313 [00:16<01:24,  3.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 49: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 544.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 50/313 [00:16<01:29,  2.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 50: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 398.50 MiB is free. Including non-PyTorch memory, this process has 4.35 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▋        | 51/313 [00:17<01:26,  3.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 51: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 544.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 52/313 [00:17<01:28,  2.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 52: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 398.50 MiB is free. Including non-PyTorch memory, this process has 4.35 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 53/313 [00:17<01:25,  3.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 53: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 544.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 54/313 [00:17<01:20,  3.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 54: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 398.50 MiB is free. Including non-PyTorch memory, this process has 4.35 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 55/313 [00:18<01:22,  3.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 55: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 544.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 56/313 [00:18<01:37,  2.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 56: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 398.50 MiB is free. Including non-PyTorch memory, this process has 4.35 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 57/313 [00:19<01:25,  2.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 57: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 544.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▊        | 58/313 [00:19<01:43,  2.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 58: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 398.50 MiB is free. Including non-PyTorch memory, this process has 4.35 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 59/313 [00:20<01:43,  2.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 59: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 544.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 60/313 [00:20<01:40,  2.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 60: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 398.50 MiB is free. Including non-PyTorch memory, this process has 4.35 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 61/313 [00:20<01:29,  2.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 61: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 544.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 62/313 [00:20<01:21,  3.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 62: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 398.50 MiB is free. Including non-PyTorch memory, this process has 4.35 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 63/313 [00:21<01:16,  3.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 63: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 544.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 64/313 [00:21<01:10,  3.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 64: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 398.50 MiB is free. Including non-PyTorch memory, this process has 4.35 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 65/313 [00:21<01:16,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 65: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 544.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 66/313 [00:22<01:13,  3.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 66: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 398.50 MiB is free. Including non-PyTorch memory, this process has 4.35 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██▏       | 67/313 [00:22<01:09,  3.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 67: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 544.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 68/313 [00:22<01:07,  3.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 68: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 398.50 MiB is free. Including non-PyTorch memory, this process has 4.35 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 69/313 [00:22<01:05,  3.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 69: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 544.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 70/313 [00:23<01:05,  3.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 70: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 398.50 MiB is free. Including non-PyTorch memory, this process has 4.35 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 71/313 [00:23<01:12,  3.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 71: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 544.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 72/313 [00:23<01:19,  3.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 72: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 396.50 MiB is free. Including non-PyTorch memory, this process has 4.35 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 73/313 [00:24<01:14,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 73: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 544.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▎       | 74/313 [00:24<01:11,  3.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 74: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 396.50 MiB is free. Including non-PyTorch memory, this process has 4.35 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 75/313 [00:24<01:07,  3.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 75: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 544.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 76/313 [00:24<01:05,  3.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 76: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 396.50 MiB is free. Including non-PyTorch memory, this process has 4.35 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 77/313 [00:25<01:03,  3.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 77: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 544.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 78/313 [00:25<01:03,  3.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 78: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 396.50 MiB is free. Including non-PyTorch memory, this process has 4.35 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 79/313 [00:25<01:01,  3.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 79: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 544.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 80/313 [00:25<01:00,  3.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 80: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 396.50 MiB is free. Including non-PyTorch memory, this process has 4.35 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 81/313 [00:26<00:59,  3.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 81: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 544.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 82/313 [00:26<00:59,  3.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 82: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 398.50 MiB is free. Including non-PyTorch memory, this process has 4.35 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 83/313 [00:26<00:58,  3.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 83: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 544.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 84/313 [00:26<00:58,  3.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 84: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 398.50 MiB is free. Including non-PyTorch memory, this process has 4.35 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 85/313 [00:27<01:02,  3.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 85: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 544.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 86/313 [00:27<01:03,  3.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 86: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 398.50 MiB is free. Including non-PyTorch memory, this process has 4.35 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 87/313 [00:27<01:04,  3.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 87: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 544.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 88/313 [00:28<01:06,  3.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 88: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 398.50 MiB is free. Including non-PyTorch memory, this process has 4.35 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 89/313 [00:28<01:05,  3.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 89: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 544.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 90/313 [00:28<01:03,  3.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 90: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 398.50 MiB is free. Including non-PyTorch memory, this process has 4.35 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 91/313 [00:28<01:00,  3.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 91: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 544.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 92/313 [00:29<00:58,  3.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 92: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 398.50 MiB is free. Including non-PyTorch memory, this process has 4.35 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 93/313 [00:29<00:57,  3.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 93: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 544.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 94/313 [00:29<01:07,  3.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 94: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 398.50 MiB is free. Including non-PyTorch memory, this process has 4.35 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 95/313 [00:30<01:08,  3.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 95: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 544.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 96/313 [00:30<01:06,  3.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 96: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 398.50 MiB is free. Including non-PyTorch memory, this process has 4.35 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 97/313 [00:30<01:05,  3.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 97: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 544.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███▏      | 98/313 [00:31<01:02,  3.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 98: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 398.50 MiB is free. Including non-PyTorch memory, this process has 4.35 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 99/313 [00:31<01:00,  3.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 99: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 544.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 100/313 [00:31<01:00,  3.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 100: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 398.50 MiB is free. Including non-PyTorch memory, this process has 4.35 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 101/313 [00:31<01:01,  3.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 101: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 544.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 102/313 [00:32<00:59,  3.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 102: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 398.50 MiB is free. Including non-PyTorch memory, this process has 4.35 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 103/313 [00:32<00:57,  3.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 103: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 544.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 104/313 [00:32<00:56,  3.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 104: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 398.50 MiB is free. Including non-PyTorch memory, this process has 4.35 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▎      | 105/313 [00:32<00:55,  3.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 105: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 544.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 106/313 [00:33<00:56,  3.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 106: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 398.50 MiB is free. Including non-PyTorch memory, this process has 4.35 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 107/313 [00:33<01:08,  3.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 107: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 544.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▍      | 108/313 [00:34<01:07,  3.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 108: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 396.50 MiB is free. Including non-PyTorch memory, this process has 4.35 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▍      | 109/313 [00:34<01:03,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 109: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 544.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 110/313 [00:34<01:03,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 110: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 396.50 MiB is free. Including non-PyTorch memory, this process has 4.35 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 111/313 [00:34<01:05,  3.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 111: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 544.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 112/313 [00:35<01:08,  2.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 112: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 396.50 MiB is free. Including non-PyTorch memory, this process has 4.35 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 113/313 [00:35<01:04,  3.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 113: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 544.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▋      | 114/313 [00:35<01:01,  3.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 114: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 396.50 MiB is free. Including non-PyTorch memory, this process has 4.35 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 115/313 [00:36<01:00,  3.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 115: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 544.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 116/313 [00:36<01:09,  2.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 116: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 396.50 MiB is free. Including non-PyTorch memory, this process has 4.35 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 117/313 [00:37<01:08,  2.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 117: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 544.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 118/313 [00:37<01:03,  3.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 118: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 396.50 MiB is free. Including non-PyTorch memory, this process has 4.35 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 119/313 [00:37<01:04,  2.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 119: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 544.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 120/313 [00:37<01:03,  3.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 120: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 396.50 MiB is free. Including non-PyTorch memory, this process has 4.35 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▊      | 121/313 [00:38<01:00,  3.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 121: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 544.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 122/313 [00:38<01:07,  2.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 122: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 396.50 MiB is free. Including non-PyTorch memory, this process has 4.35 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 123/313 [00:38<01:01,  3.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 123: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 544.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 124/313 [00:39<01:07,  2.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 124: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 396.50 MiB is free. Including non-PyTorch memory, this process has 4.35 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 125/313 [00:39<01:02,  3.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 125: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 544.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 126/313 [00:40<01:06,  2.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 126: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 396.50 MiB is free. Including non-PyTorch memory, this process has 4.35 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 127/313 [00:40<01:01,  3.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 127: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 544.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 128/313 [00:40<01:00,  3.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 128: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 398.50 MiB is free. Including non-PyTorch memory, this process has 4.35 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 129/313 [00:40<00:56,  3.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 129: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 544.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 130/313 [00:41<00:53,  3.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 130: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 398.50 MiB is free. Including non-PyTorch memory, this process has 4.35 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 131/313 [00:41<00:50,  3.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 131: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 544.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 132/313 [00:41<00:49,  3.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 132: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 398.50 MiB is free. Including non-PyTorch memory, this process has 4.35 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 133/313 [00:42<00:52,  3.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 133: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 544.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 134/313 [00:42<00:51,  3.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 134: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 398.50 MiB is free. Including non-PyTorch memory, this process has 4.35 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 135/313 [00:42<00:59,  3.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 135: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 544.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 136/313 [00:43<00:57,  3.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 136: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 398.50 MiB is free. Including non-PyTorch memory, this process has 4.35 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 137/313 [00:43<01:00,  2.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 137: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 544.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 138/313 [00:43<00:58,  3.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 138: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 398.50 MiB is free. Including non-PyTorch memory, this process has 4.35 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 139/313 [00:43<00:54,  3.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 139: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 544.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▍     | 140/313 [00:44<00:51,  3.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 140: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 396.50 MiB is free. Including non-PyTorch memory, this process has 4.35 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 141/313 [00:44<00:52,  3.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 141: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 544.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 142/313 [00:45<01:12,  2.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 142: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 396.50 MiB is free. Including non-PyTorch memory, this process has 4.35 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 143/313 [00:45<01:06,  2.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 143: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 544.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 144/313 [00:45<00:59,  2.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 144: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 398.50 MiB is free. Including non-PyTorch memory, this process has 4.35 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▋     | 145/313 [00:46<00:54,  3.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 145: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 544.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 146/313 [00:46<00:50,  3.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 146: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 396.50 MiB is free. Including non-PyTorch memory, this process has 4.35 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 147/313 [00:46<00:47,  3.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 147: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 544.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 148/313 [00:47<00:59,  2.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 148: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 396.50 MiB is free. Including non-PyTorch memory, this process has 4.35 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 149/313 [00:47<01:11,  2.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 149: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 544.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 150/313 [00:48<01:05,  2.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 150: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 398.50 MiB is free. Including non-PyTorch memory, this process has 4.35 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 151/313 [00:48<00:56,  2.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 151: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 544.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▊     | 152/313 [00:48<00:56,  2.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 152: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 398.50 MiB is free. Including non-PyTorch memory, this process has 4.35 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 153/313 [00:49<00:56,  2.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 153: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 544.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 154/313 [00:49<00:51,  3.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 154: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 398.50 MiB is free. Including non-PyTorch memory, this process has 4.35 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████▉     | 155/313 [00:49<00:49,  3.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 155: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 544.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████▉     | 156/313 [00:49<00:46,  3.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 156: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 398.50 MiB is free. Including non-PyTorch memory, this process has 4.35 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 157/313 [00:50<00:44,  3.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 157: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 544.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 158/313 [00:50<00:43,  3.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 158: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 398.50 MiB is free. Including non-PyTorch memory, this process has 4.35 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 159/313 [00:50<00:42,  3.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 159: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 544.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 160/313 [00:50<00:42,  3.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 160: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 398.50 MiB is free. Including non-PyTorch memory, this process has 4.35 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████▏    | 161/313 [00:51<00:43,  3.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 161: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 544.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 162/313 [00:51<00:47,  3.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 162: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 398.50 MiB is free. Including non-PyTorch memory, this process has 4.35 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 163/313 [00:52<00:53,  2.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 163: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 544.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 164/313 [00:52<00:56,  2.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 164: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 398.50 MiB is free. Including non-PyTorch memory, this process has 4.35 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 165/313 [00:52<00:56,  2.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 165: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 544.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 166/313 [00:53<00:51,  2.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 166: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 398.50 MiB is free. Including non-PyTorch memory, this process has 4.35 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 167/313 [00:53<00:50,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 167: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 544.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▎    | 168/313 [00:53<00:47,  3.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 168: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 398.50 MiB is free. Including non-PyTorch memory, this process has 4.35 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 169/313 [00:54<00:44,  3.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 169: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 544.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 170/313 [00:54<00:46,  3.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 170: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 398.50 MiB is free. Including non-PyTorch memory, this process has 4.35 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 171/313 [00:54<00:43,  3.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 171: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 544.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 172/313 [00:54<00:40,  3.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 172: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 398.50 MiB is free. Including non-PyTorch memory, this process has 4.35 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 173/313 [00:55<00:42,  3.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 173: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 544.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 174/313 [00:55<00:44,  3.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 174: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 398.50 MiB is free. Including non-PyTorch memory, this process has 4.35 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 175/313 [00:55<00:42,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 175: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 544.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 176/313 [00:56<00:42,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 176: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 396.50 MiB is free. Including non-PyTorch memory, this process has 4.35 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 178/313 [00:57<00:51,  2.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 177: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 544.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 178: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 398.50 MiB is free. Including non-PyTorch memory, this process has 4.35 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 179/313 [00:57<00:46,  2.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 179: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 544.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 180/313 [00:57<00:44,  2.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 180: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 398.50 MiB is free. Including non-PyTorch memory, this process has 4.35 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 181/313 [00:57<00:42,  3.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 181: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 544.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 182/313 [00:58<00:39,  3.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 182: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 396.50 MiB is free. Including non-PyTorch memory, this process has 4.35 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 184/313 [00:58<00:41,  3.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 183: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 544.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 184: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 398.50 MiB is free. Including non-PyTorch memory, this process has 4.35 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 185/313 [00:59<00:41,  3.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 185: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 544.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 186/313 [00:59<00:40,  3.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 186: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 398.50 MiB is free. Including non-PyTorch memory, this process has 4.35 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████▉    | 187/313 [00:59<00:37,  3.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 187: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 544.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 188/313 [00:59<00:35,  3.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 188: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 398.50 MiB is free. Including non-PyTorch memory, this process has 4.35 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 189/313 [01:00<00:38,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 189: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 544.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 190/313 [01:00<00:36,  3.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 190: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 396.50 MiB is free. Including non-PyTorch memory, this process has 4.35 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 191/313 [01:00<00:35,  3.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 191: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 544.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████▏   | 192/313 [01:01<00:34,  3.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 192: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 396.50 MiB is free. Including non-PyTorch memory, this process has 4.35 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 193/313 [01:01<00:35,  3.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 193: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 544.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 194/313 [01:01<00:39,  3.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 194: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 398.50 MiB is free. Including non-PyTorch memory, this process has 4.35 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 195/313 [01:02<00:42,  2.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 195: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 544.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 196/313 [01:02<00:43,  2.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 196: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 398.50 MiB is free. Including non-PyTorch memory, this process has 4.35 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 197/313 [01:02<00:39,  2.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 197: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 544.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 198/313 [01:03<00:37,  3.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 198: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 398.50 MiB is free. Including non-PyTorch memory, this process has 4.35 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▎   | 199/313 [01:03<00:34,  3.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 199: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 544.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 200/313 [01:03<00:33,  3.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 200: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 398.50 MiB is free. Including non-PyTorch memory, this process has 4.35 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 201/313 [01:04<00:31,  3.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 201: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 544.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▍   | 202/313 [01:04<00:30,  3.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 202: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 398.50 MiB is free. Including non-PyTorch memory, this process has 4.35 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▍   | 203/313 [01:04<00:30,  3.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 203: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 544.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 204/313 [01:04<00:31,  3.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 204: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 396.50 MiB is free. Including non-PyTorch memory, this process has 4.35 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 205/313 [01:05<00:31,  3.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 205: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 544.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 206/313 [01:05<00:33,  3.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 206: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 396.50 MiB is free. Including non-PyTorch memory, this process has 4.35 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 207/313 [01:05<00:34,  3.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 207: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 544.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▋   | 208/313 [01:06<00:33,  3.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 208: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 396.50 MiB is free. Including non-PyTorch memory, this process has 4.35 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 209/313 [01:06<00:37,  2.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 209: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 544.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 210/313 [01:07<00:42,  2.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 210: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 396.50 MiB is free. Including non-PyTorch memory, this process has 4.35 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 211/313 [01:07<00:39,  2.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 211: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 544.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 212/313 [01:07<00:38,  2.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 212: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 398.50 MiB is free. Including non-PyTorch memory, this process has 4.35 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 213/313 [01:08<00:34,  2.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 213: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 544.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 214/313 [01:08<00:40,  2.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 214: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 398.50 MiB is free. Including non-PyTorch memory, this process has 4.35 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▊   | 215/313 [01:09<00:36,  2.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 215: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 544.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 216/313 [01:09<00:36,  2.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 216: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 398.50 MiB is free. Including non-PyTorch memory, this process has 4.35 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 217/313 [01:09<00:32,  2.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 217: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 544.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████▉   | 218/313 [01:10<00:34,  2.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 218: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 398.50 MiB is free. Including non-PyTorch memory, this process has 4.35 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████▉   | 219/313 [01:10<00:32,  2.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 219: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 544.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 220/313 [01:10<00:33,  2.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 220: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 398.50 MiB is free. Including non-PyTorch memory, this process has 4.35 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 221/313 [01:11<00:31,  2.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 221: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 544.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 222/313 [01:11<00:29,  3.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 222: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 398.50 MiB is free. Including non-PyTorch memory, this process has 4.35 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 223/313 [01:11<00:29,  3.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 223: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 544.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 224/313 [01:11<00:27,  3.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 224: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 398.50 MiB is free. Including non-PyTorch memory, this process has 4.35 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 225/313 [01:12<00:25,  3.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 225: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 544.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 226/313 [01:12<00:26,  3.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 226: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 398.50 MiB is free. Including non-PyTorch memory, this process has 4.35 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 227/313 [01:12<00:24,  3.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 227: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 544.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 228/313 [01:13<00:23,  3.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 228: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 398.50 MiB is free. Including non-PyTorch memory, this process has 4.35 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 229/313 [01:13<00:22,  3.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 229: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 544.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 230/313 [01:13<00:21,  3.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 230: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 398.50 MiB is free. Including non-PyTorch memory, this process has 4.35 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 231/313 [01:13<00:21,  3.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 231: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 544.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 232/313 [01:14<00:22,  3.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 232: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 398.50 MiB is free. Including non-PyTorch memory, this process has 4.35 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 233/313 [01:14<00:26,  3.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 233: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 544.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▍  | 234/313 [01:14<00:24,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 234: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 398.50 MiB is free. Including non-PyTorch memory, this process has 4.35 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 235/313 [01:15<00:29,  2.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 235: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 544.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 236/313 [01:15<00:26,  2.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 236: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 398.50 MiB is free. Including non-PyTorch memory, this process has 4.35 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 237/313 [01:16<00:27,  2.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 237: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 544.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 238/313 [01:16<00:25,  2.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 238: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 398.50 MiB is free. Including non-PyTorch memory, this process has 4.35 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▋  | 239/313 [01:16<00:23,  3.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 239: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 544.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 240/313 [01:16<00:21,  3.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 240: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 398.50 MiB is free. Including non-PyTorch memory, this process has 4.35 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 241/313 [01:17<00:20,  3.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 241: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 544.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 242/313 [01:17<00:19,  3.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 242: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 398.50 MiB is free. Including non-PyTorch memory, this process has 4.35 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 243/313 [01:17<00:18,  3.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 243: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 544.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 244/313 [01:17<00:18,  3.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 244: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 398.50 MiB is free. Including non-PyTorch memory, this process has 4.35 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 245/313 [01:18<00:18,  3.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 245: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 544.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▊  | 246/313 [01:18<00:17,  3.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 246: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 398.50 MiB is free. Including non-PyTorch memory, this process has 4.35 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 247/313 [01:18<00:17,  3.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 247: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 544.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 248/313 [01:18<00:16,  3.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 248: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 398.50 MiB is free. Including non-PyTorch memory, this process has 4.35 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████▉  | 249/313 [01:19<00:16,  3.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 249: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 544.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████▉  | 250/313 [01:19<00:17,  3.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 250: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 398.50 MiB is free. Including non-PyTorch memory, this process has 4.35 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 251/313 [01:19<00:18,  3.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 251: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 544.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 252/313 [01:20<00:22,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 252: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 398.50 MiB is free. Including non-PyTorch memory, this process has 4.35 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 253/313 [01:20<00:20,  2.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 253: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 544.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 254/313 [01:20<00:18,  3.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 254: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 398.50 MiB is free. Including non-PyTorch memory, this process has 4.35 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████▏ | 255/313 [01:21<00:18,  3.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 255: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 544.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 256/313 [01:21<00:16,  3.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 256: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 398.50 MiB is free. Including non-PyTorch memory, this process has 4.35 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 257/313 [01:21<00:15,  3.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 257: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 544.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 258/313 [01:22<00:16,  3.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 258: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 398.50 MiB is free. Including non-PyTorch memory, this process has 4.35 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 259/313 [01:22<00:15,  3.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 259: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 544.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 260/313 [01:22<00:15,  3.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 260: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 398.50 MiB is free. Including non-PyTorch memory, this process has 4.35 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 261/313 [01:22<00:15,  3.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 261: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 544.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▎ | 262/313 [01:23<00:14,  3.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 262: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 398.50 MiB is free. Including non-PyTorch memory, this process has 4.35 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 263/313 [01:23<00:14,  3.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 263: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 544.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 264/313 [01:23<00:14,  3.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 264: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 398.50 MiB is free. Including non-PyTorch memory, this process has 4.35 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 265/313 [01:24<00:13,  3.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 265: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 544.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 266/313 [01:24<00:13,  3.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 266: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 398.50 MiB is free. Including non-PyTorch memory, this process has 4.35 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 267/313 [01:24<00:14,  3.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 267: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 544.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 268/313 [01:25<00:13,  3.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 268: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 398.50 MiB is free. Including non-PyTorch memory, this process has 4.35 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 269/313 [01:25<00:17,  2.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 269: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 544.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▋ | 270/313 [01:25<00:15,  2.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 270: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 398.50 MiB is free. Including non-PyTorch memory, this process has 4.35 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 271/313 [01:26<00:15,  2.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 271: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 544.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 272/313 [01:26<00:13,  3.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 272: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 398.50 MiB is free. Including non-PyTorch memory, this process has 4.35 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 273/313 [01:26<00:12,  3.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 273: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 544.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 274/313 [01:27<00:12,  3.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 274: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 398.50 MiB is free. Including non-PyTorch memory, this process has 4.35 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 275/313 [01:27<00:12,  2.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 275: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 544.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 276/313 [01:27<00:12,  2.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 276: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 398.50 MiB is free. Including non-PyTorch memory, this process has 4.35 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 278/313 [01:28<00:12,  2.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 277: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 544.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 278: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 398.50 MiB is free. Including non-PyTorch memory, this process has 4.35 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 279/313 [01:28<00:10,  3.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 279: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 544.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 280/313 [01:29<00:13,  2.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 280: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 398.50 MiB is free. Including non-PyTorch memory, this process has 4.35 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████▉ | 281/313 [01:29<00:11,  2.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 281: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 544.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 282/313 [01:29<00:10,  3.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 282: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 398.50 MiB is free. Including non-PyTorch memory, this process has 4.35 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 283/313 [01:30<00:09,  3.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 283: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 544.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 284/313 [01:30<00:10,  2.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 284: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 398.50 MiB is free. Including non-PyTorch memory, this process has 4.35 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 285/313 [01:30<00:09,  2.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 285: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 544.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████▏| 286/313 [01:31<00:08,  3.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 286: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 398.50 MiB is free. Including non-PyTorch memory, this process has 4.35 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 287/313 [01:31<00:08,  3.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 287: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 544.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 288/313 [01:31<00:08,  3.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 288: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 398.50 MiB is free. Including non-PyTorch memory, this process has 4.35 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 289/313 [01:32<00:07,  3.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 289: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 544.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 290/313 [01:32<00:06,  3.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 290: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 398.50 MiB is free. Including non-PyTorch memory, this process has 4.35 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 291/313 [01:32<00:06,  3.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 291: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 544.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 292/313 [01:33<00:06,  3.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 292: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 398.50 MiB is free. Including non-PyTorch memory, this process has 4.35 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▎| 293/313 [01:33<00:06,  3.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 293: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 544.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 294/313 [01:33<00:05,  3.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 294: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 398.50 MiB is free. Including non-PyTorch memory, this process has 4.35 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 295/313 [01:33<00:05,  3.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 295: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 544.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▍| 296/313 [01:34<00:04,  3.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 296: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 398.50 MiB is free. Including non-PyTorch memory, this process has 4.35 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▍| 297/313 [01:34<00:04,  3.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 297: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 544.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 298/313 [01:34<00:04,  3.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 298: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 398.50 MiB is free. Including non-PyTorch memory, this process has 4.35 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 299/313 [01:35<00:03,  3.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 299: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 544.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 300/313 [01:35<00:03,  3.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 300: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 398.50 MiB is free. Including non-PyTorch memory, this process has 4.35 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 301/313 [01:35<00:03,  3.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 301: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 544.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▋| 302/313 [01:35<00:03,  3.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 302: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 398.50 MiB is free. Including non-PyTorch memory, this process has 4.35 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 303/313 [01:36<00:02,  3.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 303: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 544.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 304/313 [01:36<00:02,  3.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 304: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 398.50 MiB is free. Including non-PyTorch memory, this process has 4.35 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 305/313 [01:36<00:02,  3.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 305: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 544.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 306/313 [01:37<00:02,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 306: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 398.50 MiB is free. Including non-PyTorch memory, this process has 4.35 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 307/313 [01:37<00:01,  3.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 307: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 544.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 308/313 [01:37<00:01,  2.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 308: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 398.50 MiB is free. Including non-PyTorch memory, this process has 4.35 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▊| 309/313 [01:38<00:01,  3.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 309: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 544.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 310/313 [01:38<00:00,  3.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 310: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 398.50 MiB is free. Including non-PyTorch memory, this process has 4.35 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 311/313 [01:38<00:00,  3.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 311: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 544.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 312/313 [01:38<00:00,  3.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([8, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([8, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [01:39<00:00,  3.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500, Train Loss: 0.0146, Train Acc: 0.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "Input x shape: torch.Size([13, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([13, 128])\n",
      "Epoch 1, Val Loss: 5.3665, Val Acc: 0.90%\n",
      "当前学习率: 0.002000\n",
      "保存最佳模型，验证准确率: 0.90%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/313 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 0: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 574.50 MiB is free. Including non-PyTorch memory, this process has 4.18 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 971.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/313 [00:01<07:29,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 1: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 360.50 MiB is free. Including non-PyTorch memory, this process has 4.39 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 2/313 [00:01<04:33,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 2: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 542.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1002.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 3/313 [00:02<03:14,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 3: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 392.50 MiB is free. Including non-PyTorch memory, this process has 4.36 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 4/313 [00:02<02:49,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 4: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 542.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1002.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 5/313 [00:03<02:38,  1.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 5: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 392.50 MiB is free. Including non-PyTorch memory, this process has 4.36 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 6/313 [00:03<02:34,  1.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 6: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 542.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1002.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 7/313 [00:03<02:20,  2.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 7: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 392.50 MiB is free. Including non-PyTorch memory, this process has 4.36 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 8/313 [00:04<02:22,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 8: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 542.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1002.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 9/313 [00:04<02:11,  2.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 9: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 392.50 MiB is free. Including non-PyTorch memory, this process has 4.36 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 10/313 [00:05<01:55,  2.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 10: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 542.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1002.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 11/313 [00:05<01:44,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 11: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 392.50 MiB is free. Including non-PyTorch memory, this process has 4.36 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 12/313 [00:05<01:38,  3.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 12: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 542.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1002.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 13/313 [00:05<01:33,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 13: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 392.50 MiB is free. Including non-PyTorch memory, this process has 4.36 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 14/313 [00:06<01:28,  3.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 14: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 542.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1002.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 15/313 [00:06<01:28,  3.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 15: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 392.50 MiB is free. Including non-PyTorch memory, this process has 4.36 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 16/313 [00:06<01:23,  3.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 16: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 542.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1002.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 17/313 [00:07<01:24,  3.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 17: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 392.50 MiB is free. Including non-PyTorch memory, this process has 4.36 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 18/313 [00:07<01:21,  3.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 18: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 542.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1002.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 19/313 [00:07<01:24,  3.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 19: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 392.50 MiB is free. Including non-PyTorch memory, this process has 4.36 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 20/313 [00:07<01:21,  3.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 20: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 542.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1002.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 21/313 [00:08<01:18,  3.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 21: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 392.50 MiB is free. Including non-PyTorch memory, this process has 4.36 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 22/313 [00:08<01:16,  3.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 22: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 542.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1002.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 23/313 [00:08<01:15,  3.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 23: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 392.50 MiB is free. Including non-PyTorch memory, this process has 4.36 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 24/313 [00:08<01:14,  3.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 24: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 542.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1002.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 25/313 [00:09<01:14,  3.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 25: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 392.50 MiB is free. Including non-PyTorch memory, this process has 4.36 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 26/313 [00:09<01:13,  3.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 26: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 542.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1002.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▊         | 27/313 [00:09<01:18,  3.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 27: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 392.50 MiB is free. Including non-PyTorch memory, this process has 4.36 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 28/313 [00:10<01:29,  3.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 28: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 542.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1002.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 29/313 [00:10<01:24,  3.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 29: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 392.50 MiB is free. Including non-PyTorch memory, this process has 4.36 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 30/313 [00:10<01:20,  3.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 30: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 542.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1002.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 31/313 [00:10<01:24,  3.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 31: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 392.50 MiB is free. Including non-PyTorch memory, this process has 4.36 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 32/313 [00:11<01:24,  3.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 32: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 542.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1002.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 33/313 [00:11<01:47,  2.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 33: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 392.50 MiB is free. Including non-PyTorch memory, this process has 4.36 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 34/313 [00:12<01:36,  2.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 34: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 542.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1002.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 35/313 [00:12<02:00,  2.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 35: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 392.50 MiB is free. Including non-PyTorch memory, this process has 4.36 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 36/313 [00:12<01:44,  2.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 36: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 542.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1002.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 37/313 [00:13<02:02,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 37: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 392.50 MiB is free. Including non-PyTorch memory, this process has 4.36 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 38/313 [00:13<01:49,  2.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 38: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 542.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1002.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 39/313 [00:14<01:40,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 39: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 392.50 MiB is free. Including non-PyTorch memory, this process has 4.36 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 40/313 [00:14<01:31,  3.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 40: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 542.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1002.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 41/313 [00:14<01:24,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 41: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 392.50 MiB is free. Including non-PyTorch memory, this process has 4.36 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 42/313 [00:14<01:19,  3.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 42: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 542.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1002.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▎        | 43/313 [00:15<01:21,  3.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 43: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 392.50 MiB is free. Including non-PyTorch memory, this process has 4.36 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 44/313 [00:15<01:24,  3.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 44: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 542.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1002.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 45/313 [00:15<01:30,  2.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 45: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 392.50 MiB is free. Including non-PyTorch memory, this process has 4.36 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 46/313 [00:16<01:23,  3.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 46: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 542.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1002.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 47/313 [00:16<01:32,  2.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 47: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 392.50 MiB is free. Including non-PyTorch memory, this process has 4.36 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 48/313 [00:16<01:27,  3.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 48: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 542.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1002.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 49/313 [00:17<01:33,  2.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 49: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 392.50 MiB is free. Including non-PyTorch memory, this process has 4.36 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 50/313 [00:17<01:35,  2.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 50: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 542.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1002.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▋        | 51/313 [00:17<01:26,  3.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 51: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 392.50 MiB is free. Including non-PyTorch memory, this process has 4.36 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 52/313 [00:18<01:20,  3.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 52: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 542.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1002.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 53/313 [00:18<01:43,  2.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 53: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 392.50 MiB is free. Including non-PyTorch memory, this process has 4.36 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 54/313 [00:19<01:37,  2.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 54: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 542.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1002.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 55/313 [00:19<01:28,  2.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 55: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 392.50 MiB is free. Including non-PyTorch memory, this process has 4.36 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 56/313 [00:19<01:23,  3.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 56: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 542.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1002.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 57/313 [00:19<01:20,  3.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 57: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 392.50 MiB is free. Including non-PyTorch memory, this process has 4.36 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▊        | 58/313 [00:20<01:20,  3.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 58: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 542.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1002.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 59/313 [00:20<01:33,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 59: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 392.50 MiB is free. Including non-PyTorch memory, this process has 4.36 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 60/313 [00:21<01:29,  2.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 60: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 542.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1002.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 61/313 [00:21<01:26,  2.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 61: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 392.50 MiB is free. Including non-PyTorch memory, this process has 4.36 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 62/313 [00:21<01:26,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 62: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 542.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1002.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 63/313 [00:22<01:34,  2.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 63: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 392.50 MiB is free. Including non-PyTorch memory, this process has 4.36 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 64/313 [00:22<01:34,  2.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 64: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 542.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1002.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 65/313 [00:22<01:26,  2.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 65: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 392.50 MiB is free. Including non-PyTorch memory, this process has 4.36 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 66/313 [00:23<01:26,  2.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 66: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 542.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1002.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██▏       | 67/313 [00:23<01:22,  2.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 67: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 392.50 MiB is free. Including non-PyTorch memory, this process has 4.36 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 68/313 [00:23<01:22,  2.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 68: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 542.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1002.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 69/313 [00:24<01:17,  3.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 69: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 392.50 MiB is free. Including non-PyTorch memory, this process has 4.36 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 70/313 [00:24<01:18,  3.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 70: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 542.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1002.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 71/313 [00:24<01:20,  3.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 71: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 392.50 MiB is free. Including non-PyTorch memory, this process has 4.36 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 72/313 [00:25<01:18,  3.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 72: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 540.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 73/313 [00:25<01:24,  2.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 73: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 392.50 MiB is free. Including non-PyTorch memory, this process has 4.36 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▎       | 74/313 [00:25<01:21,  2.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 74: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 540.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 75/313 [00:26<01:26,  2.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 75: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 392.50 MiB is free. Including non-PyTorch memory, this process has 4.36 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 76/313 [00:26<01:22,  2.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 76: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 540.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 77/313 [00:27<01:24,  2.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 77: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 392.50 MiB is free. Including non-PyTorch memory, this process has 4.36 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 78/313 [00:27<01:32,  2.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 78: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 540.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 79/313 [00:27<01:28,  2.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 79: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 392.50 MiB is free. Including non-PyTorch memory, this process has 4.36 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 80/313 [00:28<01:20,  2.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 80: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 540.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 82/313 [00:28<01:12,  3.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 81: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 392.50 MiB is free. Including non-PyTorch memory, this process has 4.36 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 82: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 542.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1002.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 83/313 [00:29<01:24,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 83: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 392.50 MiB is free. Including non-PyTorch memory, this process has 4.36 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 84/313 [00:29<01:23,  2.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 84: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 542.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1002.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 85/313 [00:29<01:17,  2.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 85: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 392.50 MiB is free. Including non-PyTorch memory, this process has 4.36 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 86/313 [00:30<01:12,  3.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 86: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 542.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1002.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 87/313 [00:30<01:07,  3.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 87: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 392.50 MiB is free. Including non-PyTorch memory, this process has 4.36 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 88/313 [00:30<01:04,  3.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 88: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 542.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1002.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 89/313 [00:30<01:01,  3.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 89: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 392.50 MiB is free. Including non-PyTorch memory, this process has 4.36 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 90/313 [00:31<01:00,  3.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 90: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 542.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1002.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 91/313 [00:31<00:59,  3.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 91: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 392.50 MiB is free. Including non-PyTorch memory, this process has 4.36 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 92/313 [00:31<00:58,  3.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 92: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 542.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1002.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 93/313 [00:31<00:57,  3.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 93: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 392.50 MiB is free. Including non-PyTorch memory, this process has 4.36 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 94/313 [00:32<00:56,  3.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 94: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 542.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1002.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 95/313 [00:32<00:56,  3.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 95: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 392.50 MiB is free. Including non-PyTorch memory, this process has 4.36 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 96/313 [00:32<00:55,  3.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 96: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 542.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1002.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 97/313 [00:32<00:55,  3.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 97: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 392.50 MiB is free. Including non-PyTorch memory, this process has 4.36 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███▏      | 98/313 [00:33<00:54,  3.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 98: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 542.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1002.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 99/313 [00:33<00:54,  3.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 99: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 392.50 MiB is free. Including non-PyTorch memory, this process has 4.36 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 100/313 [00:33<01:16,  2.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 100: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 542.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1002.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 101/313 [00:34<01:10,  3.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 101: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 392.50 MiB is free. Including non-PyTorch memory, this process has 4.36 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 102/313 [00:34<01:14,  2.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 102: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 542.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1002.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 103/313 [00:35<01:16,  2.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 103: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 392.50 MiB is free. Including non-PyTorch memory, this process has 4.36 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 104/313 [00:35<01:09,  3.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 104: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 542.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1002.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▎      | 105/313 [00:35<01:04,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 105: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 392.50 MiB is free. Including non-PyTorch memory, this process has 4.36 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 106/313 [00:35<01:02,  3.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 106: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 542.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1002.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 107/313 [00:36<01:03,  3.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 107: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 392.50 MiB is free. Including non-PyTorch memory, this process has 4.36 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▍      | 108/313 [00:36<00:59,  3.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 108: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 540.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▍      | 109/313 [00:36<00:57,  3.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 109: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 392.50 MiB is free. Including non-PyTorch memory, this process has 4.36 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 110/313 [00:36<00:55,  3.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 110: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 540.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 111/313 [00:37<00:54,  3.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 111: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 392.50 MiB is free. Including non-PyTorch memory, this process has 4.36 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 112/313 [00:37<00:54,  3.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 112: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 540.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 113/313 [00:37<00:59,  3.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 113: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 392.50 MiB is free. Including non-PyTorch memory, this process has 4.36 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▋      | 114/313 [00:38<01:01,  3.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 114: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 540.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 115/313 [00:38<01:01,  3.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 115: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 392.50 MiB is free. Including non-PyTorch memory, this process has 4.36 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 116/313 [00:38<01:07,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 116: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 540.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 117/313 [00:39<01:02,  3.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 117: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 392.50 MiB is free. Including non-PyTorch memory, this process has 4.36 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 118/313 [00:39<01:00,  3.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 118: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 540.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 119/313 [00:39<00:57,  3.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 119: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 392.50 MiB is free. Including non-PyTorch memory, this process has 4.36 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 120/313 [00:39<00:56,  3.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 120: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 540.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▊      | 121/313 [00:40<00:55,  3.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 121: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 392.50 MiB is free. Including non-PyTorch memory, this process has 4.36 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 123/313 [00:41<01:07,  2.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 122: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 540.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 123: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 392.50 MiB is free. Including non-PyTorch memory, this process has 4.36 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 124/313 [00:41<01:07,  2.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 124: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 540.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 125/313 [00:41<01:05,  2.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 125: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 392.50 MiB is free. Including non-PyTorch memory, this process has 4.36 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 126/313 [00:42<00:59,  3.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 126: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 540.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 127/313 [00:42<00:55,  3.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 127: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 392.50 MiB is free. Including non-PyTorch memory, this process has 4.36 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 128/313 [00:42<00:59,  3.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 128: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 542.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1002.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 129/313 [00:43<01:01,  3.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 129: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 392.50 MiB is free. Including non-PyTorch memory, this process has 4.36 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 130/313 [00:43<00:55,  3.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 130: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 542.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1002.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 131/313 [00:43<00:56,  3.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 131: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 392.50 MiB is free. Including non-PyTorch memory, this process has 4.36 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 132/313 [00:43<00:56,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 132: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 542.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1002.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 133/313 [00:44<01:00,  3.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 133: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 392.50 MiB is free. Including non-PyTorch memory, this process has 4.36 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 134/313 [00:44<00:57,  3.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 134: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 542.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1002.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 135/313 [00:44<00:55,  3.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 135: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 392.50 MiB is free. Including non-PyTorch memory, this process has 4.36 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 136/313 [00:45<01:01,  2.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 136: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 542.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1002.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 137/313 [00:45<01:04,  2.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 137: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 392.50 MiB is free. Including non-PyTorch memory, this process has 4.36 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 138/313 [00:45<00:56,  3.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 138: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 542.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1002.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 139/313 [00:46<01:01,  2.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 139: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 392.50 MiB is free. Including non-PyTorch memory, this process has 4.36 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▍     | 140/313 [00:46<01:00,  2.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 140: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 540.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 141/313 [00:46<00:56,  3.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 141: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 392.50 MiB is free. Including non-PyTorch memory, this process has 4.36 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 142/313 [00:47<00:56,  3.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 142: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 540.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 143/313 [00:47<00:55,  3.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 143: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 392.50 MiB is free. Including non-PyTorch memory, this process has 4.36 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 144/313 [00:47<00:54,  3.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 144: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 542.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1002.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▋     | 145/313 [00:48<00:50,  3.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 145: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 392.50 MiB is free. Including non-PyTorch memory, this process has 4.36 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 146/313 [00:48<00:49,  3.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 146: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 540.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 147/313 [00:48<00:52,  3.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 147: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 392.50 MiB is free. Including non-PyTorch memory, this process has 4.36 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 148/313 [00:49<00:53,  3.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 148: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 540.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 149/313 [00:49<00:56,  2.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 149: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 392.50 MiB is free. Including non-PyTorch memory, this process has 4.36 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 150/313 [00:50<01:00,  2.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 150: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 542.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1002.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 151/313 [00:50<00:55,  2.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 151: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 392.50 MiB is free. Including non-PyTorch memory, this process has 4.36 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▊     | 152/313 [00:50<00:58,  2.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 152: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 542.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1002.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 153/313 [00:51<01:00,  2.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 153: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 392.50 MiB is free. Including non-PyTorch memory, this process has 4.36 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 154/313 [00:51<01:01,  2.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 154: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 542.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1002.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████▉     | 155/313 [00:51<00:56,  2.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 155: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 392.50 MiB is free. Including non-PyTorch memory, this process has 4.36 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████▉     | 156/313 [00:52<00:59,  2.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 156: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 542.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1002.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 157/313 [00:52<00:53,  2.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 157: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 392.50 MiB is free. Including non-PyTorch memory, this process has 4.36 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 158/313 [00:52<00:52,  2.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 158: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 542.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1002.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 159/313 [00:53<00:53,  2.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 159: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 392.50 MiB is free. Including non-PyTorch memory, this process has 4.36 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 160/313 [00:53<00:47,  3.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 160: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 542.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1002.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████▏    | 161/313 [00:53<00:47,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 161: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 392.50 MiB is free. Including non-PyTorch memory, this process has 4.36 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 162/313 [00:53<00:44,  3.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 162: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 542.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1002.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 163/313 [00:54<00:45,  3.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 163: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 392.50 MiB is free. Including non-PyTorch memory, this process has 4.36 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 164/313 [00:54<00:43,  3.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 164: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 542.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1002.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 165/313 [00:54<00:42,  3.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 165: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 392.50 MiB is free. Including non-PyTorch memory, this process has 4.36 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 166/313 [00:55<00:43,  3.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 166: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 542.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1002.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 167/313 [00:55<00:42,  3.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 167: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 392.50 MiB is free. Including non-PyTorch memory, this process has 4.36 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▎    | 168/313 [00:55<00:40,  3.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 168: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 542.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1002.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 169/313 [00:56<00:56,  2.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 169: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 392.50 MiB is free. Including non-PyTorch memory, this process has 4.36 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 170/313 [00:56<00:53,  2.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 170: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 542.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1002.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 171/313 [00:57<01:05,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 171: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 392.50 MiB is free. Including non-PyTorch memory, this process has 4.36 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 172/313 [00:57<01:12,  1.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 172: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 542.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1002.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 173/313 [00:58<01:02,  2.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 173: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 392.50 MiB is free. Including non-PyTorch memory, this process has 4.36 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 174/313 [00:58<01:00,  2.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 174: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 542.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1002.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 175/313 [00:59<00:59,  2.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 175: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 392.50 MiB is free. Including non-PyTorch memory, this process has 4.36 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 176/313 [00:59<00:54,  2.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 176: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 540.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 177/313 [00:59<00:51,  2.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 177: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 392.50 MiB is free. Including non-PyTorch memory, this process has 4.36 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 178/313 [01:00<00:47,  2.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 178: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 542.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1002.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 179/313 [01:00<00:45,  2.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 179: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 392.50 MiB is free. Including non-PyTorch memory, this process has 4.36 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 180/313 [01:00<00:41,  3.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 180: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 542.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1002.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 181/313 [01:00<00:40,  3.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 181: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 392.50 MiB is free. Including non-PyTorch memory, this process has 4.36 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 182/313 [01:01<00:41,  3.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 182: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 540.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 183/313 [01:01<00:39,  3.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 183: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 392.50 MiB is free. Including non-PyTorch memory, this process has 4.36 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 184/313 [01:01<00:38,  3.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 184: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 542.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1002.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 185/313 [01:02<00:37,  3.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 185: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 392.50 MiB is free. Including non-PyTorch memory, this process has 4.36 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 186/313 [01:02<00:36,  3.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 186: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 542.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1002.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████▉    | 187/313 [01:02<00:38,  3.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 187: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 392.50 MiB is free. Including non-PyTorch memory, this process has 4.36 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 188/313 [01:02<00:35,  3.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 188: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 542.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1002.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 189/313 [01:03<00:34,  3.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 189: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 392.50 MiB is free. Including non-PyTorch memory, this process has 4.36 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 190/313 [01:03<00:33,  3.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 190: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 540.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 191/313 [01:03<00:38,  3.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 191: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 392.50 MiB is free. Including non-PyTorch memory, this process has 4.36 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████▏   | 192/313 [01:04<00:36,  3.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 192: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 540.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 193/313 [01:04<00:35,  3.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 193: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 392.50 MiB is free. Including non-PyTorch memory, this process has 4.36 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 194/313 [01:04<00:33,  3.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 194: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 542.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1002.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 195/313 [01:04<00:32,  3.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 195: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 392.50 MiB is free. Including non-PyTorch memory, this process has 4.36 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 196/313 [01:05<00:31,  3.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 196: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 542.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1002.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 197/313 [01:05<00:30,  3.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 197: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 392.50 MiB is free. Including non-PyTorch memory, this process has 4.36 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 198/313 [01:05<00:31,  3.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 198: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 542.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1002.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▎   | 199/313 [01:06<00:30,  3.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 199: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 392.50 MiB is free. Including non-PyTorch memory, this process has 4.36 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 200/313 [01:06<00:32,  3.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 200: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 542.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1002.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 201/313 [01:06<00:36,  3.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 201: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 392.50 MiB is free. Including non-PyTorch memory, this process has 4.36 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▍   | 202/313 [01:07<00:33,  3.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 202: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 542.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1002.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▍   | 203/313 [01:07<00:36,  2.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 203: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 392.50 MiB is free. Including non-PyTorch memory, this process has 4.36 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 204/313 [01:07<00:32,  3.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 204: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 540.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 205/313 [01:08<00:36,  2.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 205: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 392.50 MiB is free. Including non-PyTorch memory, this process has 4.36 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 206/313 [01:08<00:33,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 206: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 540.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 207/313 [01:08<00:32,  3.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 207: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 392.50 MiB is free. Including non-PyTorch memory, this process has 4.36 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▋   | 208/313 [01:08<00:34,  3.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 208: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 540.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 209/313 [01:09<00:35,  2.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 209: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 392.50 MiB is free. Including non-PyTorch memory, this process has 4.36 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 210/313 [01:09<00:32,  3.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 210: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 540.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 211/313 [01:09<00:32,  3.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 211: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 392.50 MiB is free. Including non-PyTorch memory, this process has 4.36 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 212/313 [01:10<00:31,  3.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 212: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 542.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1002.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 213/313 [01:10<00:29,  3.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 213: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 392.50 MiB is free. Including non-PyTorch memory, this process has 4.36 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 214/313 [01:10<00:31,  3.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 214: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 542.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1002.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▊   | 215/313 [01:11<00:29,  3.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 215: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 392.50 MiB is free. Including non-PyTorch memory, this process has 4.36 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 216/313 [01:11<00:28,  3.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 216: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 542.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1002.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████▉   | 218/313 [01:12<00:30,  3.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 217: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 392.50 MiB is free. Including non-PyTorch memory, this process has 4.36 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 218: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 542.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1002.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████▉   | 219/313 [01:12<00:28,  3.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 219: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 392.50 MiB is free. Including non-PyTorch memory, this process has 4.36 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 220/313 [01:12<00:26,  3.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 220: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 542.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1002.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 221/313 [01:12<00:27,  3.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 221: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 392.50 MiB is free. Including non-PyTorch memory, this process has 4.36 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 222/313 [01:13<00:26,  3.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 222: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 542.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1002.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 223/313 [01:13<00:26,  3.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 223: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 392.50 MiB is free. Including non-PyTorch memory, this process has 4.36 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 224/313 [01:13<00:25,  3.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 224: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 542.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1002.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 225/313 [01:14<00:24,  3.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 225: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 392.50 MiB is free. Including non-PyTorch memory, this process has 4.36 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 226/313 [01:14<00:24,  3.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 226: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 542.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1002.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 227/313 [01:14<00:26,  3.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 227: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 392.50 MiB is free. Including non-PyTorch memory, this process has 4.36 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 228/313 [01:14<00:25,  3.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 228: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 542.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1002.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 229/313 [01:15<00:28,  2.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 229: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 392.50 MiB is free. Including non-PyTorch memory, this process has 4.36 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 230/313 [01:15<00:25,  3.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 230: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 542.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1002.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 231/313 [01:16<00:31,  2.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 231: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 392.50 MiB is free. Including non-PyTorch memory, this process has 4.36 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 232/313 [01:16<00:29,  2.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 232: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 542.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1002.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 233/313 [01:16<00:26,  3.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 233: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 392.50 MiB is free. Including non-PyTorch memory, this process has 4.36 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▍  | 234/313 [01:17<00:24,  3.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 234: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 542.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1002.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 235/313 [01:17<00:22,  3.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 235: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 392.50 MiB is free. Including non-PyTorch memory, this process has 4.36 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 236/313 [01:17<00:21,  3.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 236: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 542.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1002.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 237/313 [01:17<00:20,  3.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 237: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 392.50 MiB is free. Including non-PyTorch memory, this process has 4.36 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 238/313 [01:18<00:28,  2.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 238: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 542.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1002.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▋  | 239/313 [01:18<00:26,  2.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 239: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 392.50 MiB is free. Including non-PyTorch memory, this process has 4.36 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 240/313 [01:19<00:31,  2.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 240: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 542.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1002.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 241/313 [01:19<00:29,  2.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 241: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 392.50 MiB is free. Including non-PyTorch memory, this process has 4.36 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 242/313 [01:20<00:27,  2.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 242: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 542.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1002.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 243/313 [01:20<00:25,  2.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 243: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 392.50 MiB is free. Including non-PyTorch memory, this process has 4.36 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 244/313 [01:20<00:22,  3.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 244: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 542.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1002.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 245/313 [01:20<00:23,  2.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 245: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 392.50 MiB is free. Including non-PyTorch memory, this process has 4.36 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▊  | 246/313 [01:21<00:22,  3.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 246: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 542.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1002.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 247/313 [01:21<00:20,  3.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 247: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 392.50 MiB is free. Including non-PyTorch memory, this process has 4.36 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 248/313 [01:21<00:21,  3.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 248: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 542.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1002.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████▉  | 249/313 [01:22<00:19,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 249: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 392.50 MiB is free. Including non-PyTorch memory, this process has 4.36 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████▉  | 250/313 [01:22<00:18,  3.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 250: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 542.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1002.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 251/313 [01:22<00:17,  3.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 251: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 392.50 MiB is free. Including non-PyTorch memory, this process has 4.36 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 252/313 [01:23<00:18,  3.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 252: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 542.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1002.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 253/313 [01:23<00:20,  2.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 253: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 392.50 MiB is free. Including non-PyTorch memory, this process has 4.36 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 254/313 [01:23<00:18,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 254: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 542.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1002.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████▏ | 255/313 [01:23<00:17,  3.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 255: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 392.50 MiB is free. Including non-PyTorch memory, this process has 4.36 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 256/313 [01:24<00:16,  3.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 256: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 542.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1002.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 257/313 [01:24<00:15,  3.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 257: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 392.50 MiB is free. Including non-PyTorch memory, this process has 4.36 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 258/313 [01:24<00:16,  3.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 258: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 542.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1002.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 259/313 [01:25<00:15,  3.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 259: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 392.50 MiB is free. Including non-PyTorch memory, this process has 4.36 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 260/313 [01:25<00:14,  3.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 260: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 542.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1002.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 261/313 [01:25<00:14,  3.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 261: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 392.50 MiB is free. Including non-PyTorch memory, this process has 4.36 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▎ | 262/313 [01:25<00:14,  3.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 262: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 542.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1002.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 263/313 [01:26<00:15,  3.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 263: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 392.50 MiB is free. Including non-PyTorch memory, this process has 4.36 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 264/313 [01:26<00:14,  3.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 264: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 542.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1002.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 265/313 [01:26<00:13,  3.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 265: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 392.50 MiB is free. Including non-PyTorch memory, this process has 4.36 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 266/313 [01:27<00:13,  3.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 266: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 542.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1002.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 267/313 [01:27<00:13,  3.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 267: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 392.50 MiB is free. Including non-PyTorch memory, this process has 4.36 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 268/313 [01:27<00:12,  3.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 268: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 542.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1002.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 269/313 [01:27<00:13,  3.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 269: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 392.50 MiB is free. Including non-PyTorch memory, this process has 4.36 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▋ | 270/313 [01:28<00:12,  3.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 270: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 542.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1002.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 271/313 [01:28<00:12,  3.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 271: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 392.50 MiB is free. Including non-PyTorch memory, this process has 4.36 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 272/313 [01:28<00:11,  3.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 272: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 542.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1002.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 273/313 [01:29<00:11,  3.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 273: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 392.50 MiB is free. Including non-PyTorch memory, this process has 4.36 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 274/313 [01:29<00:10,  3.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 274: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 542.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1002.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 275/313 [01:29<00:10,  3.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 275: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 392.50 MiB is free. Including non-PyTorch memory, this process has 4.36 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 276/313 [01:29<00:10,  3.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 276: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 542.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1002.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 277/313 [01:30<00:09,  3.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 277: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 392.50 MiB is free. Including non-PyTorch memory, this process has 4.36 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 278/313 [01:30<00:09,  3.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 278: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 542.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1002.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 279/313 [01:30<00:08,  3.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 279: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 392.50 MiB is free. Including non-PyTorch memory, this process has 4.36 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 280/313 [01:30<00:08,  3.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 280: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 542.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1002.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████▉ | 281/313 [01:31<00:08,  3.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 281: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 392.50 MiB is free. Including non-PyTorch memory, this process has 4.36 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 282/313 [01:31<00:07,  3.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 282: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 542.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1002.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 283/313 [01:31<00:09,  3.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 283: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 392.50 MiB is free. Including non-PyTorch memory, this process has 4.36 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 284/313 [01:32<00:08,  3.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 284: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 542.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1002.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 285/313 [01:32<00:08,  3.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 285: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 392.50 MiB is free. Including non-PyTorch memory, this process has 4.36 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████▏| 286/313 [01:32<00:09,  2.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 286: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 542.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1002.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 287/313 [01:33<00:09,  2.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 287: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 392.50 MiB is free. Including non-PyTorch memory, this process has 4.36 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 288/313 [01:33<00:08,  3.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 288: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 542.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1002.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 289/313 [01:33<00:07,  3.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 289: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 392.50 MiB is free. Including non-PyTorch memory, this process has 4.36 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 290/313 [01:34<00:07,  3.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 290: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 542.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1002.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 291/313 [01:34<00:06,  3.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 291: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 392.50 MiB is free. Including non-PyTorch memory, this process has 4.36 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 292/313 [01:34<00:06,  3.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 292: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 542.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1002.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▎| 293/313 [01:35<00:06,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 293: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 392.50 MiB is free. Including non-PyTorch memory, this process has 4.36 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 294/313 [01:35<00:05,  3.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 294: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 542.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1002.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 295/313 [01:35<00:05,  3.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 295: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 392.50 MiB is free. Including non-PyTorch memory, this process has 4.36 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▍| 296/313 [01:35<00:04,  3.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 296: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 542.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1002.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▍| 297/313 [01:36<00:04,  3.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 297: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 392.50 MiB is free. Including non-PyTorch memory, this process has 4.36 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 298/313 [01:36<00:04,  3.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 298: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 542.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1002.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 299/313 [01:36<00:04,  3.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 299: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 392.50 MiB is free. Including non-PyTorch memory, this process has 4.36 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 300/313 [01:37<00:03,  3.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 300: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 542.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1002.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 301/313 [01:37<00:03,  3.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 301: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 392.50 MiB is free. Including non-PyTorch memory, this process has 4.36 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▋| 302/313 [01:37<00:03,  2.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 302: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 542.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1002.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 303/313 [01:38<00:03,  3.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 303: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 392.50 MiB is free. Including non-PyTorch memory, this process has 4.36 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 304/313 [01:38<00:02,  3.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 304: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 542.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1002.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 305/313 [01:38<00:02,  3.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 305: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 392.50 MiB is free. Including non-PyTorch memory, this process has 4.36 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 306/313 [01:38<00:01,  3.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 306: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 542.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1002.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 307/313 [01:39<00:01,  3.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 307: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 392.50 MiB is free. Including non-PyTorch memory, this process has 4.36 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 308/313 [01:39<00:01,  3.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 308: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 542.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1002.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▊| 309/313 [01:39<00:01,  3.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 309: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 392.50 MiB is free. Including non-PyTorch memory, this process has 4.36 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 310/313 [01:39<00:00,  4.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 310: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 542.50 MiB is free. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 1002.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 311/313 [01:40<00:00,  4.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 311: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 392.50 MiB is free. Including non-PyTorch memory, this process has 4.36 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [01:40<00:00,  3.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([8, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([8, 128])\n",
      "Epoch 2/500, Train Loss: 0.0141, Train Acc: 0.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "Input x shape: torch.Size([13, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([13, 128])\n",
      "Epoch 2, Val Loss: 5.4096, Val Acc: 1.08%\n",
      "当前学习率: 0.004000\n",
      "保存最佳模型，验证准确率: 1.08%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/313 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 0: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.47 GiB is free. Including non-PyTorch memory, this process has 3.28 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 33.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/313 [00:01<07:15,  1.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 1: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.35 GiB is free. Including non-PyTorch memory, this process has 3.39 GiB memory in use. Of the allocated memory 3.14 GiB is allocated by PyTorch, and 146.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 2/313 [00:01<03:58,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 2: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.47 GiB is free. Including non-PyTorch memory, this process has 3.28 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 33.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 3/313 [00:02<03:09,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 3: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.35 GiB is free. Including non-PyTorch memory, this process has 3.39 GiB memory in use. Of the allocated memory 3.14 GiB is allocated by PyTorch, and 146.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 4/313 [00:02<02:47,  1.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 4: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.47 GiB is free. Including non-PyTorch memory, this process has 3.28 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 33.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 5/313 [00:02<02:24,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 5: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.35 GiB is free. Including non-PyTorch memory, this process has 3.39 GiB memory in use. Of the allocated memory 3.14 GiB is allocated by PyTorch, and 146.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 6/313 [00:03<02:23,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 6: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.47 GiB is free. Including non-PyTorch memory, this process has 3.28 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 33.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 7/313 [00:03<02:03,  2.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 7: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.35 GiB is free. Including non-PyTorch memory, this process has 3.39 GiB memory in use. Of the allocated memory 3.14 GiB is allocated by PyTorch, and 146.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 8/313 [00:04<01:57,  2.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 8: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.47 GiB is free. Including non-PyTorch memory, this process has 3.28 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 33.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 9/313 [00:04<01:51,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 9: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.35 GiB is free. Including non-PyTorch memory, this process has 3.39 GiB memory in use. Of the allocated memory 3.14 GiB is allocated by PyTorch, and 146.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 10/313 [00:04<01:57,  2.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 10: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.47 GiB is free. Including non-PyTorch memory, this process has 3.28 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 33.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 11/313 [00:05<01:56,  2.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 11: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.35 GiB is free. Including non-PyTorch memory, this process has 3.39 GiB memory in use. Of the allocated memory 3.14 GiB is allocated by PyTorch, and 146.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 12/313 [00:05<01:51,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 12: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.47 GiB is free. Including non-PyTorch memory, this process has 3.28 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 33.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 13/313 [00:05<01:52,  2.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 13: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.35 GiB is free. Including non-PyTorch memory, this process has 3.39 GiB memory in use. Of the allocated memory 3.14 GiB is allocated by PyTorch, and 146.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 14/313 [00:06<01:56,  2.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 14: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.47 GiB is free. Including non-PyTorch memory, this process has 3.28 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 33.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 15/313 [00:06<02:00,  2.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 15: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.35 GiB is free. Including non-PyTorch memory, this process has 3.39 GiB memory in use. Of the allocated memory 3.14 GiB is allocated by PyTorch, and 146.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 16/313 [00:07<01:53,  2.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 16: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.47 GiB is free. Including non-PyTorch memory, this process has 3.28 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 33.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 17/313 [00:07<01:49,  2.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 17: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.35 GiB is free. Including non-PyTorch memory, this process has 3.39 GiB memory in use. Of the allocated memory 3.14 GiB is allocated by PyTorch, and 146.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 18/313 [00:07<01:45,  2.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 18: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.47 GiB is free. Including non-PyTorch memory, this process has 3.28 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 33.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 19/313 [00:08<01:38,  2.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 19: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.35 GiB is free. Including non-PyTorch memory, this process has 3.39 GiB memory in use. Of the allocated memory 3.14 GiB is allocated by PyTorch, and 146.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 20/313 [00:08<01:38,  2.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 20: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.47 GiB is free. Including non-PyTorch memory, this process has 3.28 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 33.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 21/313 [00:08<01:37,  3.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 21: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.35 GiB is free. Including non-PyTorch memory, this process has 3.39 GiB memory in use. Of the allocated memory 3.14 GiB is allocated by PyTorch, and 146.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 22/313 [00:09<01:37,  2.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 22: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.47 GiB is free. Including non-PyTorch memory, this process has 3.28 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 33.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 23/313 [00:09<01:46,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 23: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.35 GiB is free. Including non-PyTorch memory, this process has 3.39 GiB memory in use. Of the allocated memory 3.14 GiB is allocated by PyTorch, and 146.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 24/313 [00:09<01:40,  2.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 24: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.47 GiB is free. Including non-PyTorch memory, this process has 3.28 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 33.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 25/313 [00:10<01:44,  2.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 25: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.35 GiB is free. Including non-PyTorch memory, this process has 3.39 GiB memory in use. Of the allocated memory 3.14 GiB is allocated by PyTorch, and 146.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 26/313 [00:10<01:34,  3.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 26: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.47 GiB is free. Including non-PyTorch memory, this process has 3.28 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 33.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▊         | 27/313 [00:10<01:53,  2.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 27: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.35 GiB is free. Including non-PyTorch memory, this process has 3.39 GiB memory in use. Of the allocated memory 3.14 GiB is allocated by PyTorch, and 146.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 28/313 [00:11<01:43,  2.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 28: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.47 GiB is free. Including non-PyTorch memory, this process has 3.28 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 33.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 29/313 [00:11<01:42,  2.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 29: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.35 GiB is free. Including non-PyTorch memory, this process has 3.39 GiB memory in use. Of the allocated memory 3.14 GiB is allocated by PyTorch, and 146.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 30/313 [00:11<01:36,  2.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 30: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.47 GiB is free. Including non-PyTorch memory, this process has 3.28 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 33.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 31/313 [00:12<01:36,  2.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 31: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.35 GiB is free. Including non-PyTorch memory, this process has 3.39 GiB memory in use. Of the allocated memory 3.14 GiB is allocated by PyTorch, and 146.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 32/313 [00:12<01:31,  3.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 32: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.47 GiB is free. Including non-PyTorch memory, this process has 3.28 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 33.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 33/313 [00:12<01:31,  3.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 33: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.35 GiB is free. Including non-PyTorch memory, this process has 3.39 GiB memory in use. Of the allocated memory 3.14 GiB is allocated by PyTorch, and 146.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 34/313 [00:13<01:26,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 34: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.47 GiB is free. Including non-PyTorch memory, this process has 3.28 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 33.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 35/313 [00:13<01:29,  3.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 35: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.35 GiB is free. Including non-PyTorch memory, this process has 3.39 GiB memory in use. Of the allocated memory 3.14 GiB is allocated by PyTorch, and 146.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 36/313 [00:13<01:24,  3.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 36: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.47 GiB is free. Including non-PyTorch memory, this process has 3.28 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 33.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 37/313 [00:14<01:23,  3.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 37: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.35 GiB is free. Including non-PyTorch memory, this process has 3.39 GiB memory in use. Of the allocated memory 3.14 GiB is allocated by PyTorch, and 146.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 38/313 [00:14<01:30,  3.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 38: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.47 GiB is free. Including non-PyTorch memory, this process has 3.28 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 33.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 39/313 [00:14<01:28,  3.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 39: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.35 GiB is free. Including non-PyTorch memory, this process has 3.39 GiB memory in use. Of the allocated memory 3.14 GiB is allocated by PyTorch, and 146.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 40/313 [00:15<01:38,  2.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 40: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.47 GiB is free. Including non-PyTorch memory, this process has 3.28 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 33.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 41/313 [00:15<01:35,  2.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 41: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.35 GiB is free. Including non-PyTorch memory, this process has 3.39 GiB memory in use. Of the allocated memory 3.14 GiB is allocated by PyTorch, and 146.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 42/313 [00:15<01:31,  2.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 42: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.47 GiB is free. Including non-PyTorch memory, this process has 3.28 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 33.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▎        | 43/313 [00:16<01:33,  2.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 43: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.35 GiB is free. Including non-PyTorch memory, this process has 3.39 GiB memory in use. Of the allocated memory 3.14 GiB is allocated by PyTorch, and 146.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 44/313 [00:16<01:46,  2.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 44: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.47 GiB is free. Including non-PyTorch memory, this process has 3.28 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 33.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 45/313 [00:17<01:37,  2.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 45: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.35 GiB is free. Including non-PyTorch memory, this process has 3.39 GiB memory in use. Of the allocated memory 3.14 GiB is allocated by PyTorch, and 146.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 46/313 [00:17<01:32,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 46: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.47 GiB is free. Including non-PyTorch memory, this process has 3.28 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 33.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 47/313 [00:17<01:27,  3.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 47: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.35 GiB is free. Including non-PyTorch memory, this process has 3.39 GiB memory in use. Of the allocated memory 3.14 GiB is allocated by PyTorch, and 146.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 48/313 [00:18<01:35,  2.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 48: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.47 GiB is free. Including non-PyTorch memory, this process has 3.28 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 33.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 49/313 [00:18<01:51,  2.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 49: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.35 GiB is free. Including non-PyTorch memory, this process has 3.39 GiB memory in use. Of the allocated memory 3.14 GiB is allocated by PyTorch, and 146.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 50/313 [00:18<01:42,  2.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 50: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.47 GiB is free. Including non-PyTorch memory, this process has 3.28 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 33.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▋        | 51/313 [00:19<01:42,  2.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 51: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.35 GiB is free. Including non-PyTorch memory, this process has 3.39 GiB memory in use. Of the allocated memory 3.14 GiB is allocated by PyTorch, and 146.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 52/313 [00:19<01:33,  2.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 52: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.47 GiB is free. Including non-PyTorch memory, this process has 3.28 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 33.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 53/313 [00:19<01:27,  2.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 53: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.35 GiB is free. Including non-PyTorch memory, this process has 3.39 GiB memory in use. Of the allocated memory 3.14 GiB is allocated by PyTorch, and 146.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 54/313 [00:20<01:24,  3.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 54: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.47 GiB is free. Including non-PyTorch memory, this process has 3.28 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 33.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 55/313 [00:20<01:24,  3.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 55: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.35 GiB is free. Including non-PyTorch memory, this process has 3.39 GiB memory in use. Of the allocated memory 3.14 GiB is allocated by PyTorch, and 146.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 56/313 [00:20<01:22,  3.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 56: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.47 GiB is free. Including non-PyTorch memory, this process has 3.28 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 33.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 57/313 [00:21<01:30,  2.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 57: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.35 GiB is free. Including non-PyTorch memory, this process has 3.39 GiB memory in use. Of the allocated memory 3.14 GiB is allocated by PyTorch, and 146.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▊        | 58/313 [00:21<01:23,  3.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 58: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.47 GiB is free. Including non-PyTorch memory, this process has 3.28 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 33.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 59/313 [00:21<01:20,  3.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 59: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.35 GiB is free. Including non-PyTorch memory, this process has 3.39 GiB memory in use. Of the allocated memory 3.14 GiB is allocated by PyTorch, and 146.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 60/313 [00:22<01:19,  3.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 60: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.47 GiB is free. Including non-PyTorch memory, this process has 3.28 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 33.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 61/313 [00:22<01:17,  3.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 61: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.35 GiB is free. Including non-PyTorch memory, this process has 3.39 GiB memory in use. Of the allocated memory 3.14 GiB is allocated by PyTorch, and 146.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 62/313 [00:22<01:15,  3.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 62: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.47 GiB is free. Including non-PyTorch memory, this process has 3.28 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 33.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 63/313 [00:22<01:13,  3.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 63: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.35 GiB is free. Including non-PyTorch memory, this process has 3.39 GiB memory in use. Of the allocated memory 3.14 GiB is allocated by PyTorch, and 146.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 64/313 [00:23<01:16,  3.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 64: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.47 GiB is free. Including non-PyTorch memory, this process has 3.28 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 33.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 65/313 [00:23<01:15,  3.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 65: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.35 GiB is free. Including non-PyTorch memory, this process has 3.39 GiB memory in use. Of the allocated memory 3.14 GiB is allocated by PyTorch, and 146.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 66/313 [00:24<01:29,  2.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 66: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.47 GiB is free. Including non-PyTorch memory, this process has 3.28 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 33.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██▏       | 67/313 [00:24<01:24,  2.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 67: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.35 GiB is free. Including non-PyTorch memory, this process has 3.39 GiB memory in use. Of the allocated memory 3.14 GiB is allocated by PyTorch, and 146.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 68/313 [00:24<01:20,  3.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 68: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.47 GiB is free. Including non-PyTorch memory, this process has 3.28 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 33.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 69/313 [00:25<01:22,  2.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 69: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.35 GiB is free. Including non-PyTorch memory, this process has 3.39 GiB memory in use. Of the allocated memory 3.14 GiB is allocated by PyTorch, and 146.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 70/313 [00:25<01:24,  2.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 70: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.47 GiB is free. Including non-PyTorch memory, this process has 3.28 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 33.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 71/313 [00:25<01:21,  2.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 71: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.35 GiB is free. Including non-PyTorch memory, this process has 3.39 GiB memory in use. Of the allocated memory 3.14 GiB is allocated by PyTorch, and 146.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 72/313 [00:25<01:15,  3.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 72: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.46 GiB is free. Including non-PyTorch memory, this process has 3.28 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 35.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 73/313 [00:26<01:13,  3.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 73: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.35 GiB is free. Including non-PyTorch memory, this process has 3.39 GiB memory in use. Of the allocated memory 3.14 GiB is allocated by PyTorch, and 146.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▎       | 74/313 [00:26<01:14,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 74: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.46 GiB is free. Including non-PyTorch memory, this process has 3.28 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 35.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 75/313 [00:26<01:13,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 75: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.35 GiB is free. Including non-PyTorch memory, this process has 3.39 GiB memory in use. Of the allocated memory 3.14 GiB is allocated by PyTorch, and 146.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 76/313 [00:27<01:13,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 76: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.46 GiB is free. Including non-PyTorch memory, this process has 3.28 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 35.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 77/313 [00:27<01:15,  3.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 77: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.35 GiB is free. Including non-PyTorch memory, this process has 3.39 GiB memory in use. Of the allocated memory 3.14 GiB is allocated by PyTorch, and 146.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 78/313 [00:27<01:12,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 78: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.46 GiB is free. Including non-PyTorch memory, this process has 3.28 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 35.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 79/313 [00:28<01:18,  2.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 79: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.35 GiB is free. Including non-PyTorch memory, this process has 3.39 GiB memory in use. Of the allocated memory 3.14 GiB is allocated by PyTorch, and 146.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 80/313 [00:28<01:20,  2.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 80: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.46 GiB is free. Including non-PyTorch memory, this process has 3.28 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 35.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 81/313 [00:28<01:20,  2.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 81: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.35 GiB is free. Including non-PyTorch memory, this process has 3.39 GiB memory in use. Of the allocated memory 3.14 GiB is allocated by PyTorch, and 146.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 82/313 [00:29<01:26,  2.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 82: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.47 GiB is free. Including non-PyTorch memory, this process has 3.28 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 33.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 83/313 [00:29<01:22,  2.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 83: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.35 GiB is free. Including non-PyTorch memory, this process has 3.39 GiB memory in use. Of the allocated memory 3.14 GiB is allocated by PyTorch, and 146.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 84/313 [00:30<01:17,  2.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 84: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.47 GiB is free. Including non-PyTorch memory, this process has 3.28 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 33.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 85/313 [00:30<01:14,  3.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 85: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.35 GiB is free. Including non-PyTorch memory, this process has 3.39 GiB memory in use. Of the allocated memory 3.14 GiB is allocated by PyTorch, and 146.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 86/313 [00:30<01:19,  2.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 86: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.47 GiB is free. Including non-PyTorch memory, this process has 3.28 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 33.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 87/313 [00:31<01:16,  2.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 87: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.35 GiB is free. Including non-PyTorch memory, this process has 3.39 GiB memory in use. Of the allocated memory 3.14 GiB is allocated by PyTorch, and 146.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 88/313 [00:31<01:45,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 88: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.47 GiB is free. Including non-PyTorch memory, this process has 3.28 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 33.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 89/313 [00:32<01:32,  2.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 89: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.35 GiB is free. Including non-PyTorch memory, this process has 3.39 GiB memory in use. Of the allocated memory 3.14 GiB is allocated by PyTorch, and 146.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 90/313 [00:32<01:23,  2.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 90: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.47 GiB is free. Including non-PyTorch memory, this process has 3.28 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 33.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 91/313 [00:32<01:19,  2.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 91: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.35 GiB is free. Including non-PyTorch memory, this process has 3.39 GiB memory in use. Of the allocated memory 3.14 GiB is allocated by PyTorch, and 146.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 92/313 [00:32<01:13,  3.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 92: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.47 GiB is free. Including non-PyTorch memory, this process has 3.28 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 33.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 93/313 [00:33<01:25,  2.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 93: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.35 GiB is free. Including non-PyTorch memory, this process has 3.39 GiB memory in use. Of the allocated memory 3.14 GiB is allocated by PyTorch, and 146.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 94/313 [00:33<01:18,  2.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 94: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.47 GiB is free. Including non-PyTorch memory, this process has 3.28 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 33.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 95/313 [00:34<01:20,  2.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 95: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.35 GiB is free. Including non-PyTorch memory, this process has 3.39 GiB memory in use. Of the allocated memory 3.14 GiB is allocated by PyTorch, and 146.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 96/313 [00:34<01:17,  2.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 96: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.47 GiB is free. Including non-PyTorch memory, this process has 3.28 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 33.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 97/313 [00:34<01:14,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 97: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.35 GiB is free. Including non-PyTorch memory, this process has 3.39 GiB memory in use. Of the allocated memory 3.14 GiB is allocated by PyTorch, and 146.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███▏      | 98/313 [00:35<01:12,  2.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 98: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.47 GiB is free. Including non-PyTorch memory, this process has 3.28 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 33.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 99/313 [00:35<01:18,  2.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 99: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.35 GiB is free. Including non-PyTorch memory, this process has 3.39 GiB memory in use. Of the allocated memory 3.14 GiB is allocated by PyTorch, and 146.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 100/313 [00:35<01:19,  2.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 100: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.47 GiB is free. Including non-PyTorch memory, this process has 3.28 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 33.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 101/313 [00:36<01:20,  2.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 101: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.35 GiB is free. Including non-PyTorch memory, this process has 3.39 GiB memory in use. Of the allocated memory 3.14 GiB is allocated by PyTorch, and 146.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 102/313 [00:36<01:13,  2.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 102: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.47 GiB is free. Including non-PyTorch memory, this process has 3.28 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 33.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 103/313 [00:37<01:15,  2.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 103: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.35 GiB is free. Including non-PyTorch memory, this process has 3.39 GiB memory in use. Of the allocated memory 3.14 GiB is allocated by PyTorch, and 146.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 104/313 [00:37<01:10,  2.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 104: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.47 GiB is free. Including non-PyTorch memory, this process has 3.28 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 33.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▎      | 105/313 [00:37<01:16,  2.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 105: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.35 GiB is free. Including non-PyTorch memory, this process has 3.39 GiB memory in use. Of the allocated memory 3.14 GiB is allocated by PyTorch, and 146.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 106/313 [00:38<01:13,  2.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 106: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.47 GiB is free. Including non-PyTorch memory, this process has 3.28 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 33.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 107/313 [00:38<01:19,  2.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 107: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.35 GiB is free. Including non-PyTorch memory, this process has 3.39 GiB memory in use. Of the allocated memory 3.14 GiB is allocated by PyTorch, and 146.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▍      | 108/313 [00:38<01:17,  2.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 108: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.46 GiB is free. Including non-PyTorch memory, this process has 3.28 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 35.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▍      | 109/313 [00:39<01:13,  2.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 109: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.35 GiB is free. Including non-PyTorch memory, this process has 3.39 GiB memory in use. Of the allocated memory 3.14 GiB is allocated by PyTorch, and 146.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 110/313 [00:39<01:11,  2.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 110: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.46 GiB is free. Including non-PyTorch memory, this process has 3.28 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 35.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 111/313 [00:39<01:06,  3.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 111: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.35 GiB is free. Including non-PyTorch memory, this process has 3.39 GiB memory in use. Of the allocated memory 3.14 GiB is allocated by PyTorch, and 146.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 112/313 [00:40<01:08,  2.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 112: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.46 GiB is free. Including non-PyTorch memory, this process has 3.28 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 35.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 113/313 [00:40<01:04,  3.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 113: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.35 GiB is free. Including non-PyTorch memory, this process has 3.39 GiB memory in use. Of the allocated memory 3.14 GiB is allocated by PyTorch, and 146.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▋      | 114/313 [00:40<01:03,  3.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 114: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.46 GiB is free. Including non-PyTorch memory, this process has 3.28 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 35.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 115/313 [00:41<01:07,  2.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 115: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.35 GiB is free. Including non-PyTorch memory, this process has 3.39 GiB memory in use. Of the allocated memory 3.14 GiB is allocated by PyTorch, and 146.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 116/313 [00:41<01:05,  3.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 116: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.46 GiB is free. Including non-PyTorch memory, this process has 3.28 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 35.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 117/313 [00:41<01:04,  3.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 117: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.35 GiB is free. Including non-PyTorch memory, this process has 3.39 GiB memory in use. Of the allocated memory 3.14 GiB is allocated by PyTorch, and 146.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 118/313 [00:42<01:01,  3.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 118: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.46 GiB is free. Including non-PyTorch memory, this process has 3.28 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 35.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 119/313 [00:42<01:02,  3.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 119: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.35 GiB is free. Including non-PyTorch memory, this process has 3.39 GiB memory in use. Of the allocated memory 3.14 GiB is allocated by PyTorch, and 146.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 120/313 [00:42<01:01,  3.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 120: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.46 GiB is free. Including non-PyTorch memory, this process has 3.28 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 35.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▊      | 121/313 [00:43<01:07,  2.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 121: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.35 GiB is free. Including non-PyTorch memory, this process has 3.39 GiB memory in use. Of the allocated memory 3.14 GiB is allocated by PyTorch, and 146.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 122/313 [00:43<01:05,  2.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 122: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.46 GiB is free. Including non-PyTorch memory, this process has 3.28 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 35.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 123/313 [00:43<01:01,  3.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 123: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.35 GiB is free. Including non-PyTorch memory, this process has 3.39 GiB memory in use. Of the allocated memory 3.14 GiB is allocated by PyTorch, and 146.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 124/313 [00:44<01:03,  2.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 124: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.46 GiB is free. Including non-PyTorch memory, this process has 3.28 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 35.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 125/313 [00:44<01:07,  2.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 125: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.35 GiB is free. Including non-PyTorch memory, this process has 3.39 GiB memory in use. Of the allocated memory 3.14 GiB is allocated by PyTorch, and 146.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 126/313 [00:44<01:02,  2.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 126: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.46 GiB is free. Including non-PyTorch memory, this process has 3.28 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 35.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 127/313 [00:45<01:01,  3.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 127: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.35 GiB is free. Including non-PyTorch memory, this process has 3.39 GiB memory in use. Of the allocated memory 3.14 GiB is allocated by PyTorch, and 146.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 128/313 [00:45<01:09,  2.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 128: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.47 GiB is free. Including non-PyTorch memory, this process has 3.28 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 33.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 129/313 [00:46<01:11,  2.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 129: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.35 GiB is free. Including non-PyTorch memory, this process has 3.39 GiB memory in use. Of the allocated memory 3.14 GiB is allocated by PyTorch, and 146.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 130/313 [00:46<01:05,  2.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 130: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.47 GiB is free. Including non-PyTorch memory, this process has 3.28 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 33.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 131/313 [00:46<01:01,  2.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 131: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.35 GiB is free. Including non-PyTorch memory, this process has 3.39 GiB memory in use. Of the allocated memory 3.14 GiB is allocated by PyTorch, and 146.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 132/313 [00:46<00:59,  3.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 132: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.47 GiB is free. Including non-PyTorch memory, this process has 3.28 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 33.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 133/313 [00:47<01:04,  2.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 133: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.35 GiB is free. Including non-PyTorch memory, this process has 3.39 GiB memory in use. Of the allocated memory 3.14 GiB is allocated by PyTorch, and 146.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 134/313 [00:47<01:02,  2.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 134: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.47 GiB is free. Including non-PyTorch memory, this process has 3.28 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 33.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 135/313 [00:47<00:59,  2.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 135: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.35 GiB is free. Including non-PyTorch memory, this process has 3.39 GiB memory in use. Of the allocated memory 3.14 GiB is allocated by PyTorch, and 146.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 136/313 [00:48<00:56,  3.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 136: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.47 GiB is free. Including non-PyTorch memory, this process has 3.28 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 33.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 137/313 [00:48<00:54,  3.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 137: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.35 GiB is free. Including non-PyTorch memory, this process has 3.39 GiB memory in use. Of the allocated memory 3.14 GiB is allocated by PyTorch, and 146.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 138/313 [00:48<00:53,  3.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 138: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.47 GiB is free. Including non-PyTorch memory, this process has 3.28 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 33.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 139/313 [00:49<00:59,  2.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 139: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.35 GiB is free. Including non-PyTorch memory, this process has 3.39 GiB memory in use. Of the allocated memory 3.14 GiB is allocated by PyTorch, and 146.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▍     | 140/313 [00:49<01:04,  2.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 140: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.46 GiB is free. Including non-PyTorch memory, this process has 3.28 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 35.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 141/313 [00:50<01:06,  2.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 141: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.35 GiB is free. Including non-PyTorch memory, this process has 3.39 GiB memory in use. Of the allocated memory 3.14 GiB is allocated by PyTorch, and 146.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 142/313 [00:50<01:07,  2.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 142: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.46 GiB is free. Including non-PyTorch memory, this process has 3.28 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 35.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 143/313 [00:50<01:03,  2.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 143: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.35 GiB is free. Including non-PyTorch memory, this process has 3.39 GiB memory in use. Of the allocated memory 3.14 GiB is allocated by PyTorch, and 146.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 144/313 [00:51<01:00,  2.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 144: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.47 GiB is free. Including non-PyTorch memory, this process has 3.28 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 33.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▋     | 145/313 [00:51<00:59,  2.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 145: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.35 GiB is free. Including non-PyTorch memory, this process has 3.39 GiB memory in use. Of the allocated memory 3.14 GiB is allocated by PyTorch, and 146.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 146/313 [00:51<00:57,  2.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 146: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.46 GiB is free. Including non-PyTorch memory, this process has 3.28 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 35.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 147/313 [00:52<00:58,  2.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 147: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.35 GiB is free. Including non-PyTorch memory, this process has 3.39 GiB memory in use. Of the allocated memory 3.14 GiB is allocated by PyTorch, and 146.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 148/313 [00:52<00:53,  3.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 148: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.46 GiB is free. Including non-PyTorch memory, this process has 3.28 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 35.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 149/313 [00:52<01:01,  2.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 149: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.35 GiB is free. Including non-PyTorch memory, this process has 3.39 GiB memory in use. Of the allocated memory 3.14 GiB is allocated by PyTorch, and 146.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 150/313 [00:53<00:58,  2.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 150: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.47 GiB is free. Including non-PyTorch memory, this process has 3.28 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 33.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 151/313 [00:53<00:54,  2.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 151: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.35 GiB is free. Including non-PyTorch memory, this process has 3.39 GiB memory in use. Of the allocated memory 3.14 GiB is allocated by PyTorch, and 146.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▊     | 152/313 [00:53<00:52,  3.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 152: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.47 GiB is free. Including non-PyTorch memory, this process has 3.28 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 33.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 153/313 [00:54<00:51,  3.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 153: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.35 GiB is free. Including non-PyTorch memory, this process has 3.39 GiB memory in use. Of the allocated memory 3.14 GiB is allocated by PyTorch, and 146.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 154/313 [00:54<00:49,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 154: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.47 GiB is free. Including non-PyTorch memory, this process has 3.28 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 33.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████▉     | 155/313 [00:54<00:48,  3.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 155: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.35 GiB is free. Including non-PyTorch memory, this process has 3.39 GiB memory in use. Of the allocated memory 3.14 GiB is allocated by PyTorch, and 146.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████▉     | 156/313 [00:55<00:48,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 156: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.47 GiB is free. Including non-PyTorch memory, this process has 3.28 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 33.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 157/313 [00:55<00:50,  3.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 157: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.35 GiB is free. Including non-PyTorch memory, this process has 3.39 GiB memory in use. Of the allocated memory 3.14 GiB is allocated by PyTorch, and 146.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 158/313 [00:55<00:47,  3.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 158: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.47 GiB is free. Including non-PyTorch memory, this process has 3.28 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 33.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 159/313 [00:56<00:47,  3.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 159: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.35 GiB is free. Including non-PyTorch memory, this process has 3.39 GiB memory in use. Of the allocated memory 3.14 GiB is allocated by PyTorch, and 146.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 160/313 [00:56<00:46,  3.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 160: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.47 GiB is free. Including non-PyTorch memory, this process has 3.28 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 33.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████▏    | 161/313 [00:56<00:45,  3.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 161: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.35 GiB is free. Including non-PyTorch memory, this process has 3.39 GiB memory in use. Of the allocated memory 3.14 GiB is allocated by PyTorch, and 146.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 162/313 [00:56<00:46,  3.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 162: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.47 GiB is free. Including non-PyTorch memory, this process has 3.28 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 33.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 163/313 [00:57<00:45,  3.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 163: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.35 GiB is free. Including non-PyTorch memory, this process has 3.39 GiB memory in use. Of the allocated memory 3.14 GiB is allocated by PyTorch, and 146.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 164/313 [00:57<00:45,  3.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 164: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.47 GiB is free. Including non-PyTorch memory, this process has 3.28 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 33.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 165/313 [00:58<00:51,  2.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 165: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.35 GiB is free. Including non-PyTorch memory, this process has 3.39 GiB memory in use. Of the allocated memory 3.14 GiB is allocated by PyTorch, and 146.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 166/313 [00:58<00:50,  2.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 166: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.47 GiB is free. Including non-PyTorch memory, this process has 3.28 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 33.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 167/313 [00:58<00:55,  2.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 167: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.35 GiB is free. Including non-PyTorch memory, this process has 3.39 GiB memory in use. Of the allocated memory 3.14 GiB is allocated by PyTorch, and 146.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▎    | 168/313 [00:59<00:55,  2.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 168: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.47 GiB is free. Including non-PyTorch memory, this process has 3.28 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 33.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 169/313 [00:59<00:54,  2.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 169: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.35 GiB is free. Including non-PyTorch memory, this process has 3.39 GiB memory in use. Of the allocated memory 3.14 GiB is allocated by PyTorch, and 146.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 170/313 [00:59<00:52,  2.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 170: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.47 GiB is free. Including non-PyTorch memory, this process has 3.28 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 33.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 171/313 [01:00<00:53,  2.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 171: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.35 GiB is free. Including non-PyTorch memory, this process has 3.39 GiB memory in use. Of the allocated memory 3.14 GiB is allocated by PyTorch, and 146.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 172/313 [01:00<00:49,  2.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 172: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.47 GiB is free. Including non-PyTorch memory, this process has 3.28 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 33.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 173/313 [01:00<00:47,  2.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 173: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.35 GiB is free. Including non-PyTorch memory, this process has 3.39 GiB memory in use. Of the allocated memory 3.14 GiB is allocated by PyTorch, and 146.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 174/313 [01:01<00:45,  3.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 174: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.47 GiB is free. Including non-PyTorch memory, this process has 3.28 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 33.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 175/313 [01:01<00:43,  3.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 175: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.35 GiB is free. Including non-PyTorch memory, this process has 3.39 GiB memory in use. Of the allocated memory 3.14 GiB is allocated by PyTorch, and 146.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 176/313 [01:01<00:45,  2.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 176: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.46 GiB is free. Including non-PyTorch memory, this process has 3.28 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 35.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 177/313 [01:02<00:46,  2.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 177: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.35 GiB is free. Including non-PyTorch memory, this process has 3.39 GiB memory in use. Of the allocated memory 3.14 GiB is allocated by PyTorch, and 146.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 178/313 [01:02<00:48,  2.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 178: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.47 GiB is free. Including non-PyTorch memory, this process has 3.28 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 33.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 179/313 [01:02<00:47,  2.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 179: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.35 GiB is free. Including non-PyTorch memory, this process has 3.39 GiB memory in use. Of the allocated memory 3.14 GiB is allocated by PyTorch, and 146.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 180/313 [01:03<00:43,  3.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 180: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.47 GiB is free. Including non-PyTorch memory, this process has 3.28 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 33.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 181/313 [01:03<00:41,  3.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 181: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.35 GiB is free. Including non-PyTorch memory, this process has 3.39 GiB memory in use. Of the allocated memory 3.14 GiB is allocated by PyTorch, and 146.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 182/313 [01:03<00:41,  3.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 182: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.46 GiB is free. Including non-PyTorch memory, this process has 3.28 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 35.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 183/313 [01:04<00:41,  3.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 183: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.35 GiB is free. Including non-PyTorch memory, this process has 3.39 GiB memory in use. Of the allocated memory 3.14 GiB is allocated by PyTorch, and 146.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 184/313 [01:04<00:42,  3.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 184: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.47 GiB is free. Including non-PyTorch memory, this process has 3.28 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 33.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 185/313 [01:04<00:40,  3.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 185: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.35 GiB is free. Including non-PyTorch memory, this process has 3.39 GiB memory in use. Of the allocated memory 3.14 GiB is allocated by PyTorch, and 146.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 186/313 [01:05<00:38,  3.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 186: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.47 GiB is free. Including non-PyTorch memory, this process has 3.28 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 33.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████▉    | 187/313 [01:05<00:37,  3.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 187: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.35 GiB is free. Including non-PyTorch memory, this process has 3.39 GiB memory in use. Of the allocated memory 3.14 GiB is allocated by PyTorch, and 146.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 188/313 [01:05<00:42,  2.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 188: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.47 GiB is free. Including non-PyTorch memory, this process has 3.28 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 33.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 189/313 [01:06<00:40,  3.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 189: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.35 GiB is free. Including non-PyTorch memory, this process has 3.39 GiB memory in use. Of the allocated memory 3.14 GiB is allocated by PyTorch, and 146.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 190/313 [01:06<00:40,  3.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 190: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.46 GiB is free. Including non-PyTorch memory, this process has 3.28 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 35.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 191/313 [01:06<00:38,  3.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 191: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.35 GiB is free. Including non-PyTorch memory, this process has 3.39 GiB memory in use. Of the allocated memory 3.14 GiB is allocated by PyTorch, and 146.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████▏   | 192/313 [01:07<00:42,  2.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 192: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.46 GiB is free. Including non-PyTorch memory, this process has 3.28 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 35.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 193/313 [01:07<00:40,  2.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 193: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.35 GiB is free. Including non-PyTorch memory, this process has 3.39 GiB memory in use. Of the allocated memory 3.14 GiB is allocated by PyTorch, and 146.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 194/313 [01:07<00:40,  2.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 194: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.47 GiB is free. Including non-PyTorch memory, this process has 3.28 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 33.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 195/313 [01:08<00:38,  3.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 195: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.35 GiB is free. Including non-PyTorch memory, this process has 3.39 GiB memory in use. Of the allocated memory 3.14 GiB is allocated by PyTorch, and 146.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 196/313 [01:08<00:37,  3.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 196: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.47 GiB is free. Including non-PyTorch memory, this process has 3.28 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 33.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 197/313 [01:08<00:36,  3.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 197: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.35 GiB is free. Including non-PyTorch memory, this process has 3.39 GiB memory in use. Of the allocated memory 3.14 GiB is allocated by PyTorch, and 146.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 198/313 [01:09<00:36,  3.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 198: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.47 GiB is free. Including non-PyTorch memory, this process has 3.28 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 33.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▎   | 199/313 [01:09<00:36,  3.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 199: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.35 GiB is free. Including non-PyTorch memory, this process has 3.39 GiB memory in use. Of the allocated memory 3.14 GiB is allocated by PyTorch, and 146.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 200/313 [01:09<00:37,  3.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 200: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.47 GiB is free. Including non-PyTorch memory, this process has 3.28 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 33.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 201/313 [01:10<00:38,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 201: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.35 GiB is free. Including non-PyTorch memory, this process has 3.39 GiB memory in use. Of the allocated memory 3.14 GiB is allocated by PyTorch, and 146.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▍   | 203/313 [01:10<00:38,  2.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 202: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.47 GiB is free. Including non-PyTorch memory, this process has 3.28 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 33.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 203: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.35 GiB is free. Including non-PyTorch memory, this process has 3.39 GiB memory in use. Of the allocated memory 3.14 GiB is allocated by PyTorch, and 146.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 204/313 [01:11<00:41,  2.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 204: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.46 GiB is free. Including non-PyTorch memory, this process has 3.28 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 35.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 205/313 [01:11<00:42,  2.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 205: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.35 GiB is free. Including non-PyTorch memory, this process has 3.39 GiB memory in use. Of the allocated memory 3.14 GiB is allocated by PyTorch, and 146.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 206/313 [01:11<00:40,  2.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 206: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.46 GiB is free. Including non-PyTorch memory, this process has 3.28 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 35.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 207/313 [01:12<00:37,  2.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 207: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.35 GiB is free. Including non-PyTorch memory, this process has 3.39 GiB memory in use. Of the allocated memory 3.14 GiB is allocated by PyTorch, and 146.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▋   | 208/313 [01:12<00:39,  2.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 208: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.46 GiB is free. Including non-PyTorch memory, this process has 3.28 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 35.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 209/313 [01:13<00:37,  2.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 209: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.35 GiB is free. Including non-PyTorch memory, this process has 3.39 GiB memory in use. Of the allocated memory 3.14 GiB is allocated by PyTorch, and 146.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 210/313 [01:13<00:33,  3.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 210: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.46 GiB is free. Including non-PyTorch memory, this process has 3.28 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 35.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 211/313 [01:13<00:33,  3.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 211: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.35 GiB is free. Including non-PyTorch memory, this process has 3.39 GiB memory in use. Of the allocated memory 3.14 GiB is allocated by PyTorch, and 146.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 212/313 [01:13<00:32,  3.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 212: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.47 GiB is free. Including non-PyTorch memory, this process has 3.28 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 33.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 213/313 [01:14<00:32,  3.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 213: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.35 GiB is free. Including non-PyTorch memory, this process has 3.39 GiB memory in use. Of the allocated memory 3.14 GiB is allocated by PyTorch, and 146.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 214/313 [01:14<00:34,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 214: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.47 GiB is free. Including non-PyTorch memory, this process has 3.28 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 33.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▊   | 215/313 [01:15<00:35,  2.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 215: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.35 GiB is free. Including non-PyTorch memory, this process has 3.39 GiB memory in use. Of the allocated memory 3.14 GiB is allocated by PyTorch, and 146.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 216/313 [01:15<00:34,  2.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 216: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.47 GiB is free. Including non-PyTorch memory, this process has 3.28 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 33.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 217/313 [01:15<00:35,  2.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 217: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.35 GiB is free. Including non-PyTorch memory, this process has 3.39 GiB memory in use. Of the allocated memory 3.14 GiB is allocated by PyTorch, and 146.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████▉   | 218/313 [01:16<00:40,  2.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 218: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.47 GiB is free. Including non-PyTorch memory, this process has 3.28 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 33.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████▉   | 219/313 [01:16<00:40,  2.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 219: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.35 GiB is free. Including non-PyTorch memory, this process has 3.39 GiB memory in use. Of the allocated memory 3.14 GiB is allocated by PyTorch, and 146.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 220/313 [01:17<00:36,  2.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 220: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.47 GiB is free. Including non-PyTorch memory, this process has 3.28 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 33.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 221/313 [01:17<00:35,  2.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 221: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.35 GiB is free. Including non-PyTorch memory, this process has 3.39 GiB memory in use. Of the allocated memory 3.14 GiB is allocated by PyTorch, and 146.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 222/313 [01:17<00:33,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 222: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.47 GiB is free. Including non-PyTorch memory, this process has 3.28 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 33.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 223/313 [01:18<00:35,  2.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 223: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.35 GiB is free. Including non-PyTorch memory, this process has 3.39 GiB memory in use. Of the allocated memory 3.14 GiB is allocated by PyTorch, and 146.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 224/313 [01:18<00:31,  2.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 224: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.47 GiB is free. Including non-PyTorch memory, this process has 3.28 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 33.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 225/313 [01:18<00:29,  2.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 225: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.35 GiB is free. Including non-PyTorch memory, this process has 3.39 GiB memory in use. Of the allocated memory 3.14 GiB is allocated by PyTorch, and 146.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 226/313 [01:19<00:28,  3.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 226: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.47 GiB is free. Including non-PyTorch memory, this process has 3.28 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 33.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 227/313 [01:19<00:27,  3.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 227: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.35 GiB is free. Including non-PyTorch memory, this process has 3.39 GiB memory in use. Of the allocated memory 3.14 GiB is allocated by PyTorch, and 146.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 228/313 [01:19<00:25,  3.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 228: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.47 GiB is free. Including non-PyTorch memory, this process has 3.28 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 33.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 229/313 [01:19<00:24,  3.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 229: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.35 GiB is free. Including non-PyTorch memory, this process has 3.39 GiB memory in use. Of the allocated memory 3.14 GiB is allocated by PyTorch, and 146.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 230/313 [01:20<00:30,  2.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 230: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.47 GiB is free. Including non-PyTorch memory, this process has 3.28 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 33.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 231/313 [01:20<00:28,  2.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 231: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.35 GiB is free. Including non-PyTorch memory, this process has 3.39 GiB memory in use. Of the allocated memory 3.14 GiB is allocated by PyTorch, and 146.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 232/313 [01:21<00:27,  2.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 232: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.47 GiB is free. Including non-PyTorch memory, this process has 3.28 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 33.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 233/313 [01:21<00:26,  3.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 233: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.35 GiB is free. Including non-PyTorch memory, this process has 3.39 GiB memory in use. Of the allocated memory 3.14 GiB is allocated by PyTorch, and 146.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▍  | 234/313 [01:21<00:24,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 234: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.47 GiB is free. Including non-PyTorch memory, this process has 3.28 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 33.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 235/313 [01:22<00:27,  2.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 235: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.35 GiB is free. Including non-PyTorch memory, this process has 3.39 GiB memory in use. Of the allocated memory 3.14 GiB is allocated by PyTorch, and 146.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 236/313 [01:22<00:25,  3.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 236: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.47 GiB is free. Including non-PyTorch memory, this process has 3.28 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 33.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 237/313 [01:22<00:24,  3.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 237: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.35 GiB is free. Including non-PyTorch memory, this process has 3.39 GiB memory in use. Of the allocated memory 3.14 GiB is allocated by PyTorch, and 146.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 238/313 [01:22<00:23,  3.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 238: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.47 GiB is free. Including non-PyTorch memory, this process has 3.28 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 33.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▋  | 239/313 [01:23<00:22,  3.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 239: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.35 GiB is free. Including non-PyTorch memory, this process has 3.39 GiB memory in use. Of the allocated memory 3.14 GiB is allocated by PyTorch, and 146.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 240/313 [01:23<00:21,  3.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 240: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.47 GiB is free. Including non-PyTorch memory, this process has 3.28 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 33.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 241/313 [01:23<00:22,  3.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 241: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.35 GiB is free. Including non-PyTorch memory, this process has 3.39 GiB memory in use. Of the allocated memory 3.14 GiB is allocated by PyTorch, and 146.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 242/313 [01:24<00:22,  3.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 242: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.47 GiB is free. Including non-PyTorch memory, this process has 3.28 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 33.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 243/313 [01:24<00:21,  3.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 243: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.35 GiB is free. Including non-PyTorch memory, this process has 3.39 GiB memory in use. Of the allocated memory 3.14 GiB is allocated by PyTorch, and 146.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 244/313 [01:24<00:20,  3.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 244: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.47 GiB is free. Including non-PyTorch memory, this process has 3.28 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 33.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 245/313 [01:25<00:23,  2.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([16, 2000, 256])\n",
      "Multi-scale features shape: torch.Size([16, 128])\n",
      "内存不足错误在批次 245: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 4.75 GiB of which 1.35 GiB is free. Including non-PyTorch memory, this process has 3.39 GiB memory in use. Of the allocated memory 3.14 GiB is allocated by PyTorch, and 146.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▊  | 246/313 [01:25<00:21,  3.16it/s]"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import os\n",
    "import gc  # 垃圾回收\n",
    "import math\n",
    "\n",
    "# 训练器类\n",
    "class Trainer:\n",
    "    def __init__(self, config=Config, model=None):\n",
    "        \"\"\"初始化训练器\"\"\"\n",
    "        self.config = config\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        print(f\"使用设备: {self.device}\")\n",
    "\n",
    "        # 创建模型\n",
    "        if model is None:\n",
    "            raise ValueError(\"初始化Trainer时必须传入model参数\")\n",
    "        self.model = model.to(self.device)  # 使用传入的模型\n",
    "\n",
    "        # 定义损失函数\n",
    "        self.ce_loss = nn.CrossEntropyLoss()\n",
    "\n",
    "        # 定义优化器\n",
    "        self.optimizer = optim.Adam(\n",
    "            self.model.parameters(),\n",
    "            lr=config.LR,\n",
    "            weight_decay=config.WEIGHT_DECAY\n",
    "        )\n",
    "\n",
    "        # 学习率调度器\n",
    "        self.scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            self.optimizer,\n",
    "            mode='min',\n",
    "            factor=0.5,\n",
    "            patience=3,\n",
    "        )\n",
    "\n",
    "        # 学习率预热调度器\n",
    "        self.warmup_scheduler = optim.lr_scheduler.LambdaLR(\n",
    "            self.optimizer,\n",
    "            lr_lambda=lambda epoch: min(1.0, epoch / config.WARMUP_EPOCHS)\n",
    "        )\n",
    "\n",
    "        # 混合精度训练\n",
    "        if config.ENABLE_MIXED_PRECISION and torch.cuda.is_available():\n",
    "            self.scaler = torch.cuda.amp.GradScaler()\n",
    "            print(\"启用混合精度训练\")\n",
    "        else:\n",
    "            self.scaler = None\n",
    "\n",
    "        # 创建检查点目录\n",
    "        os.makedirs(config.CHECKPOINT_DIR, exist_ok=True)\n",
    "\n",
    "        # 早停计数器\n",
    "        self.early_stop_counter = 0\n",
    "        self.best_val_accuracy = 0.0  # 改为基于准确率早停\n",
    "        print(f\"模型预期输入长度: {config.MAX_SEQ_LEN}\")\n",
    "\n",
    "    def train_one_epoch(self, dataloader, epoch):\n",
    "        \"\"\"\n",
    "        训练一个epoch\n",
    "        :param dataloader: 训练数据加载器\n",
    "        :param epoch: 当前epoch\n",
    "        :return: 平均训练损失和准确率\n",
    "        \"\"\"\n",
    "        self.model.train()\n",
    "        total_loss = 0.0\n",
    "        total_ce_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        # 梯度累积\n",
    "        accumulation_steps = self.config.GRADIENT_ACCUMULATION_STEPS\n",
    "        self.optimizer.zero_grad()\n",
    "\n",
    "        progress_bar = tqdm(enumerate(dataloader), total=len(dataloader))\n",
    "        for i, batch in progress_bar:\n",
    "            try:\n",
    "                # 解包批次数据 - 现在接收三个值\n",
    "                inputs, labels, multi_scale_features = batch\n",
    "                inputs, labels = inputs.to(self.device), labels.to(self.device)\n",
    "                multi_scale_features = multi_scale_features.to(self.device)\n",
    "\n",
    "                # 确保输入维度正确 [batch, 1, seq_len]\n",
    "                if inputs.dim() == 2:  # [batch, seq_len]\n",
    "                    inputs = inputs.unsqueeze(1)  # 添加通道维度 -> [batch, 1, seq_len]\n",
    "\n",
    "                # 确保音频长度正确\n",
    "                if inputs.size(2) > self.config.MAX_SEQ_LEN:\n",
    "                    inputs = inputs[:, :, :self.config.MAX_SEQ_LEN]\n",
    "                elif inputs.size(2) < self.config.MAX_SEQ_LEN:\n",
    "                    pad_len = self.config.MAX_SEQ_LEN - inputs.size(2)\n",
    "                    inputs = torch.nn.functional.pad(inputs, (0, pad_len), value=0.0)\n",
    "\n",
    "                # 使用混合精度训练\n",
    "                if self.scaler is not None:\n",
    "                    with torch.cuda.amp.autocast():\n",
    "                        # 前向传播 - 传入多尺度特征\n",
    "                        embeddings, logits = self.model(inputs, multi_scale_features)\n",
    "\n",
    "                        # 计算损失\n",
    "                        ce = self.ce_loss(logits, labels)\n",
    "                        loss = self.config.CE_WEIGHT * ce\n",
    "\n",
    "                        # 梯度累积\n",
    "                        loss = loss / accumulation_steps\n",
    "\n",
    "                    # 反向传播\n",
    "                    self.scaler.scale(loss).backward()\n",
    "\n",
    "                    # 梯度裁剪\n",
    "                    self.scaler.unscale_(self.optimizer)\n",
    "                    torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.config.GRAD_CLIP)\n",
    "\n",
    "                    if (i + 1) % accumulation_steps == 0:\n",
    "                        self.scaler.step(self.optimizer)  # 优化器步骤\n",
    "                        self.scaler.update()\n",
    "                        # 2. 再调用预热调度器\n",
    "                        if epoch <= self.config.WARMUP_EPOCHS:\n",
    "                            self.warmup_scheduler.step()\n",
    "                        self.optimizer.zero_grad()\n",
    "\n",
    "                else:\n",
    "                    # 标准训练（不使用混合精度）\n",
    "                    embeddings, logits = self.model(inputs, multi_scale_features)\n",
    "\n",
    "                    # 计算损失\n",
    "                    ce = self.ce_loss(logits, labels)\n",
    "                    loss = self.config.CE_WEIGHT * ce\n",
    "\n",
    "                    # 梯度累积\n",
    "                    loss = loss / accumulation_steps\n",
    "                    loss.backward()\n",
    "\n",
    "                    # 梯度裁剪\n",
    "                    torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.config.GRAD_CLIP)\n",
    "\n",
    "                    if (i + 1) % accumulation_steps == 0:\n",
    "                        # 1. 先更新参数\n",
    "                        self.optimizer.step()\n",
    "                        # 2. 再调用学习率预热调度器（仅在预热阶段）\n",
    "                        if epoch <= self.config.WARMUP_EPOCHS:\n",
    "                            self.warmup_scheduler.step()  # 移动到optimizer.step()之后\n",
    "                        self.optimizer.zero_grad()\n",
    "\n",
    "                # 统计\n",
    "                total_loss += loss.item() * accumulation_steps\n",
    "                total_ce_loss += ce.item()\n",
    "                _, predicted = logits.max(1)\n",
    "                total += labels.size(0)\n",
    "                correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "                # 更新进度条\n",
    "                if i % 10 == 0:  # 减少更新频率\n",
    "                    accuracy = 100. * correct / total\n",
    "                    avg_loss = total_loss / (i + 1)\n",
    "                    progress_bar.set_description(\n",
    "                        f\"Epoch {epoch}, Loss: {avg_loss:.4f}, Acc: {accuracy:.2f}%\"\n",
    "                    )\n",
    "\n",
    "                # 手动垃圾回收\n",
    "                if i % 50 == 0:\n",
    "                    torch.cuda.empty_cache()\n",
    "                    gc.collect()\n",
    "\n",
    "            except RuntimeError as e:\n",
    "                if \"out of memory\" in str(e):\n",
    "                    print(f\"内存不足错误在批次 {i}: {e}\")\n",
    "                    torch.cuda.empty_cache()\n",
    "                    gc.collect()\n",
    "                    continue\n",
    "                else:\n",
    "                    raise e\n",
    "\n",
    "        avg_loss = total_loss / len(dataloader)\n",
    "        accuracy = 100. * correct / total\n",
    "        return avg_loss, accuracy\n",
    "\n",
    "    def validate(self, dataloader):\n",
    "        \"\"\"\n",
    "        验证模型性能\n",
    "        :param dataloader: 验证数据加载器\n",
    "        :return: 验证损失和准确率\n",
    "        \"\"\"\n",
    "        self.model.eval()\n",
    "        total_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for i, batch in enumerate(dataloader):\n",
    "                try:\n",
    "                    # 解包批次数据 - 现在接收三个值\n",
    "                    inputs, labels, multi_scale_features = batch\n",
    "                    inputs, labels = inputs.to(self.device), labels.to(self.device)\n",
    "                    multi_scale_features = multi_scale_features.to(self.device)\n",
    "\n",
    "                    # 确保输入维度正确 [batch, 1, seq_len]\n",
    "                    if inputs.dim() == 2:  # [batch, seq_len]\n",
    "                        inputs = inputs.unsqueeze(1)  # 添加通道维度 -> [batch, 1, seq_len]\n",
    "\n",
    "                    # 确保音频长度正确\n",
    "                    if inputs.size(2) > self.config.MAX_SEQ_LEN:\n",
    "                        inputs = inputs[:, :, :self.config.MAX_SEQ_LEN]\n",
    "                    elif inputs.size(2) < self.config.MAX_SEQ_LEN:\n",
    "                        pad_len = self.config.MAX_SEQ_LEN - inputs.size(2)\n",
    "                        inputs = torch.nn.functional.pad(inputs, (0, pad_len), value=0.0)\n",
    "\n",
    "                    # 前向传播 - 传入多尺度特征\n",
    "                    embeddings, logits = self.model(inputs, multi_scale_features)\n",
    "\n",
    "                    # 计算损失\n",
    "                    ce = self.ce_loss(logits, labels)\n",
    "                    loss = self.config.CE_WEIGHT * ce\n",
    "\n",
    "                    total_loss += loss.item()\n",
    "\n",
    "                    # 统计准确率\n",
    "                    _, predicted = logits.max(1)\n",
    "                    total += labels.size(0)\n",
    "                    correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "                    # 内存管理\n",
    "                    if i % 20 == 0:\n",
    "                        torch.cuda.empty_cache()\n",
    "                        gc.collect()\n",
    "\n",
    "                except RuntimeError as e:\n",
    "                    if \"out of memory\" in str(e):\n",
    "                        print(f\"验证时内存不足: {e}\")\n",
    "                        torch.cuda.empty_cache()\n",
    "                        gc.collect()\n",
    "                        continue\n",
    "                    else:\n",
    "                        raise e\n",
    "\n",
    "        avg_loss = total_loss / len(dataloader)\n",
    "        accuracy = 100. * correct / total\n",
    "        return avg_loss, accuracy\n",
    "\n",
    "    def train(self, train_dataloader, val_dataloader):\n",
    "        \"\"\"\n",
    "        完整训练流程\n",
    "        :param train_dataloader: 训练数据加载器\n",
    "        :param val_dataloader: 验证数据加载器\n",
    "        \"\"\"\n",
    "        print(\"开始训练...\")\n",
    "        print(f\"训练集批次: {len(train_dataloader)}, 验证集批次: {len(val_dataloader)}\")\n",
    "\n",
    "        for epoch in range(1, self.config.EPOCHS + 1):\n",
    "            try:\n",
    "                # 应用学习率预热\n",
    "                if epoch <= self.config.WARMUP_EPOCHS:\n",
    "                    self.warmup_scheduler.step()\n",
    "\n",
    "                # 训练一个epoch\n",
    "                train_loss, train_acc = self.train_one_epoch(train_dataloader, epoch)\n",
    "                print(f\"Epoch {epoch}/{self.config.EPOCHS}, Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%\")\n",
    "\n",
    "                # 验证\n",
    "                val_loss, val_acc = self.validate(val_dataloader)\n",
    "                print(f\"Epoch {epoch}, Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%\")\n",
    "\n",
    "                # 更新学习率\n",
    "                self.scheduler.step(val_loss)\n",
    "                current_lr = self.optimizer.param_groups[0]['lr']\n",
    "                print(f\"当前学习率: {current_lr:.6f}\")\n",
    "\n",
    "                # 早停检查 (基于验证准确率)\n",
    "                if val_acc > self.best_val_accuracy + self.config.MIN_DELTA:\n",
    "                    self.best_val_accuracy = val_acc\n",
    "                    self.early_stop_counter = 0\n",
    "                    # 保存最佳模型\n",
    "                    torch.save({\n",
    "                        'epoch': epoch,\n",
    "                        'model_state_dict': self.model.state_dict(),\n",
    "                        'optimizer_state_dict': self.optimizer.state_dict(),\n",
    "                        'val_loss': val_loss,\n",
    "                        'val_accuracy': val_acc\n",
    "                    }, os.path.join(self.config.CHECKPOINT_DIR, 'best_model.pth'))\n",
    "                    print(f\"保存最佳模型，验证准确率: {val_acc:.2f}%\")\n",
    "                else:\n",
    "                    self.early_stop_counter += 1\n",
    "                    if self.early_stop_counter >= self.config.PATIENCE:\n",
    "                        print(f\"早停于第 {epoch} 轮\")\n",
    "                        break\n",
    "\n",
    "                # 定期保存模型\n",
    "                if epoch % self.config.SAVE_INTERVAL == 0:\n",
    "                    torch.save({\n",
    "                        'epoch': epoch,\n",
    "                        'model_state_dict': self.model.state_dict(),\n",
    "                        'optimizer_state_dict': self.optimizer.state_dict(),\n",
    "                        'train_loss': train_loss,\n",
    "                        'train_accuracy': train_acc\n",
    "                    }, os.path.join(self.config.CHECKPOINT_DIR, f'model_epoch_{epoch}.pth'))\n",
    "\n",
    "                # 清理内存\n",
    "                torch.cuda.empty_cache()\n",
    "                gc.collect()\n",
    "\n",
    "            except KeyboardInterrupt:\n",
    "                print(\"训练被用户中断\")\n",
    "                break\n",
    "            except Exception as e:\n",
    "                print(f\"训练错误: {e}\")\n",
    "                torch.cuda.empty_cache()\n",
    "                gc.collect()\n",
    "                continue\n",
    "\n",
    "    def load_checkpoint(self, checkpoint_path):\n",
    "        \"\"\"\n",
    "        加载检查点\n",
    "        :param checkpoint_path: 检查点路径\n",
    "        \"\"\"\n",
    "        checkpoint = torch.load(checkpoint_path, map_location=self.device)\n",
    "        self.model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        if 'optimizer_state_dict' in checkpoint:\n",
    "            self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        epoch = checkpoint.get('epoch', 0)\n",
    "        print(f\"从第 {epoch} 轮加载检查点\")\n",
    "        return epoch\n",
    "\n",
    "# 评估器类\n",
    "class Evaluator:\n",
    "    def __init__(self, model, config=Config):\n",
    "        \"\"\"初始化评估器\"\"\"\n",
    "        self.model = model\n",
    "        self.config = config\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.model.to(self.device)\n",
    "        self.model.eval()\n",
    "\n",
    "    def evaluate_accuracy(self, dataloader):\n",
    "        \"\"\"\n",
    "        评估模型准确率\n",
    "        :param dataloader: 数据加载器\n",
    "        :return: 准确率\n",
    "        \"\"\"\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for i, batch in enumerate(dataloader):\n",
    "                try:\n",
    "                    # 解包批次数据 - 现在接收三个值\n",
    "                    inputs, labels, multi_scale_features = batch\n",
    "                    inputs, labels = inputs.to(self.device), labels.to(self.device)\n",
    "                    multi_scale_features = multi_scale_features.to(self.device)\n",
    "\n",
    "                    # 确保输入维度正确\n",
    "                    if inputs.dim() == 2:  # [batch, seq_len]\n",
    "                        inputs = inputs.unsqueeze(1)  # 添加通道维度 -> [batch, 1, seq_len]\n",
    "\n",
    "                    # 截断过长的序列\n",
    "                    if inputs.size(2) > self.config.MAX_SEQ_LEN:\n",
    "                        inputs = inputs[:, :, :self.config.MAX_SEQ_LEN]\n",
    "\n",
    "                    # 前向传播 - 传入多尺度特征\n",
    "                    _, logits = self.model(inputs, multi_scale_features)\n",
    "                    _, predicted = logits.max(1)\n",
    "                    total += labels.size(0)\n",
    "                    correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "                    # 内存管理\n",
    "                    if i % 20 == 0:\n",
    "                        torch.cuda.empty_cache()\n",
    "                        gc.collect()\n",
    "\n",
    "                except RuntimeError as e:\n",
    "                    if \"out of memory\" in str(e):\n",
    "                        print(f\"评估时内存不足: {e}\")\n",
    "                        torch.cuda.empty_cache()\n",
    "                        gc.collect()\n",
    "                        continue\n",
    "                    else:\n",
    "                        raise e\n",
    "\n",
    "        accuracy = 100. * correct / total\n",
    "        return accuracy\n",
    "\n",
    "# 测试代码\n",
    "if __name__ == \"__main__\":\n",
    "    # 设置较小的批次大小\n",
    "    batch_size = Config.BATCH_SIZE\n",
    "\n",
    "    print(\"创建数据加载器...\")\n",
    "    try:\n",
    "        dataloaders = get_dataloaders(batch_size=batch_size)\n",
    "\n",
    "        if dataloaders is None:\n",
    "            print(\"无法创建数据加载器，退出\")\n",
    "            exit(1)\n",
    "\n",
    "        print(f\"训练集批次数: {len(dataloaders['train'])}\")\n",
    "        print(f\"验证集批次数: {len(dataloaders['val'])}\")\n",
    "        print(f\"测试集批次数: {len(dataloaders['test'])}\")\n",
    "\n",
    "        # 关键修改：从训练集中获取实际说话人数量（类别数）\n",
    "        num_speakers = len(dataloaders[\"train\"].dataset.speaker_to_idx)\n",
    "        print(f\"数据集中实际说话人数量（类别数）: {num_speakers}\")\n",
    "\n",
    "        # 创建训练器前，先初始化模型并传入正确的num_classes\n",
    "        print(\"创建模型和训练器...\")\n",
    "        # 关键修改：确保在创建Trainer时使用正确的num_classes初始化模型\n",
    "        # 1. 初始化模型（传入正确的num_classes）\n",
    "        model = CHiLAPModel(num_classes=num_speakers)\n",
    "        # 2. 将模型传入Trainer，确保优化器初始化时模型已存在\n",
    "        trainer = Trainer(config=Config, model=model)  # 传入model参数\n",
    "\n",
    "        # 测试一个批次\n",
    "        print(\"测试前向传播...\")\n",
    "        try:\n",
    "            # 修改：接收三个返回值\n",
    "            x, y, multi_scale_features = next(iter(dataloaders[\"train\"]))\n",
    "            print(f\"原始输入形状: {x.shape}, 标签形状: {y.shape}, 多尺度特征形状: {multi_scale_features.shape}\")\n",
    "\n",
    "            # 处理输入维度\n",
    "            if x.dim() == 2:  # [batch, seq_len]\n",
    "                x = x.unsqueeze(1)  # 添加通道维度 -> [batch, 1, seq_len]\n",
    "\n",
    "            # 确保音频长度正确\n",
    "            if x.size(2) > Config.MAX_SEQ_LEN:\n",
    "                x = x[:, :, :Config.MAX_SEQ_LEN]\n",
    "            elif x.size(2) < Config.MAX_SEQ_LEN:\n",
    "                pad_len = Config.MAX_SEQ_LEN - x.size(2)\n",
    "                x = torch.nn.functional.pad(x, (0, pad_len), value=0.0)\n",
    "\n",
    "            print(f\"处理后输入形状: {x.shape}\")\n",
    "\n",
    "            x = x.to(trainer.device)\n",
    "            y = y.to(trainer.device)\n",
    "            multi_scale_features = multi_scale_features.to(trainer.device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                # 修改：传入多尺度特征\n",
    "                embeddings, logits = trainer.model(x, multi_scale_features)\n",
    "                print(f\"嵌入形状: {embeddings.shape}, 输出形状: {logits.shape}\")\n",
    "                print(\"前向传播测试成功!\")\n",
    "        except Exception as e:\n",
    "            print(f\"前向传播测试失败: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            exit(1)\n",
    "\n",
    "        # 开始训练\n",
    "        print(\"开始训练...\")\n",
    "        trainer.train(dataloaders[\"train\"], dataloaders[\"val\"])\n",
    "\n",
    "        # 创建评估器\n",
    "        print(\"创建评估器...\")\n",
    "        evaluator = Evaluator(trainer.model)\n",
    "\n",
    "        # 评估模型\n",
    "        print(\"评估模型...\")\n",
    "        test_accuracy = evaluator.evaluate_accuracy(dataloaders[\"test\"])\n",
    "        print(f\"测试集准确率: {test_accuracy:.2f}%\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"程序执行错误: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
