{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19cbb3ef-21d1-4477-b83c-f0893d704685",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "class Config:\n",
    "    # 数据加载器配置\n",
    "    DEBUG_MODE = True\n",
    "    DEBUG_SAMPLE_SIZE = 5000\n",
    "    BASE_DIR = os.getcwd()\n",
    "    LIBRISPEECH_PATH = os.path.join(BASE_DIR, \"devDataset\", \"LibriSpeech\")\n",
    "    SAMPLE_RATE = 16000\n",
    "    DURATION = 1.0\n",
    "    MAX_SAMPLES = int(SAMPLE_RATE * DURATION)\n",
    "    NOISE_TYPES = [\"white\", \"babble\"]\n",
    "    SNR_LEVELS = [0, 5, 10]\n",
    "    BATCH_SIZE = 8\n",
    "    NUM_WORKERS = 2\n",
    "    VALID_RATIO = 0.1\n",
    "    MAX_SEQ_LEN = 16000\n",
    "    \n",
    "    # 模型配置\n",
    "    INPUT_DIM = 1\n",
    "    HIDDEN_DIM = 256\n",
    "    EMBEDDING_DIM = 128\n",
    "    ATTENTION_HEADS = 4\n",
    "\n",
    "    # 复杂混沌模块参数 (从c_hilap_model.py导入)\n",
    "    CHAOS_DIM = 3  # 混沌系统维度\n",
    "    LORENZ_SIGMA = 10.0  # 洛伦兹系统参数\n",
    "    LORENZ_RHO = 28.0  # 洛伦兹系统参数\n",
    "    LORENZ_BETA = 8.0 / 3.0  # 洛伦兹系统参数\n",
    "    CHAOS_STEP_SIZE = 0.01  # 混沌系统积分步长\n",
    "    CHAOS_TIME_STEPS = 10  # 混沌演化时间步数\n",
    "    \n",
    "    # 训练配置\n",
    "    EPOCHS = 500\n",
    "    LR = 0.0005\n",
    "    LR_DECAY = 0.95\n",
    "    WEIGHT_DECAY = 1e-5\n",
    "    SAVE_INTERVAL = 10\n",
    "    VAL_INTERVAL = 1\n",
    "    CHECKPOINT_DIR = \"./checkpoints_T1\"\n",
    "\n",
    "    # 优化参数\n",
    "    WARMUP_EPOCHS = 5\n",
    "    GRAD_CLIP = 1.0\n",
    "\n",
    "    # 损失函数权重\n",
    "    CE_WEIGHT = 1.0\n",
    "    # 暂时不使用复杂的损失函数，专注于评估混沌模块的影响\n",
    "    SYNC_WEIGHT = 0.0  # 相位同步损失权重（设为0）\n",
    "    LYAPUNOV_WEIGHT = 0.0  # 李雅普诺夫稳定性损失权重（设为0）\n",
    "\n",
    "    # 早停参数\n",
    "    PATIENCE = 15 # 增加耐心值，给复杂模块更多时间收敛\n",
    "    MIN_DELTA = 0.001\n",
    "\n",
    "    # 内存优化参数\n",
    "    GRADIENT_ACCUMULATION_STEPS = 4\n",
    "    ENABLE_MIXED_PRECISION = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2dedd7ce-16fa-4205-93d4-30cfa14da541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加载LibriSpeech数据集: /users/tianyuey/Project/devDataset/LibriSpeech\n",
      "处理子集: dev-clean\n",
      "处理子集: dev-other\n",
      "找到 73 个不同的说话人\n",
      "有效文件: 5000/5000\n",
      "找到 73 个不同的说话人\n",
      "最终 train 数据集大小: 5000 个样本\n",
      "加载LibriSpeech数据集: /users/tianyuey/Project/devDataset/LibriSpeech\n",
      "处理子集: dev-clean\n",
      "处理子集: dev-other\n",
      "找到 73 个不同的说话人\n",
      "有效文件: 557/557\n",
      "找到 73 个不同的说话人\n",
      "最终 val 数据集大小: 557 个样本\n",
      "加载LibriSpeech数据集: /users/tianyuey/Project/devDataset/LibriSpeech\n",
      "处理子集: dev-clean\n",
      "处理子集: dev-other\n",
      "找到 73 个不同的说话人\n",
      "有效文件: 5567/5567\n",
      "找到 73 个不同的说话人\n",
      "最终 test 数据集大小: 5567 个样本\n",
      "加载LibriSpeech数据集: /users/tianyuey/Project/devDataset/LibriSpeech\n",
      "处理子集: dev-clean\n",
      "处理子集: dev-other\n",
      "找到 73 个不同的说话人\n",
      "有效文件: 5567/5567\n",
      "找到 73 个不同的说话人\n",
      "最终 test 数据集大小: 5567 个样本\n",
      "训练集: 5000 样本\n",
      "验证集: 557 样本\n",
      "测试集: 5567 样本\n",
      "带噪声测试集: 5567 样本\n",
      "总说话人数: 73\n",
      "音频数据形状: torch.Size([8, 16000]), 标签形状: torch.Size([8])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import librosa\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import soundfile as sf\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 噪声生成与注入\n",
    "class NoiseInjector:\n",
    "    @staticmethod\n",
    "    def generate_white_noise(length):\n",
    "        return np.random.randn(length).astype(np.float32)\n",
    "\n",
    "    @staticmethod\n",
    "    def generate_babble_noise(length, num_speakers=3):\n",
    "        noise = np.zeros(length, dtype=np.float32)\n",
    "        for _ in range(num_speakers):\n",
    "            start = random.randint(0, max(0, length - Config.SAMPLE_RATE))\n",
    "            end = min(start + Config.SAMPLE_RATE, length)\n",
    "            noise[start:end] += np.random.randn(end - start).astype(np.float32)\n",
    "        return noise / num_speakers\n",
    "\n",
    "    @staticmethod\n",
    "    def add_noise(signal, noise_type=\"white\", snr_db=10):\n",
    "        if len(signal) == 0:\n",
    "            return signal\n",
    "        signal_power = np.mean(signal ** 2)\n",
    "        if signal_power < 1e-10:\n",
    "            return signal\n",
    "\n",
    "        signal_db = 10 * np.log10(signal_power)\n",
    "        noise = (NoiseInjector.generate_white_noise(len(signal)) if noise_type == \"white\"\n",
    "                 else NoiseInjector.generate_babble_noise(len(signal)))\n",
    "        noise_power = np.mean(noise ** 2)\n",
    "        noise_db = -100 if noise_power < 1e-10 else 10 * np.log10(noise_power)\n",
    "        target_noise_db = signal_db - snr_db\n",
    "        noise_scale = 10 ** ((target_noise_db - noise_db) / 20)\n",
    "        noisy_signal = signal + noise * noise_scale\n",
    "        max_val = np.max(np.abs(noisy_signal))\n",
    "        if max_val > 1e-5:\n",
    "            noisy_signal = noisy_signal / max_val\n",
    "        return noisy_signal\n",
    "\n",
    "\n",
    "# 数据集类\n",
    "class SpeakerRecognitionDataset(Dataset):\n",
    "    def __init__(self, split=\"train\", add_noise=False, noise_type=\"white\", snr_db=10):\n",
    "        self.split = split\n",
    "        self.add_noise = add_noise\n",
    "        self.noise_type = noise_type\n",
    "        self.snr_db = snr_db\n",
    "\n",
    "        self.audio_paths, self.labels = self._load_dataset()\n",
    "        self.speaker_to_idx = self._build_speaker_map()\n",
    "\n",
    "        # 调试模式：限制样本数\n",
    "        if Config.DEBUG_MODE:\n",
    "            if split == \"train\":\n",
    "                self.audio_paths = self.audio_paths[:Config.DEBUG_SAMPLE_SIZE]\n",
    "                self.labels = self.labels[:Config.DEBUG_SAMPLE_SIZE]\n",
    "            elif split == \"val\":\n",
    "                self.audio_paths = self.audio_paths[:min(Config.DEBUG_SAMPLE_SIZE // 2, len(self.audio_paths))]\n",
    "                self.labels = self.labels[:min(Config.DEBUG_SAMPLE_SIZE // 2, len(self.labels))]\n",
    "\n",
    "        self._validate_dataset()\n",
    "        print(f\"最终 {split} 数据集大小: {len(self.audio_paths)} 个样本\")\n",
    "\n",
    "    def _load_dataset(self):\n",
    "        audio_paths, labels = [], []\n",
    "        root = Config.LIBRISPEECH_PATH\n",
    "        if not os.path.exists(root):\n",
    "            print(f\"错误: LibriSpeech路径不存在 - {root}\")\n",
    "            return [], []\n",
    "\n",
    "        print(f\"加载LibriSpeech数据集: {root}\")\n",
    "        # 只遍历 dev-clean 和 dev-other\n",
    "        for subset_dir in [\"dev-clean\", \"dev-other\"]:\n",
    "            subset_path = os.path.join(root, subset_dir)\n",
    "            if not os.path.isdir(subset_path):\n",
    "                continue\n",
    "            print(f\"处理子集: {subset_dir}\")\n",
    "            for speaker_dir in os.listdir(subset_path):\n",
    "                speaker_path = os.path.join(subset_path, speaker_dir)\n",
    "                if not os.path.isdir(speaker_path):\n",
    "                    continue\n",
    "                for chapter_dir in os.listdir(speaker_path):\n",
    "                    chapter_path = os.path.join(speaker_path, chapter_dir)\n",
    "                    if not os.path.isdir(chapter_path):\n",
    "                        continue\n",
    "                    for file in os.listdir(chapter_path):\n",
    "                        if file.endswith(\".flac\"):\n",
    "                            audio_paths.append(os.path.join(chapter_path, file))\n",
    "                            labels.append(speaker_dir)\n",
    "\n",
    "        if self.split != \"test\" and len(audio_paths) > 0:\n",
    "            train_paths, val_paths, train_labels, val_labels = train_test_split(\n",
    "                audio_paths, labels, test_size=Config.VALID_RATIO, random_state=42\n",
    "            )\n",
    "            return (train_paths, train_labels) if self.split == \"train\" else (val_paths, val_labels)\n",
    "        return audio_paths, labels\n",
    "\n",
    "    def _build_speaker_map(self):\n",
    "        unique_speakers = sorted(set(self.labels))\n",
    "        print(f\"找到 {len(unique_speakers)} 个不同的说话人\")\n",
    "        return {spk: idx for idx, spk in enumerate(unique_speakers)}\n",
    "\n",
    "    def _validate_dataset(self):\n",
    "        if len(self.audio_paths) == 0:\n",
    "            print(f\"警告: {self.split}数据集为空\")\n",
    "            return\n",
    "        valid_count, invalid_indices = 0, []\n",
    "        for i in range(len(self.audio_paths) - 1, -1, -1):\n",
    "            path = self.audio_paths[i]\n",
    "            try:\n",
    "                if not os.path.exists(path):\n",
    "                    raise FileNotFoundError(\"文件不存在\")\n",
    "                if os.path.getsize(path) < 1024:\n",
    "                    raise ValueError(\"文件太小可能已损坏\")\n",
    "                signal, sr = sf.read(path) if path.endswith('.flac') else librosa.load(path, sr=Config.SAMPLE_RATE)[0:2]\n",
    "                if len(signal) < Config.SAMPLE_RATE // 2:\n",
    "                    raise ValueError(\"音频过短\")\n",
    "                if np.max(np.abs(signal)) < 1e-5:\n",
    "                    raise ValueError(\"接近静音\")\n",
    "                valid_count += 1\n",
    "            except Exception as e:\n",
    "                invalid_indices.append(i)\n",
    "                print(f\"无效文件: {path} - {str(e)}\")\n",
    "        for i in invalid_indices:\n",
    "            self.audio_paths.pop(i)\n",
    "            self.labels.pop(i)\n",
    "        print(f\"有效文件: {valid_count}/{len(self.audio_paths) + len(invalid_indices)}\")\n",
    "        self.speaker_to_idx = self._build_speaker_map()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.audio_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path, speaker_id = self.audio_paths[idx], self.labels[idx]\n",
    "        label = self.speaker_to_idx[speaker_id]\n",
    "        try:\n",
    "            if path.endswith('.flac'):\n",
    "                signal, sr = sf.read(path)\n",
    "                if sr != Config.SAMPLE_RATE:\n",
    "                    signal = librosa.resample(signal, orig_sr=sr, target_sr=Config.SAMPLE_RATE)\n",
    "            else:\n",
    "                signal, sr = librosa.load(path, sr=Config.SAMPLE_RATE, mono=True)\n",
    "        except Exception as e:\n",
    "            print(f\"加载音频错误 {path}: {str(e)}\")\n",
    "            signal = np.zeros(Config.MAX_SAMPLES, dtype=np.float32)\n",
    "\n",
    "        if len(signal) > Config.MAX_SAMPLES:\n",
    "            signal = signal[:Config.MAX_SAMPLES]\n",
    "        elif len(signal) < Config.MAX_SAMPLES:\n",
    "            signal = np.pad(signal, (0, Config.MAX_SAMPLES - len(signal)), mode=\"constant\")\n",
    "\n",
    "        max_val = np.max(np.abs(signal))\n",
    "        if max_val > 1e-5:\n",
    "            signal = signal / max_val\n",
    "\n",
    "        if self.add_noise and self.split == \"train\":\n",
    "            noise_type = random.choice(Config.NOISE_TYPES)\n",
    "            snr_db = random.choice(Config.SNR_LEVELS)\n",
    "            signal = NoiseInjector.add_noise(signal, noise_type, snr_db)\n",
    "\n",
    "        return torch.FloatTensor(signal), label\n",
    "\n",
    "\n",
    "# 数据加载器\n",
    "def get_dataloaders(batch_size=None):\n",
    "    if batch_size is None:\n",
    "        batch_size = Config.BATCH_SIZE\n",
    "    train_dataset = SpeakerRecognitionDataset(split=\"train\")\n",
    "    val_dataset = SpeakerRecognitionDataset(split=\"val\")\n",
    "    test_dataset = SpeakerRecognitionDataset(split=\"test\")\n",
    "\n",
    "    noisy_test_dataset = SpeakerRecognitionDataset(split=\"test\", add_noise=True)\n",
    "\n",
    "    print(f\"训练集: {len(train_dataset)} 样本\")\n",
    "    print(f\"验证集: {len(val_dataset)} 样本\")\n",
    "    print(f\"测试集: {len(test_dataset)} 样本\")\n",
    "    print(f\"带噪声测试集: {len(noisy_test_dataset)} 样本\")\n",
    "    print(f\"总说话人数: {len(train_dataset.speaker_to_idx)}\")\n",
    "\n",
    "    return {\n",
    "        \"train\": DataLoader(train_dataset, batch_size=batch_size, shuffle=True,\n",
    "                            num_workers=Config.NUM_WORKERS, pin_memory=True),\n",
    "        \"val\": DataLoader(val_dataset, batch_size=batch_size, shuffle=False,\n",
    "                          num_workers=Config.NUM_WORKERS, pin_memory=True),\n",
    "        \"test\": DataLoader(test_dataset, batch_size=batch_size, shuffle=False,\n",
    "                           num_workers=Config.NUM_WORKERS, pin_memory=True),\n",
    "        \"noisy_test\": DataLoader(noisy_test_dataset, batch_size=batch_size, shuffle=False,\n",
    "                                 num_workers=Config.NUM_WORKERS, pin_memory=True),\n",
    "    }\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    dataloaders = get_dataloaders()\n",
    "    x, y = next(iter(dataloaders[\"train\"]))\n",
    "    print(f\"音频数据形状: {x.shape}, 标签形状: {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f06dd6f3-ecbd-4576-b7db-73d1ea4e7fd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型结构:\n",
      "CHiLAPModel(\n",
      "  (feature_extractor): Sequential(\n",
      "    (0): Conv1d(1, 256, kernel_size=(5,), stride=(2,), padding=(2,))\n",
      "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): PReLU(num_parameters=1)\n",
      "    (3): Conv1d(256, 256, kernel_size=(5,), stride=(2,), padding=(2,))\n",
      "    (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): PReLU(num_parameters=1)\n",
      "    (6): Conv1d(256, 256, kernel_size=(5,), stride=(2,), padding=(2,))\n",
      "    (7): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (8): PReLU(num_parameters=1)\n",
      "  )\n",
      "  (chaos_layer): LorenzOscillator(\n",
      "    (input_to_chaos): Linear(in_features=256, out_features=3, bias=True)\n",
      "    (chaos_to_output): Linear(in_features=3, out_features=256, bias=True)\n",
      "  )\n",
      "  (attention): SimpleAttention(\n",
      "    (attention): Sequential(\n",
      "      (0): Conv1d(256, 1, kernel_size=(1,), stride=(1,))\n",
      "      (1): Softmax(dim=2)\n",
      "    )\n",
      "  )\n",
      "  (tdnn_block): Sequential(\n",
      "    (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): PReLU(num_parameters=1)\n",
      "    (3): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
      "    (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): PReLU(num_parameters=1)\n",
      "  )\n",
      "  (pooling): StatisticalPooling()\n",
      "  (embedding): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=128, bias=True)\n",
      "    (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): PReLU(num_parameters=1)\n",
      "    (3): Dropout(p=0.2, inplace=False)\n",
      "  )\n",
      "  (classifier): Linear(in_features=128, out_features=10, bias=True)\n",
      ")\n",
      "\n",
      "测试前向传播:\n",
      "输入形状: torch.Size([2, 1, 16000])\n",
      "嵌入向量形状: torch.Size([2, 128])\n",
      "分类输出形状: torch.Size([2, 10])\n",
      "前向传播成功!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "# 从c_hilap_model.py导入的复杂混沌模块\n",
    "class LorenzOscillator(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, chaos_dim=Config.CHAOS_DIM,\n",
    "                 sigma=Config.LORENZ_SIGMA, rho=Config.LORENZ_RHO, beta=Config.LORENZ_BETA):\n",
    "        \"\"\"\n",
    "        洛伦兹混沌振荡器模块\n",
    "        :param input_dim: 输入维度\n",
    "        :param hidden_dim: 隐藏维度\n",
    "        :param chaos_dim: 混沌系统维度\n",
    "        :param sigma, rho, beta: 洛伦兹系统参数\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.chaos_dim = chaos_dim\n",
    "        self.sigma = sigma\n",
    "        self.rho = rho\n",
    "        self.beta = beta\n",
    "\n",
    "        # 输入到混沌系统的映射\n",
    "        self.input_to_chaos = nn.Linear(input_dim, chaos_dim)\n",
    "\n",
    "        # 混沌状态到输出的映射\n",
    "        self.chaos_to_output = nn.Linear(chaos_dim, hidden_dim)\n",
    "\n",
    "        # 自适应耦合权重\n",
    "        self.coupling_weights = nn.Parameter(torch.randn(chaos_dim, chaos_dim) * 0.1)\n",
    "\n",
    "    def lorenz_system(self, t, state, input_signal):\n",
    "        \"\"\"\n",
    "        洛伦兹系统微分方程 - 批处理版本\n",
    "        dx/dt = σ(y - x) + W_x·h_{t-1}\n",
    "        dy/dt = x(ρ - z) - y\n",
    "        dz/dt = xy - βz\n",
    "        \"\"\"\n",
    "        # 拆分状态变量\n",
    "        x = state[:, 0]  # [batch_size]\n",
    "        y = state[:, 1]  # [batch_size]\n",
    "        z = state[:, 2]  # [batch_size]\n",
    "\n",
    "        # 计算混沌系统的导数\n",
    "        dx_dt = self.sigma * (y - x) + torch.einsum('ij,bj->bi', self.coupling_weights[0:1], input_signal).squeeze(1)\n",
    "        dy_dt = x * (self.rho - z) - y + torch.einsum('ij,bj->bi', self.coupling_weights[1:2], input_signal).squeeze(1)\n",
    "        dz_dt = x * y - self.beta * z + torch.einsum('ij,bj->bi', self.coupling_weights[2:3], input_signal).squeeze(1)\n",
    "\n",
    "        # 组合导数\n",
    "        derivatives = torch.stack([dx_dt, dy_dt, dz_dt], dim=1)\n",
    "        return derivatives\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        前向传播\n",
    "        :param x: 输入特征 [batch_size, seq_len, input_dim]\n",
    "        :return: 混沌处理后的特征 [batch_size, seq_len, hidden_dim]\n",
    "        \"\"\"\n",
    "        batch_size, seq_len, _ = x.size()\n",
    "\n",
    "        # 限制序列长度防止内存溢出\n",
    "        if seq_len > Config.MAX_SEQ_LEN:\n",
    "            x = x[:, :Config.MAX_SEQ_LEN, :]\n",
    "            seq_len = Config.MAX_SEQ_LEN\n",
    "\n",
    "        outputs = []\n",
    "        current_state = torch.zeros(batch_size, self.chaos_dim, device=x.device)\n",
    "\n",
    "        for t in range(seq_len):\n",
    "            # 获取当前时间步的输入\n",
    "            input_t = x[:, t, :]\n",
    "\n",
    "            # 将输入映射到混沌系统空间\n",
    "            input_chaos = self.input_to_chaos(input_t)  # [batch_size, chaos_dim]\n",
    "\n",
    "            # 使用RK4方法数值求解洛伦兹系统\n",
    "            k1 = self.lorenz_system(0, current_state, input_chaos)\n",
    "            k2 = self.lorenz_system(0, current_state + 0.5 * Config.CHAOS_STEP_SIZE * k1, input_chaos)\n",
    "            k3 = self.lorenz_system(0, current_state + 0.5 * Config.CHAOS_STEP_SIZE * k2, input_chaos)\n",
    "            k4 = self.lorenz_system(0, current_state + Config.CHAOS_STEP_SIZE * k3, input_chaos)\n",
    "\n",
    "            # 更新状态\n",
    "            current_state = current_state + (Config.CHAOS_STEP_SIZE / 6.0) * (k1 + 2 * k2 + 2 * k3 + k4)\n",
    "\n",
    "            # 将混沌状态映射到输出空间\n",
    "            output_t = self.chaos_to_output(current_state)\n",
    "            outputs.append(output_t)\n",
    "\n",
    "        # 堆叠所有时间步的输出\n",
    "        outputs = torch.stack(outputs, dim=1)  # [batch_size, seq_len, hidden_dim]\n",
    "        return outputs\n",
    "\n",
    "\n",
    "# 简化注意力机制\n",
    "class SimpleAttention(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        \"\"\"\n",
    "        简化的注意力机制\n",
    "        :param input_dim: 输入维度\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Conv1d(input_dim, 1, kernel_size=1),\n",
    "            nn.Softmax(dim=2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        前向传播\n",
    "        :param x: 输入特征 [batch_size, channels, seq_len]\n",
    "        :return: 注意力加权后的特征 [batch_size, channels, seq_len]\n",
    "        \"\"\"\n",
    "        # 计算注意力权重 [batch_size, 1, seq_len]\n",
    "        attn_weights = self.attention(x)\n",
    "\n",
    "        # 应用注意力权重\n",
    "        return x * attn_weights\n",
    "\n",
    "\n",
    "# 统计池化层\n",
    "class StatisticalPooling(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        前向传播\n",
    "        :param x: 输入特征 [batch_size, channels, seq_len]\n",
    "        :return: 池化后的特征 [batch_size, channels*2]\n",
    "        \"\"\"\n",
    "        # 计算均值和标准差\n",
    "        mean = torch.mean(x, dim=2)\n",
    "        std = torch.std(x, dim=2)\n",
    "\n",
    "        # 拼接均值和标准差\n",
    "        return torch.cat((mean, std), dim=1)\n",
    "\n",
    "\n",
    "# 完整的C-HiLAP模型（简化版+复杂混沌模块）\n",
    "class CHiLAPModel(nn.Module):\n",
    "    def __init__(self, input_dim=Config.INPUT_DIM, hidden_dim=Config.HIDDEN_DIM,\n",
    "                 embedding_dim=Config.EMBEDDING_DIM, num_classes=None):\n",
    "        \"\"\"\n",
    "        混沌层次吸引子传播(C-HiLAP)模型 - 简化版+复杂混沌模块\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        # 若未传入num_classes，可设置一个默认值（但实际使用时必须从数据集获取后传入）\n",
    "        if num_classes is None:\n",
    "            raise ValueError(\"必须指定num_classes（说话人数量），请从数据集获取后传入\")\n",
    "\n",
    "        # 特征提取层\n",
    "        self.feature_extractor = nn.Sequential(\n",
    "            nn.Conv1d(input_dim, hidden_dim, kernel_size=5, stride=2, padding=2),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.PReLU(),\n",
    "            nn.Conv1d(hidden_dim, hidden_dim, kernel_size=5, stride=2, padding=2),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.PReLU(),\n",
    "            nn.Conv1d(hidden_dim, hidden_dim, kernel_size=5, stride=2, padding=2),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.PReLU()\n",
    "        )\n",
    "\n",
    "        # 复杂混沌模块 (替换简化版本)\n",
    "        self.chaos_layer = LorenzOscillator(hidden_dim, hidden_dim)\n",
    "\n",
    "        # 注意力层\n",
    "        self.attention = SimpleAttention(hidden_dim)\n",
    "\n",
    "        # TDNN层\n",
    "        self.tdnn_block = nn.Sequential(\n",
    "            nn.Conv1d(hidden_dim, hidden_dim, kernel_size=3, dilation=1, padding=1),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.PReLU(),\n",
    "            nn.Conv1d(hidden_dim, hidden_dim, kernel_size=3, dilation=2, padding=2),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.PReLU()\n",
    "        )\n",
    "\n",
    "        # 池化层\n",
    "        self.pooling = StatisticalPooling()\n",
    "\n",
    "        # 嵌入层\n",
    "        self.embedding = nn.Sequential(\n",
    "            nn.Linear(hidden_dim * 2, embedding_dim),  # 统计池化输出channels*2\n",
    "            nn.BatchNorm1d(embedding_dim),\n",
    "            nn.PReLU(),\n",
    "            nn.Dropout(0.2)\n",
    "        )\n",
    "\n",
    "        # 分类器\n",
    "        self.classifier = nn.Linear(embedding_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        前向传播\n",
    "        :param x: 输入特征 [batch_size, channels, seq_len] 或 [batch_size, seq_len, channels]\n",
    "        :return: 嵌入向量和分类结果\n",
    "        \"\"\"\n",
    "        # 检查输入维度并转换为正确的格式 [batch_size, channels, seq_len]\n",
    "        if x.dim() == 3:\n",
    "            # 如果是 [batch_size, seq_len, channels] 格式\n",
    "            if x.size(1) > x.size(2):  # 序列长度应该大于通道数\n",
    "                x = x.permute(0, 2, 1)  # 转换为 [batch_size, channels, seq_len]\n",
    "\n",
    "        # 限制序列长度防止内存溢出\n",
    "        seq_len = x.size(2)\n",
    "        if seq_len > Config.MAX_SEQ_LEN:\n",
    "            x = x[:, :, :Config.MAX_SEQ_LEN]\n",
    "\n",
    "        # 特征提取\n",
    "        x = self.feature_extractor(x)\n",
    "\n",
    "        # 转置维度以适应复杂混沌模块 [batch_size, channels, seq_len] -> [batch_size, seq_len, channels]\n",
    "        x = x.permute(0, 2, 1)\n",
    "\n",
    "        # 混沌处理 (复杂模块)\n",
    "        x = self.chaos_layer(x)\n",
    "\n",
    "        # 转置回原始维度 [batch_size, seq_len, channels] -> [batch_size, channels, seq_len]\n",
    "        x = x.permute(0, 2, 1)\n",
    "\n",
    "        # 注意力加权\n",
    "        x = self.attention(x)\n",
    "\n",
    "        # TDNN处理\n",
    "        x = self.tdnn_block(x)\n",
    "\n",
    "        # 池化\n",
    "        x = self.pooling(x)\n",
    "\n",
    "        # 嵌入向量\n",
    "        embedding = self.embedding(x)\n",
    "\n",
    "        # 分类\n",
    "        logits = self.classifier(embedding)\n",
    "\n",
    "        return embedding, logits\n",
    "\n",
    "\n",
    "# 测试代码\n",
    "if __name__ == \"__main__\":\n",
    "    # 创建模型实例\n",
    "    model = CHiLAPModel(num_classes=10)  # 添加num_classes参数\n",
    "\n",
    "    print(\"模型结构:\")\n",
    "    print(model)\n",
    "\n",
    "    # 生成随机输入（使用较小的序列长度进行测试）\n",
    "    batch_size = 2\n",
    "    seq_len = Config.MAX_SEQ_LEN\n",
    "    # 正确的输入格式：[batch_size, channels, seq_len]\n",
    "    x = torch.randn(batch_size, 1, seq_len)\n",
    "\n",
    "    print(f\"\\n测试前向传播:\")\n",
    "    print(f\"输入形状: {x.shape}\")\n",
    "\n",
    "    # 前向传播\n",
    "    try:\n",
    "        embedding, logits = model(x)\n",
    "        print(f\"嵌入向量形状: {embedding.shape}\")\n",
    "        print(f\"分类输出形状: {logits.shape}\")\n",
    "        print(\"前向传播成功!\")\n",
    "    except Exception as e:\n",
    "        print(f\"前向传播错误: {e}\")\n",
    "        import traceback\n",
    "\n",
    "        traceback.print_exc()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0535e3-b6d8-4fb9-9efe-cfdf3e747174",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "创建数据加载器...\n",
      "加载LibriSpeech数据集: /users/tianyuey/Project/devDataset/LibriSpeech\n",
      "处理子集: dev-clean\n",
      "处理子集: dev-other\n",
      "找到 73 个不同的说话人\n",
      "有效文件: 5000/5000\n",
      "找到 73 个不同的说话人\n",
      "最终 train 数据集大小: 5000 个样本\n",
      "加载LibriSpeech数据集: /users/tianyuey/Project/devDataset/LibriSpeech\n",
      "处理子集: dev-clean\n",
      "处理子集: dev-other\n",
      "找到 73 个不同的说话人\n",
      "有效文件: 557/557\n",
      "找到 73 个不同的说话人\n",
      "最终 val 数据集大小: 557 个样本\n",
      "加载LibriSpeech数据集: /users/tianyuey/Project/devDataset/LibriSpeech\n",
      "处理子集: dev-clean\n",
      "处理子集: dev-other\n",
      "找到 73 个不同的说话人\n",
      "有效文件: 5567/5567\n",
      "找到 73 个不同的说话人\n",
      "最终 test 数据集大小: 5567 个样本\n",
      "训练集批次数: 625\n",
      "验证集批次数: 70\n",
      "测试集批次数: 696\n",
      "数据集中实际说话人数量（类别数）: 73\n",
      "创建模型和训练器...\n",
      "使用设备: cuda\n",
      "模型预期输入长度: 16000\n",
      "测试前向传播...\n",
      "原始输入形状: torch.Size([8, 16000]), 标签形状: torch.Size([8])\n",
      "处理后输入形状: torch.Size([8, 1, 16000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib64/python3.12/site-packages/torch/optim/lr_scheduler.py:182: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "嵌入形状: torch.Size([8, 128]), 输出形状: torch.Size([8, 73])\n",
      "前向传播测试成功!\n",
      "开始训练...\n",
      "开始训练...\n",
      "训练集批次: 625, 验证集批次: 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 4.3933, Acc: 0.00%:   0%|          | 3/625 [01:19<4:23:24, 25.41s/it]"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import os\n",
    "import gc  # 垃圾回收\n",
    "import math\n",
    "\n",
    "# 训练器类\n",
    "class Trainer:\n",
    "    def __init__(self, config=Config, model=None):\n",
    "        \"\"\"初始化训练器\"\"\"\n",
    "        self.config = config\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        print(f\"使用设备: {self.device}\")\n",
    "\n",
    "        # 创建模型\n",
    "        if model is None:\n",
    "            raise ValueError(\"初始化Trainer时必须传入model参数\")\n",
    "        self.model = model.to(self.device)  # 使用传入的模型\n",
    "\n",
    "        # 定义损失函数\n",
    "        self.ce_loss = nn.CrossEntropyLoss()\n",
    "\n",
    "        # 定义优化器\n",
    "        self.optimizer = optim.Adam(\n",
    "            self.model.parameters(),\n",
    "            lr=config.LR,\n",
    "            weight_decay=config.WEIGHT_DECAY\n",
    "        )\n",
    "\n",
    "        # 学习率调度器\n",
    "        self.scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            self.optimizer,\n",
    "            mode='min',\n",
    "            factor=0.5,\n",
    "            patience=5,  # 增加耐心值\n",
    "        )\n",
    "\n",
    "        # 学习率预热调度器\n",
    "        self.warmup_scheduler = optim.lr_scheduler.LambdaLR(\n",
    "            self.optimizer,\n",
    "            lr_lambda=lambda epoch: min(1.0, epoch / config.WARMUP_EPOCHS)\n",
    "        )\n",
    "\n",
    "        # 混合精度训练\n",
    "        if config.ENABLE_MIXED_PRECISION and torch.cuda.is_available():\n",
    "            self.scaler = torch.cuda.amp.GradScaler()\n",
    "            print(\"启用混合精度训练\")\n",
    "        else:\n",
    "            self.scaler = None\n",
    "\n",
    "        # 创建检查点目录\n",
    "        os.makedirs(config.CHECKPOINT_DIR, exist_ok=True)\n",
    "\n",
    "        # 早停计数器\n",
    "        self.early_stop_counter = 0\n",
    "        self.best_val_accuracy = 0.0  # 改为基于准确率早停\n",
    "        print(f\"模型预期输入长度: {config.MAX_SEQ_LEN}\")\n",
    "\n",
    "    def train_one_epoch(self, dataloader, epoch):\n",
    "        \"\"\"\n",
    "        训练一个epoch\n",
    "        :param dataloader: 训练数据加载器\n",
    "        :param epoch: 当前epoch\n",
    "        :return: 平均训练损失和准确率\n",
    "        \"\"\"\n",
    "        self.model.train()\n",
    "        total_loss = 0.0\n",
    "        total_ce_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        # 梯度累积\n",
    "        accumulation_steps = self.config.GRADIENT_ACCUMULATION_STEPS\n",
    "        self.optimizer.zero_grad()\n",
    "\n",
    "        progress_bar = tqdm(enumerate(dataloader), total=len(dataloader))\n",
    "        for i, (inputs, labels) in progress_bar:\n",
    "            try:\n",
    "                inputs, labels = inputs.to(self.device), labels.to(self.device)\n",
    "\n",
    "                # 确保输入维度正确 [batch, 1, seq_len]\n",
    "                if inputs.dim() == 2:  # [batch, seq_len]\n",
    "                    inputs = inputs.unsqueeze(1)  # 添加通道维度 -> [batch, 1, seq_len]\n",
    "\n",
    "                # 确保音频长度正确\n",
    "                if inputs.size(2) > self.config.MAX_SEQ_LEN:\n",
    "                    inputs = inputs[:, :, :self.config.MAX_SEQ_LEN]\n",
    "                elif inputs.size(2) < self.config.MAX_SEQ_LEN:\n",
    "                    pad_len = self.config.MAX_SEQ_LEN - inputs.size(2)\n",
    "                    inputs = torch.nn.functional.pad(inputs, (0, pad_len), value=0.0)\n",
    "\n",
    "                # 使用混合精度训练\n",
    "                if self.scaler is not None:\n",
    "                    with torch.cuda.amp.autocast():\n",
    "                        # 前向传播\n",
    "                        embeddings, logits = self.model(inputs)\n",
    "\n",
    "                        # 计算损失\n",
    "                        ce = self.ce_loss(logits, labels)\n",
    "                        loss = self.config.CE_WEIGHT * ce\n",
    "\n",
    "                        # 梯度累积\n",
    "                        loss = loss / accumulation_steps\n",
    "\n",
    "                    # 反向传播\n",
    "                    self.scaler.scale(loss).backward()\n",
    "\n",
    "                    # 梯度裁剪（新增，防止复杂模块梯度爆炸）\n",
    "                    self.scaler.unscale_(self.optimizer)\n",
    "                    torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.config.GRAD_CLIP)\n",
    "\n",
    "                    if (i + 1) % accumulation_steps == 0:\n",
    "                        self.scaler.step(self.optimizer)  # 优化器步骤\n",
    "                        self.scaler.update()\n",
    "                        # 2. 再调用预热调度器\n",
    "                        if epoch <= self.config.WARMUP_EPOCHS:\n",
    "                            self.warmup_scheduler.step()\n",
    "                        self.optimizer.zero_grad()\n",
    "\n",
    "                else:\n",
    "                    # 标准训练（不使用混合精度）\n",
    "                    embeddings, logits = self.model(inputs)\n",
    "\n",
    "                    # 计算损失\n",
    "                    ce = self.ce_loss(logits, labels)\n",
    "                    loss = self.config.CE_WEIGHT * ce\n",
    "\n",
    "                    # 梯度累积\n",
    "                    loss = loss / accumulation_steps\n",
    "                    loss.backward()\n",
    "\n",
    "                    # 梯度裁剪（新增，防止复杂模块梯度爆炸）\n",
    "                    torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.config.GRAD_CLIP)\n",
    "\n",
    "                    if (i + 1) % accumulation_steps == 0:\n",
    "                        # 1. 先更新参数\n",
    "                        self.optimizer.step()\n",
    "                        # 2. 再调用学习率预热调度器（仅在预热阶段）\n",
    "                        if epoch <= self.config.WARMUP_EPOCHS:\n",
    "                            self.warmup_scheduler.step()  # 移动到optimizer.step()之后\n",
    "                        self.optimizer.zero_grad()\n",
    "\n",
    "                # 统计\n",
    "                total_loss += loss.item() * accumulation_steps\n",
    "                total_ce_loss += ce.item()\n",
    "                _, predicted = logits.max(1)\n",
    "                total += labels.size(0)\n",
    "                correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "                # 更新进度条\n",
    "                if i % 10 == 0:  # 减少更新频率\n",
    "                    accuracy = 100. * correct / total\n",
    "                    avg_loss = total_loss / (i + 1)\n",
    "                    progress_bar.set_description(\n",
    "                        f\"Epoch {epoch}, Loss: {avg_loss:.4f}, Acc: {accuracy:.2f}%\"\n",
    "                    )\n",
    "\n",
    "                # 手动垃圾回收\n",
    "                if i % 50 == 0:\n",
    "                    torch.cuda.empty_cache()\n",
    "                    gc.collect()\n",
    "\n",
    "            except RuntimeError as e:\n",
    "                if \"out of memory\" in str(e):\n",
    "                    print(f\"内存不足错误在批次 {i}: {e}\")\n",
    "                    torch.cuda.empty_cache()\n",
    "                    gc.collect()\n",
    "                    continue\n",
    "                else:\n",
    "                    raise e\n",
    "\n",
    "        avg_loss = total_loss / len(dataloader)\n",
    "        accuracy = 100. * correct / total\n",
    "        return avg_loss, accuracy\n",
    "\n",
    "    def validate(self, dataloader):\n",
    "        \"\"\"\n",
    "        验证模型性能\n",
    "        :param dataloader: 验证数据加载器\n",
    "        :return: 验证损失和准确率\n",
    "        \"\"\"\n",
    "        self.model.eval()\n",
    "        total_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for i, (inputs, labels) in enumerate(dataloader):\n",
    "                try:\n",
    "                    inputs, labels = inputs.to(self.device), labels.to(self.device)\n",
    "\n",
    "                    # 确保输入维度正确 [batch, 1, seq_len]\n",
    "                    if inputs.dim() == 2:  # [batch, seq_len]\n",
    "                        inputs = inputs.unsqueeze(1)  # 添加通道维度 -> [batch, 1, seq_len]\n",
    "\n",
    "                    # 确保音频长度正确\n",
    "                    if inputs.size(2) > self.config.MAX_SEQ_LEN:\n",
    "                        inputs = inputs[:, :, :self.config.MAX_SEQ_LEN]\n",
    "                    elif inputs.size(2) < self.config.MAX_SEQ_LEN:\n",
    "                        pad_len = self.config.MAX_SEQ_LEN - inputs.size(2)\n",
    "                        inputs = torch.nn.functional.pad(inputs, (0, pad_len), value=0.0)\n",
    "\n",
    "                    # 前向传播\n",
    "                    embeddings, logits = self.model(inputs)\n",
    "\n",
    "                    # 计算损失\n",
    "                    ce = self.ce_loss(logits, labels)\n",
    "                    loss = self.config.CE_WEIGHT * ce\n",
    "\n",
    "                    total_loss += loss.item()\n",
    "\n",
    "                    # 统计准确率\n",
    "                    _, predicted = logits.max(1)\n",
    "                    total += labels.size(0)\n",
    "                    correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "                    # 内存管理\n",
    "                    if i % 20 == 0:\n",
    "                        torch.cuda.empty_cache()\n",
    "                        gc.collect()\n",
    "\n",
    "                except RuntimeError as e:\n",
    "                    if \"out of memory\" in str(e):\n",
    "                        print(f\"验证时内存不足: {e}\")\n",
    "                        torch.cuda.empty_cache()\n",
    "                        gc.collect()\n",
    "                        continue\n",
    "                    else:\n",
    "                        raise e\n",
    "\n",
    "        avg_loss = total_loss / len(dataloader)\n",
    "        accuracy = 100. * correct / total\n",
    "        return avg_loss, accuracy\n",
    "\n",
    "    def train(self, train_dataloader, val_dataloader):\n",
    "        \"\"\"\n",
    "        完整训练流程\n",
    "        :param train_dataloader: 训练数据加载器\n",
    "        :param val_dataloader: 验证数据加载器\n",
    "        \"\"\"\n",
    "        print(\"开始训练...\")\n",
    "        print(f\"训练集批次: {len(train_dataloader)}, 验证集批次: {len(val_dataloader)}\")\n",
    "\n",
    "        for epoch in range(1, self.config.EPOCHS + 1):\n",
    "            try:\n",
    "                # 应用学习率预热\n",
    "                if epoch <= self.config.WARMUP_EPOCHS:\n",
    "                    self.warmup_scheduler.step()\n",
    "\n",
    "                # 训练一个epoch\n",
    "                train_loss, train_acc = self.train_one_epoch(train_dataloader, epoch)\n",
    "                print(f\"Epoch {epoch}/{self.config.EPOCHS}, Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%\")\n",
    "\n",
    "                # 验证\n",
    "                val_loss, val_acc = self.validate(val_dataloader)\n",
    "                print(f\"Epoch {epoch}, Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%\")\n",
    "\n",
    "                # 更新学习率\n",
    "                self.scheduler.step(val_loss)\n",
    "                current_lr = self.optimizer.param_groups[0]['lr']\n",
    "                print(f\"当前学习率: {current_lr:.6f}\")\n",
    "\n",
    "                # 早停检查 (基于验证准确率)\n",
    "                if val_acc > self.best_val_accuracy + self.config.MIN_DELTA:\n",
    "                    self.best_val_accuracy = val_acc\n",
    "                    self.early_stop_counter = 0\n",
    "                    # 保存最佳模型\n",
    "                    torch.save({\n",
    "                        'epoch': epoch,\n",
    "                        'model_state_dict': self.model.state_dict(),\n",
    "                        'optimizer_state_dict': self.optimizer.state_dict(),\n",
    "                        'val_loss': val_loss,\n",
    "                        'val_accuracy': val_acc\n",
    "                    }, os.path.join(self.config.CHECKPOINT_DIR, 'best_model.pth'))\n",
    "                    print(f\"保存最佳模型，验证准确率: {val_acc:.2f}%\")\n",
    "                else:\n",
    "                    self.early_stop_counter += 1\n",
    "                    if self.early_stop_counter >= self.config.PATIENCE:\n",
    "                        print(f\"早停于第 {epoch} 轮\")\n",
    "                        break\n",
    "\n",
    "                # 定期保存模型\n",
    "                if epoch % self.config.SAVE_INTERVAL == 0:\n",
    "                    torch.save({\n",
    "                        'epoch': epoch,\n",
    "                        'model_state_dict': self.model.state_dict(),\n",
    "                        'optimizer_state_dict': self.optimizer.state_dict(),\n",
    "                        'train_loss': train_loss,\n",
    "                        'train_accuracy': train_acc\n",
    "                    }, os.path.join(self.config.CHECKPOINT_DIR, f'model_epoch_{epoch}.pth'))\n",
    "\n",
    "                # 清理内存\n",
    "                torch.cuda.empty_cache()\n",
    "                gc.collect()\n",
    "\n",
    "            except KeyboardInterrupt:\n",
    "                print(\"训练被用户中断\")\n",
    "                break\n",
    "            except Exception as e:\n",
    "                print(f\"训练错误: {e}\")\n",
    "                torch.cuda.empty_cache()\n",
    "                gc.collect()\n",
    "                continue\n",
    "\n",
    "    def load_checkpoint(self, checkpoint_path):\n",
    "        \"\"\"\n",
    "        加载检查点\n",
    "        :param checkpoint_path: 检查点路径\n",
    "        \"\"\"\n",
    "        checkpoint = torch.load(checkpoint_path, map_location=self.device)\n",
    "        self.model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        if 'optimizer_state_dict' in checkpoint:\n",
    "            self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        epoch = checkpoint.get('epoch', 0)\n",
    "        print(f\"从第 {epoch} 轮加载检查点\")\n",
    "        return epoch\n",
    "\n",
    "\n",
    "# 评估器类\n",
    "class Evaluator:\n",
    "    def __init__(self, model, config=Config):\n",
    "        \"\"\"初始化评估器\"\"\"\n",
    "        self.model = model\n",
    "        self.config = config\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.model.to(self.device)\n",
    "        self.model.eval()\n",
    "\n",
    "    def evaluate_accuracy(self, dataloader):\n",
    "        \"\"\"\n",
    "        评估模型准确率\n",
    "        :param dataloader: 数据加载器\n",
    "        :return: 准确率\n",
    "        \"\"\"\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for i, (inputs, labels) in enumerate(dataloader):\n",
    "                try:\n",
    "                    inputs, labels = inputs.to(self.device), labels.to(self.device)\n",
    "\n",
    "                    # 确保输入维度正确\n",
    "                    if inputs.dim() == 2:  # [batch, seq_len]\n",
    "                        inputs = inputs.unsqueeze(1)  # 添加通道维度 -> [batch, 1, seq_len]\n",
    "\n",
    "                    # 截断过长的序列\n",
    "                    if inputs.size(2) > self.config.MAX_SEQ_LEN:\n",
    "                        inputs = inputs[:, :, :self.config.MAX_SEQ_LEN]\n",
    "\n",
    "                    _, logits = self.model(inputs)\n",
    "                    _, predicted = logits.max(1)\n",
    "                    total += labels.size(0)\n",
    "                    correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "                    # 内存管理\n",
    "                    if i % 20 == 0:\n",
    "                        torch.cuda.empty_cache()\n",
    "                        gc.collect()\n",
    "\n",
    "                except RuntimeError as e:\n",
    "                    if \"out of memory\" in str(e):\n",
    "                        print(f\"评估时内存不足: {e}\")\n",
    "                        torch.cuda.empty_cache()\n",
    "                        gc.collect()\n",
    "                        continue\n",
    "                    else:\n",
    "                        raise e\n",
    "\n",
    "        accuracy = 100. * correct / total\n",
    "        return accuracy\n",
    "\n",
    "\n",
    "# 内存友好的数据加载器创建函数\n",
    "def create_small_dataloaders(dataset_name, batch_size=4):\n",
    "    \"\"\"创建小批次的数据加载器以节省内存\"\"\"\n",
    "    try:\n",
    "        train_dataset = SpeakerRecognitionDataset(split='train')\n",
    "        val_dataset = SpeakerRecognitionDataset(split='val')\n",
    "        test_dataset = SpeakerRecognitionDataset(split='test')\n",
    "\n",
    "\n",
    "        return {\n",
    "            \"train\": DataLoader(train_dataset, batch_size=batch_size, shuffle=True,\n",
    "                                num_workers=0, pin_memory=False),\n",
    "            \"val\": DataLoader(val_dataset, batch_size=batch_size, shuffle=False,\n",
    "                              num_workers=0, pin_memory=False),\n",
    "            \"test\": DataLoader(test_dataset, batch_size=batch_size, shuffle=False,\n",
    "                               num_workers=0, pin_memory=False),\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"数据加载器创建错误: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# 测试代码\n",
    "if __name__ == \"__main__\":\n",
    "    # 设置较小的批次大小\n",
    "    batch_size = Config.BATCH_SIZE\n",
    "\n",
    "    print(\"创建数据加载器...\")\n",
    "    try:\n",
    "        # 使用内存友好的数据加载器\n",
    "        dataloaders = create_small_dataloaders(\"librispeech\", batch_size=batch_size)\n",
    "\n",
    "        if dataloaders is None:\n",
    "            print(\"无法创建数据加载器，退出\")\n",
    "            exit(1)\n",
    "\n",
    "        print(f\"训练集批次数: {len(dataloaders['train'])}\")\n",
    "        print(f\"验证集批次数: {len(dataloaders['val'])}\")\n",
    "        print(f\"测试集批次数: {len(dataloaders['test'])}\")\n",
    "\n",
    "        # 关键修改：从训练集中获取实际说话人数量（类别数）\n",
    "        num_speakers = len(dataloaders[\"train\"].dataset.speaker_to_idx)\n",
    "        print(f\"数据集中实际说话人数量（类别数）: {num_speakers}\")\n",
    "\n",
    "        # 创建训练器前，先初始化模型并传入正确的num_classes\n",
    "        print(\"创建模型和训练器...\")\n",
    "        # 关键修改：确保在创建Trainer时使用正确的num_classes初始化模型\n",
    "        config = Config()\n",
    "        # 1. 初始化模型（传入正确的num_classes）\n",
    "        model = CHiLAPModel(num_classes=num_speakers)\n",
    "        # 2. 将模型传入Trainer，确保优化器初始化时模型已存在\n",
    "        trainer = Trainer(config=config, model=model)  # 传入model参数\n",
    "\n",
    "        # 测试一个批次\n",
    "        print(\"测试前向传播...\")\n",
    "        try:\n",
    "            x, y = next(iter(dataloaders[\"train\"]))\n",
    "            print(f\"原始输入形状: {x.shape}, 标签形状: {y.shape}\")\n",
    "\n",
    "            # 处理输入维度\n",
    "            if x.dim() == 2:  # [batch, seq_len]\n",
    "                x = x.unsqueeze(1)  # 添加通道维度 -> [batch, 1, seq_len]\n",
    "\n",
    "            # 确保音频长度正确\n",
    "            if x.size(2) > Config.MAX_SEQ_LEN:\n",
    "                x = x[:, :, :Config.MAX_SEQ_LEN]\n",
    "            elif x.size(2) < Config.MAX_SEQ_LEN:\n",
    "                pad_len = Config.MAX_SEQ_LEN - x.size(2)\n",
    "                x = torch.nn.functional.pad(x, (0, pad_len), value=0.0)\n",
    "\n",
    "            print(f\"处理后输入形状: {x.shape}\")\n",
    "\n",
    "            x = x.to(trainer.device)\n",
    "            y = y.to(trainer.device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                embeddings, logits = trainer.model(x)\n",
    "                print(f\"嵌入形状: {embeddings.shape}, 输出形状: {logits.shape}\")\n",
    "                print(\"前向传播测试成功!\")\n",
    "        except Exception as e:\n",
    "            print(f\"前向传播测试失败: {e}\")\n",
    "            import traceback\n",
    "\n",
    "            traceback.print_exc()\n",
    "            exit(1)\n",
    "\n",
    "        # 开始训练\n",
    "        print(\"开始训练...\")\n",
    "        trainer.train(dataloaders[\"train\"], dataloaders[\"val\"])\n",
    "\n",
    "        # 创建评估器\n",
    "        print(\"创建评估器...\")\n",
    "        evaluator = Evaluator(trainer.model)\n",
    "\n",
    "        # 评估模型\n",
    "        print(\"评估模型...\")\n",
    "        test_accuracy = evaluator.evaluate_accuracy(dataloaders[\"test\"])\n",
    "        print(f\"测试集准确率: {test_accuracy:.2f}%\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"程序执行错误: {e}\")\n",
    "        import traceback\n",
    "\n",
    "        traceback.print_exc()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878cacdb-3b8a-4321-9bfc-85f4113e4cce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
