{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "454d9ec6-709c-4dbf-83c7-c09d1a396d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "class Config:\n",
    "    # 数据加载器配置（保持与基础配置兼容，仅使用LibriSpeech开发集）\n",
    "    DEBUG_MODE = True\n",
    "    DEBUG_SAMPLE_SIZE = 5000\n",
    "    BASE_DIR = os.getcwd()\n",
    "    LIBRISPEECH_PATH = os.path.join(BASE_DIR, \"devDataset\", \"LibriSpeech\")  # 仅使用LibriSpeech开发集\n",
    "    SAMPLE_RATE = 16000\n",
    "    DURATION = 1.0\n",
    "    MAX_SAMPLES = int(SAMPLE_RATE * DURATION)\n",
    "    NOISE_TYPES = [\"white\", \"babble\"]  # 噪声类型适配复杂损失的鲁棒性训练\n",
    "    SNR_LEVELS = [-5, 0, 5, 10]  # 扩展SNR范围以增强复杂损失的稳定性约束\n",
    "    BATCH_SIZE = 16  # 适配复杂损失计算的内存需求\n",
    "    NUM_WORKERS = 2\n",
    "    VALID_RATIO = 0.1  # 从开发集中划分验证集\n",
    "    MAX_SEQ_LEN = 16000\n",
    "    \n",
    "    # 模型配置（简化模型基础上适配复杂损失）\n",
    "    INPUT_DIM = 1\n",
    "    HIDDEN_DIM = 256\n",
    "    EMBEDDING_DIM = 128  # 嵌入向量维度，用于复杂损失计算\n",
    "    CHAOS_DIM = 64  # 混沌模块维度，影响相位同步损失\n",
    "    CHAOS_TIME_STEPS = 5  # 混沌时间步，与李雅普诺夫损失相关\n",
    "    ATTENTION_HEADS = 4\n",
    "    DROPOUT_RATE = 0.1  # 新增dropout增强泛化性\n",
    "    \n",
    "    # 复杂损失配置（T5模型核心扩展）\n",
    "    CE_WEIGHT = 1.0  # 交叉熵损失权重\n",
    "    SYNC_WEIGHT = 0.3  # 相位同步损失权重\n",
    "    LYAPUNOV_WEIGHT = 0.2  # 李雅普诺夫稳定性损失权重\n",
    "    LOSS_WARMUP_EPOCHS = 3  # 损失预热周期，逐步启用复杂损失\n",
    "    \n",
    "    # 训练配置（针对多损失联合优化调整）\n",
    "    EPOCHS = 500\n",
    "    LR = 0.005  # 略低于基础模型，适配多损失优化\n",
    "    LR_DECAY = 0.95\n",
    "    WEIGHT_DECAY = 1e-5\n",
    "    SAVE_INTERVAL = 10\n",
    "    VAL_INTERVAL = 1\n",
    "    CHECKPOINT_DIR = \"../checkpoints/T5\"  # 单独的 checkpoint 目录\n",
    "    WARMUP_EPOCHS = 5\n",
    "    GRAD_CLIP = 1.0  # 梯度裁剪防止多损失梯度爆炸\n",
    "    PATIENCE = 15  # 增加早停耐心，适应复杂损失收敛特性\n",
    "    MIN_DELTA = 0.001\n",
    "    GRADIENT_ACCUMULATION_STEPS = 4  # 累积梯度减轻内存压力\n",
    "    ENABLE_MIXED_PRECISION = True  # 启用混合精度训练加速复杂损失计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15cc9844-3c99-4667-ad6f-af0c19edb28a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[train] 开发集样本数: 5000\n",
      "[val] 开发集样本数: 557\n",
      "[test] 开发集样本数: 5567\n",
      "[test] 开发集样本数: 5567\n",
      "数据加载器创建成功\n",
      "训练集批次形状: 音频 torch.Size([16, 1, 16000]) (预期 [batch, 1, 16000]), 标签 torch.Size([16])\n",
      "音频值范围: [-1.0000, 1.0000]\n",
      "带噪声测试集音频范围: [-1.0000, 1.0000]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import librosa\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import soundfile as sf\n",
    "from tqdm import tqdm\n",
    "\n",
    "class T5NoiseInjector:\n",
    "    \"\"\"噪声注入工具类，适配T5模型的复杂损失鲁棒性训练\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def generate_white_noise(length):\n",
    "        \"\"\"生成白噪声，符合T5模型输入范围要求\"\"\"\n",
    "        return np.random.randn(length).astype(np.float32)\n",
    "    \n",
    "    @staticmethod\n",
    "    def generate_babble_noise(length, num_speakers=3):\n",
    "        \"\"\"生成多说话人混合噪声，增强复杂损失训练的真实性\"\"\"\n",
    "        noise = np.zeros(length, dtype=np.float32)\n",
    "        for _ in range(num_speakers):\n",
    "            start = random.randint(0, max(0, length - Config.SAMPLE_RATE))\n",
    "            end = min(start + Config.SAMPLE_RATE, length)\n",
    "            noise[start:end] += np.random.randn(end - start).astype(np.float32)\n",
    "        return noise / num_speakers  # 归一化处理\n",
    "    \n",
    "    @staticmethod\n",
    "    def add_noise(signal, noise_type=\"white\", snr_db=10):\n",
    "        \"\"\"按指定SNR添加噪声，确保与T5模型复杂损失计算兼容\"\"\"\n",
    "        if len(signal) == 0:\n",
    "            return signal\n",
    "        \n",
    "        # 计算信号功率，避免数值不稳定\n",
    "        signal_power = np.mean(signal **2)\n",
    "        if signal_power < 1e-10:\n",
    "            return signal\n",
    "        signal_db = 10 * np.log10(signal_power)\n",
    "        \n",
    "        # 根据配置生成指定类型噪声\n",
    "        if noise_type == \"white\":\n",
    "            noise = T5NoiseInjector.generate_white_noise(len(signal))\n",
    "        elif noise_type == \"babble\":\n",
    "            noise = T5NoiseInjector.generate_babble_noise(len(signal))\n",
    "        else:\n",
    "            raise ValueError(f\"不支持的噪声类型: {noise_type}\")\n",
    "        \n",
    "        # 调整噪声功率以匹配目标SNR\n",
    "        noise_power = np.mean(noise** 2)\n",
    "        noise_db = 10 * np.log10(noise_power + 1e-10)  # 避免log(0)\n",
    "        target_noise_db = signal_db - snr_db\n",
    "        noise_scale = 10 ** ((target_noise_db - noise_db) / 20)\n",
    "        noisy_signal = signal + noise * noise_scale\n",
    "        \n",
    "        # 归一化到[-1, 1]范围，确保复杂损失计算稳定性\n",
    "        max_val = np.max(np.abs(noisy_signal))\n",
    "        if max_val > 1e-5:\n",
    "            noisy_signal = noisy_signal / max_val\n",
    "        return noisy_signal\n",
    "\n",
    "\n",
    "class T5LibriSpeechDataset(Dataset):\n",
    "    \"\"\"T5模型专用数据集，仅加载LibriSpeech开发集数据\"\"\"\n",
    "    \n",
    "    def __init__(self, split=\"train\", add_noise=False):\n",
    "        self.split = split\n",
    "        self.add_noise = add_noise\n",
    "        self.audio_paths, self.labels = self._load_librispeech_dev()\n",
    "        self.speaker_to_idx = self._build_speaker_map()\n",
    "        \n",
    "        # 调试模式样本量限制\n",
    "        if Config.DEBUG_MODE:\n",
    "            if split == \"train\":\n",
    "                self.audio_paths = self.audio_paths[:Config.DEBUG_SAMPLE_SIZE]\n",
    "                self.labels = self.labels[:Config.DEBUG_SAMPLE_SIZE]\n",
    "            elif split == \"val\":\n",
    "                limit = min(Config.DEBUG_SAMPLE_SIZE // 2, len(self.audio_paths))\n",
    "                self.audio_paths = self.audio_paths[:limit]\n",
    "                self.labels = self.labels[:limit]\n",
    "        \n",
    "        # 验证数据集有效性\n",
    "        self._validate_dataset()\n",
    "        print(f\"[{split}] 开发集样本数: {len(self.audio_paths)}\")\n",
    "    \n",
    "    def _load_librispeech_dev(self):\n",
    "        \"\"\"仅加载LibriSpeech开发集（含'dev'的子集）\"\"\"\n",
    "        audio_paths = []\n",
    "        labels = []\n",
    "        root = Config.LIBRISPEECH_PATH\n",
    "        \n",
    "        if not os.path.exists(root):\n",
    "            raise FileNotFoundError(f\"LibriSpeech开发集路径不存在: {root}\")\n",
    "        \n",
    "        # 仅处理包含'dev'的子目录（开发集）\n",
    "        for subset in os.listdir(root):\n",
    "            if \"dev\" not in subset.lower():\n",
    "                continue  # 跳过非开发集子集\n",
    "            \n",
    "            subset_path = os.path.join(root, subset)\n",
    "            if not os.path.isdir(subset_path):\n",
    "                continue\n",
    "            \n",
    "            # 遍历开发集子目录结构 (speaker -> chapter -> *.flac)\n",
    "            for speaker_id in os.listdir(subset_path):\n",
    "                speaker_path = os.path.join(subset_path, speaker_id)\n",
    "                if not os.path.isdir(speaker_path):\n",
    "                    continue\n",
    "                \n",
    "                for chapter in os.listdir(speaker_path):\n",
    "                    chapter_path = os.path.join(speaker_path, chapter)\n",
    "                    if not os.path.isdir(chapter_path):\n",
    "                        continue\n",
    "                    \n",
    "                    # 收集所有flac文件\n",
    "                    for file in os.listdir(chapter_path):\n",
    "                        if file.endswith(\".flac\"):\n",
    "                            audio_paths.append(os.path.join(chapter_path, file))\n",
    "                            labels.append(speaker_id)\n",
    "        \n",
    "        # 划分训练/验证集\n",
    "        if self.split != \"test\" and len(audio_paths) > 0:\n",
    "            train_paths, val_paths, train_labels, val_labels = train_test_split(\n",
    "                audio_paths, labels, \n",
    "                test_size=Config.VALID_RATIO, \n",
    "                random_state=42,\n",
    "                stratify=labels  # 保持说话人分布一致\n",
    "            )\n",
    "            return (train_paths, train_labels) if self.split == \"train\" else (val_paths, val_labels)\n",
    "        \n",
    "        return audio_paths, labels\n",
    "    \n",
    "    def _build_speaker_map(self):\n",
    "        \"\"\"构建说话人ID到整数的映射，适配分类损失计算\"\"\"\n",
    "        unique_speakers = sorted(set(self.labels))\n",
    "        return {speaker: idx for idx, speaker in enumerate(unique_speakers)}\n",
    "    \n",
    "    def _validate_dataset(self):\n",
    "        \"\"\"验证并移除无效音频文件，确保训练稳定性\"\"\"\n",
    "        invalid_indices = []\n",
    "        for i in range(len(self.audio_paths)-1, -1, -1):\n",
    "            path = self.audio_paths[i]\n",
    "            try:\n",
    "                if not os.path.exists(path) or os.path.getsize(path) < 1024:\n",
    "                    raise ValueError(\"文件不存在或过小\")\n",
    "                # 测试加载文件\n",
    "                sf.read(path)\n",
    "            except Exception as e:\n",
    "                invalid_indices.append(i)\n",
    "                print(f\"移除无效文件: {path}, 原因: {str(e)}\")\n",
    "        \n",
    "        # 移除无效样本\n",
    "        for i in invalid_indices:\n",
    "            self.audio_paths.pop(i)\n",
    "            self.labels.pop(i)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.audio_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"加载并预处理音频样本，返回模型输入格式\"\"\"\n",
    "        path = self.audio_paths[idx]\n",
    "        label = self.speaker_to_idx[self.labels[idx]]\n",
    "        \n",
    "        # 加载音频文件（优先使用soundfile处理flac格式）\n",
    "        try:\n",
    "            signal, sr = sf.read(path)\n",
    "            # 确保采样率匹配\n",
    "            if sr != Config.SAMPLE_RATE:\n",
    "                signal = librosa.resample(\n",
    "                    signal, \n",
    "                    orig_sr=sr, \n",
    "                    target_sr=Config.SAMPLE_RATE\n",
    "                )\n",
    "        except Exception as e:\n",
    "            print(f\"加载失败 {path}，使用静音替代: {e}\")\n",
    "            signal = np.zeros(Config.MAX_SAMPLES, dtype=np.float32)\n",
    "        \n",
    "        # 统一音频长度（截断或补零）\n",
    "        if len(signal) > Config.MAX_SAMPLES:\n",
    "            signal = signal[:Config.MAX_SAMPLES]\n",
    "        else:\n",
    "            signal = np.pad(\n",
    "                signal, \n",
    "                (0, Config.MAX_SAMPLES - len(signal)), \n",
    "                mode=\"constant\"\n",
    "            )\n",
    "        \n",
    "        # 归一化处理\n",
    "        max_val = np.max(np.abs(signal))\n",
    "        if max_val > 1e-5:\n",
    "            signal = signal / max_val\n",
    "        \n",
    "        # 训练时添加噪声（适配复杂损失的鲁棒性训练）\n",
    "        if self.add_noise and self.split == \"train\":\n",
    "            noise_type = random.choice(Config.NOISE_TYPES)\n",
    "            snr_db = random.choice(Config.SNR_LEVELS)\n",
    "            signal = T5NoiseInjector.add_noise(signal, noise_type, snr_db)\n",
    "        \n",
    "        # 转换为张量并添加通道维度 [1, MAX_SAMPLES]\n",
    "        return torch.FloatTensor(signal).unsqueeze(0), label\n",
    "\n",
    "\n",
    "def get_t5_dataloaders():\n",
    "    \"\"\"创建T5模型专用数据加载器\"\"\"\n",
    "    # 实例化数据集\n",
    "    train_dataset = T5LibriSpeechDataset(split=\"train\", add_noise=True)\n",
    "    val_dataset = T5LibriSpeechDataset(split=\"val\", add_noise=False)\n",
    "    test_dataset = T5LibriSpeechDataset(split=\"test\", add_noise=False)\n",
    "    noisy_test_dataset = T5LibriSpeechDataset(split=\"test\", add_noise=True)\n",
    "    \n",
    "    # 检查数据集有效性\n",
    "    if len(train_dataset) == 0:\n",
    "        raise RuntimeError(\"训练集为空，请检查LibriSpeech开发集路径\")\n",
    "    \n",
    "    # 创建数据加载器\n",
    "    dataloaders = {\n",
    "        \"train\": DataLoader(\n",
    "            train_dataset,\n",
    "            batch_size=Config.BATCH_SIZE,\n",
    "            shuffle=True,\n",
    "            num_workers=Config.NUM_WORKERS,\n",
    "            pin_memory=True,\n",
    "            drop_last=True\n",
    "        ),\n",
    "        \"val\": DataLoader(\n",
    "            val_dataset,\n",
    "            batch_size=Config.BATCH_SIZE,\n",
    "            shuffle=False,\n",
    "            num_workers=Config.NUM_WORKERS,\n",
    "            pin_memory=True\n",
    "        ),\n",
    "        \"test\": DataLoader(\n",
    "            test_dataset,\n",
    "            batch_size=Config.BATCH_SIZE,\n",
    "            shuffle=False,\n",
    "            num_workers=Config.NUM_WORKERS,\n",
    "            pin_memory=True\n",
    "        ),\n",
    "        \"noisy_test\": DataLoader(\n",
    "            noisy_test_dataset,\n",
    "            batch_size=Config.BATCH_SIZE,\n",
    "            shuffle=False,\n",
    "            num_workers=Config.NUM_WORKERS,\n",
    "            pin_memory=True\n",
    "        )\n",
    "    }\n",
    "    \n",
    "    return dataloaders\n",
    "\n",
    "\n",
    "# 测试数据加载器\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        dataloaders = get_t5_dataloaders()\n",
    "        print(\"数据加载器创建成功\")\n",
    "        \n",
    "        # 验证训练集批次\n",
    "        train_loader = dataloaders[\"train\"]\n",
    "        x, y = next(iter(train_loader))\n",
    "        print(f\"训练集批次形状: 音频 {x.shape} (预期 [batch, 1, 16000]), 标签 {y.shape}\")\n",
    "        print(f\"音频值范围: [{x.min():.4f}, {x.max():.4f}]\")\n",
    "        \n",
    "        # 验证带噪声测试集\n",
    "        noisy_test_loader = dataloaders[\"noisy_test\"]\n",
    "        x_noisy, _ = next(iter(noisy_test_loader))\n",
    "        print(f\"带噪声测试集音频范围: [{x_noisy.min():.4f}, {x_noisy.max():.4f}]\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"测试失败: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "010380eb-889e-4544-b267-621dbd590843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T5 C-HiLAP模型结构:\n",
      "T5CHiLAPModel(\n",
      "  (feature_extractor): Sequential(\n",
      "    (0): Conv1d(1, 256, kernel_size=(5,), stride=(2,), padding=(2,))\n",
      "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): PReLU(num_parameters=1)\n",
      "    (3): Conv1d(256, 256, kernel_size=(5,), stride=(2,), padding=(2,))\n",
      "    (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): PReLU(num_parameters=1)\n",
      "    (6): Conv1d(256, 256, kernel_size=(5,), stride=(2,), padding=(2,))\n",
      "    (7): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (8): PReLU(num_parameters=1)\n",
      "  )\n",
      "  (chaos_layer): ChaoticStimulus(\n",
      "    (chaos_transform): Sequential(\n",
      "      (0): Conv1d(256, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "      (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): PReLU(num_parameters=1)\n",
      "      (3): Conv1d(64, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "      (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): PReLU(num_parameters=1)\n",
      "    )\n",
      "  )\n",
      "  (attention): EnhancedAttention(\n",
      "    (query): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
      "    (key): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
      "    (value): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
      "    (out): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
      "  )\n",
      "  (tdnn_block): Sequential(\n",
      "    (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): PReLU(num_parameters=1)\n",
      "    (3): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
      "    (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): PReLU(num_parameters=1)\n",
      "    (6): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))\n",
      "    (7): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (8): PReLU(num_parameters=1)\n",
      "  )\n",
      "  (pooling): StatisticalPooling()\n",
      "  (embedding): Sequential(\n",
      "    (0): Linear(in_features=1024, out_features=128, bias=True)\n",
      "    (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): PReLU(num_parameters=1)\n",
      "    (3): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (classifier): Linear(in_features=128, out_features=100, bias=True)\n",
      ")\n",
      "\n",
      "测试前向传播:\n",
      "输入形状: torch.Size([2, 1, 16000])\n",
      "嵌入向量形状: torch.Size([2, 128])\n",
      "分类输出形状: torch.Size([2, 100])\n",
      "混沌状态形状: torch.Size([2, 256, 2000])\n",
      "注意力权重形状: torch.Size([2, 4, 2000, 2000])\n",
      "前向传播成功!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "# 混沌激励模块（增强版，适配复杂损失计算）\n",
    "class ChaoticStimulus(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, chaos_dim=Config.CHAOS_DIM):\n",
    "        super().__init__()\n",
    "        self.chaos_transform = nn.Sequential(\n",
    "            nn.Conv1d(input_dim, chaos_dim, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(chaos_dim),\n",
    "            nn.PReLU(),\n",
    "            nn.Conv1d(chaos_dim, output_dim, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(output_dim),\n",
    "            nn.PReLU()\n",
    "        )\n",
    "        \n",
    "        # 混沌系统参数（用于相位同步损失计算）\n",
    "        self.chaos_factor = nn.Parameter(torch.tensor(0.1))\n",
    "        self.chaos_bias = nn.Parameter(torch.randn(1, output_dim, 1))  # 混沌偏置项\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        前向传播，返回处理后的特征和混沌状态（用于复杂损失）\n",
    "        :param x: 输入特征 [batch_size, channels, seq_len]\n",
    "        :return: 处理后的特征和混沌状态元组\n",
    "        \"\"\"\n",
    "        # 特征变换\n",
    "        transformed = self.chaos_transform(x)\n",
    "        \n",
    "        # 生成混沌状态（用于相位同步损失）\n",
    "        chaos_state = torch.sin(transformed + self.chaos_bias) * self.chaos_factor\n",
    "        \n",
    "        # 训练时添加混沌扰动\n",
    "        if self.training:\n",
    "            transformed = transformed + chaos_state\n",
    "        \n",
    "        return transformed, chaos_state\n",
    "\n",
    "\n",
    "# 改进的注意力机制（支持复杂损失中的权重分析）\n",
    "class EnhancedAttention(nn.Module):\n",
    "    def __init__(self, input_dim, heads=Config.ATTENTION_HEADS):\n",
    "        super().__init__()\n",
    "        self.heads = heads\n",
    "        self.head_dim = input_dim // heads\n",
    "        \n",
    "        # 注意力线性变换\n",
    "        self.query = nn.Conv1d(input_dim, input_dim, kernel_size=1)\n",
    "        self.key = nn.Conv1d(input_dim, input_dim, kernel_size=1)\n",
    "        self.value = nn.Conv1d(input_dim, input_dim, kernel_size=1)\n",
    "        self.out = nn.Conv1d(input_dim, input_dim, kernel_size=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        前向传播，返回加权特征和注意力权重（用于损失分析）\n",
    "        :param x: 输入特征 [batch_size, channels, seq_len]\n",
    "        :return: 加权特征和注意力权重\n",
    "        \"\"\"\n",
    "        batch_size, channels, seq_len = x.shape\n",
    "        \n",
    "        # 线性变换并分拆注意力头\n",
    "        q = self.query(x).view(batch_size, self.heads, self.head_dim, seq_len)  # [B, H, D, L]\n",
    "        k = self.key(x).view(batch_size, self.heads, self.head_dim, seq_len)    # [B, H, D, L]\n",
    "        v = self.value(x).view(batch_size, self.heads, self.head_dim, seq_len)  # [B, H, D, L]\n",
    "        \n",
    "        # 计算注意力分数 [B, H, L, L]\n",
    "        scores = torch.matmul(q.transpose(2, 3), k) / (self.head_dim **0.5)\n",
    "        attn_weights = F.softmax(scores, dim=-1)\n",
    "        \n",
    "        # 应用注意力权重\n",
    "        weighted = torch.matmul(attn_weights, v.transpose(2, 3))  # [B, H, L, D]\n",
    "        weighted = weighted.transpose(2, 3).contiguous().view(batch_size, channels, seq_len)  # [B, C, L]\n",
    "        weighted = self.out(weighted)\n",
    "        \n",
    "        return weighted, attn_weights\n",
    "\n",
    "\n",
    "# 统计池化层（保留更多统计特征用于复杂损失）\n",
    "class StatisticalPooling(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        前向传播，返回更丰富的统计特征\n",
    "        :param x: 输入特征 [batch_size, channels, seq_len]\n",
    "        :return: 融合统计特征 [batch_size, channels*4]\n",
    "        \"\"\"\n",
    "        mean = torch.mean(x, dim=2)\n",
    "        std = torch.std(x, dim=2)\n",
    "        max_val = torch.max(x, dim=2)[0]\n",
    "        min_val = torch.min(x, dim=2)[0]\n",
    "        return torch.cat((mean, std, max_val, min_val), dim=1)\n",
    "\n",
    "\n",
    "# T5模型的C-HiLAP实现（简化模型+复杂损失适配）\n",
    "class T5CHiLAPModel(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.config = Config()\n",
    "        \n",
    "        # 特征提取层\n",
    "        self.feature_extractor = nn.Sequential(\n",
    "            nn.Conv1d(self.config.INPUT_DIM, self.config.HIDDEN_DIM, \n",
    "                      kernel_size=5, stride=2, padding=2),\n",
    "            nn.BatchNorm1d(self.config.HIDDEN_DIM),\n",
    "            nn.PReLU(),\n",
    "            nn.Conv1d(self.config.HIDDEN_DIM, self.config.HIDDEN_DIM, \n",
    "                      kernel_size=5, stride=2, padding=2),\n",
    "            nn.BatchNorm1d(self.config.HIDDEN_DIM),\n",
    "            nn.PReLU(),\n",
    "            nn.Conv1d(self.config.HIDDEN_DIM, self.config.HIDDEN_DIM, \n",
    "                      kernel_size=5, stride=2, padding=2),\n",
    "            nn.BatchNorm1d(self.config.HIDDEN_DIM),\n",
    "            nn.PReLU()\n",
    "        )\n",
    "        \n",
    "        # 混沌激励模块\n",
    "        self.chaos_layer = ChaoticStimulus(\n",
    "            self.config.HIDDEN_DIM, \n",
    "            self.config.HIDDEN_DIM\n",
    "        )\n",
    "        \n",
    "        # 增强注意力层\n",
    "        self.attention = EnhancedAttention(\n",
    "            self.config.HIDDEN_DIM,\n",
    "            self.config.ATTENTION_HEADS\n",
    "        )\n",
    "        \n",
    "        # TDNN层（深度时序特征提取）\n",
    "        self.tdnn_block = nn.Sequential(\n",
    "            nn.Conv1d(self.config.HIDDEN_DIM, self.config.HIDDEN_DIM, \n",
    "                      kernel_size=3, dilation=1, padding=1),\n",
    "            nn.BatchNorm1d(self.config.HIDDEN_DIM),\n",
    "            nn.PReLU(),\n",
    "            nn.Conv1d(self.config.HIDDEN_DIM, self.config.HIDDEN_DIM, \n",
    "                      kernel_size=3, dilation=2, padding=2),\n",
    "            nn.BatchNorm1d(self.config.HIDDEN_DIM),\n",
    "            nn.PReLU(),\n",
    "            nn.Conv1d(self.config.HIDDEN_DIM, self.config.HIDDEN_DIM, \n",
    "                      kernel_size=3, dilation=4, padding=4),\n",
    "            nn.BatchNorm1d(self.config.HIDDEN_DIM),\n",
    "            nn.PReLU()\n",
    "        )\n",
    "        \n",
    "        # 池化层\n",
    "        self.pooling = StatisticalPooling()\n",
    "        \n",
    "        # 嵌入层（用于计算李雅普诺夫稳定性损失）\n",
    "        self.embedding = nn.Sequential(\n",
    "            nn.Linear(self.config.HIDDEN_DIM * 4, self.config.EMBEDDING_DIM),  # 匹配统计池化输出\n",
    "            nn.BatchNorm1d(self.config.EMBEDDING_DIM),\n",
    "            nn.PReLU(),\n",
    "            nn.Dropout(self.config.DROPOUT_RATE)\n",
    "        )\n",
    "        \n",
    "        # 分类器\n",
    "        self.classifier = nn.Linear(self.config.EMBEDDING_DIM, num_classes)\n",
    "        \n",
    "        # 参考吸引子（用于相位同步损失）\n",
    "        self.reference_attractor = nn.Parameter(\n",
    "            torch.randn(1, self.config.HIDDEN_DIM, self.config.CHAOS_TIME_STEPS)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        前向传播，返回所有复杂损失计算所需的输出\n",
    "        :param x: 输入音频特征 [batch_size, channels, seq_len]\n",
    "        :return: 嵌入向量、分类logits、混沌状态、注意力权重（用于损失计算）\n",
    "        \"\"\"\n",
    "        # 调整输入维度\n",
    "        if x.dim() == 3 and x.size(1) > x.size(2):\n",
    "            x = x.permute(0, 2, 1)  # 确保形状为 [batch, channels, seq_len]\n",
    "        \n",
    "        # 限制序列长度\n",
    "        seq_len = x.size(2)\n",
    "        if seq_len > self.config.MAX_SEQ_LEN:\n",
    "            x = x[:, :, :self.config.MAX_SEQ_LEN]\n",
    "        \n",
    "        # 特征提取\n",
    "        x = self.feature_extractor(x)  # [B, HIDDEN_DIM, L/8]\n",
    "        \n",
    "        # 混沌处理（获取混沌状态用于损失）\n",
    "        x, chaos_state = self.chaos_layer(x)  # [B, HIDDEN_DIM, L/8]\n",
    "        \n",
    "        # 注意力处理（获取权重用于损失分析）\n",
    "        x, attn_weights = self.attention(x)  # [B, HIDDEN_DIM, L/8]\n",
    "        \n",
    "        # TDNN处理\n",
    "        x = self.tdnn_block(x)  # [B, HIDDEN_DIM, L/8]\n",
    "        \n",
    "        # 池化\n",
    "        x = self.pooling(x)  # [B, HIDDEN_DIM*4]\n",
    "        \n",
    "        # 嵌入向量（用于李雅普诺夫损失）\n",
    "        embedding = self.embedding(x)  # [B, EMBEDDING_DIM]\n",
    "        \n",
    "        # 分类输出\n",
    "        logits = self.classifier(embedding)  # [B, num_classes]\n",
    "        \n",
    "        # 返回所有复杂损失计算所需组件\n",
    "        return {\n",
    "            \"embedding\": embedding,\n",
    "            \"logits\": logits,\n",
    "            \"chaos_state\": chaos_state,\n",
    "            \"attn_weights\": attn_weights,\n",
    "            \"reference_attractor\": self.reference_attractor\n",
    "        }\n",
    "\n",
    "\n",
    "# 测试模型\n",
    "if __name__ == \"__main__\":\n",
    "    # 初始化模型（假设分类数为100，根据实际数据集调整）\n",
    "    num_classes = 100\n",
    "    model = T5CHiLAPModel(num_classes=num_classes)\n",
    "    \n",
    "    # 生成测试输入（匹配LibriSpeech开发集音频格式）\n",
    "    batch_size = 2\n",
    "    test_input = torch.randn(batch_size, 1, Config.MAX_SEQ_LEN)  # [batch, channels, seq_len]\n",
    "    \n",
    "    print(\"T5 C-HiLAP模型结构:\")\n",
    "    print(model)\n",
    "    \n",
    "    print(\"\\n测试前向传播:\")\n",
    "    print(f\"输入形状: {test_input.shape}\")\n",
    "    \n",
    "    try:\n",
    "        outputs = model(test_input)\n",
    "        print(f\"嵌入向量形状: {outputs['embedding'].shape}\")\n",
    "        print(f\"分类输出形状: {outputs['logits'].shape}\")\n",
    "        print(f\"混沌状态形状: {outputs['chaos_state'].shape}\")\n",
    "        print(f\"注意力权重形状: {outputs['attn_weights'].shape}\")\n",
    "        print(\"前向传播成功!\")\n",
    "    except Exception as e:\n",
    "        print(f\"前向传播错误: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da17b53e-a033-4aaf-83f1-1708d3fb453d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "创建T5数据加载器...\n",
      "[train] 开发集样本数: 5000\n",
      "[val] 开发集样本数: 557\n",
      "[test] 开发集样本数: 5567\n",
      "[test] 开发集样本数: 5567\n",
      "说话人数量（类别数）: 73\n",
      "初始化T5 C-HiLAP模型...\n",
      "初始化训练器...\n",
      "使用设备: cuda\n",
      "启用混合精度训练\n",
      "测试前向传播...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/run/nvme/job_5065118/tmp/ipykernel_2107680/3615266546.py:129: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "前向传播测试失败: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 4.75 GiB of which 17.38 MiB is free. Process 2070169 has 2.71 GiB memory in use. Process 2073078 has 1.06 GiB memory in use. Process 2183819 has 274.00 MiB memory in use. Process 2184326 has 274.00 MiB memory in use. Process 2186346 has 274.00 MiB memory in use. Process 2186900 has 274.00 MiB memory in use. Including non-PyTorch memory, this process has 974.00 MiB memory in use. Of the allocated memory 851.15 MiB is allocated by PyTorch, and 32.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "启动训练...\n",
      "开始T5模型训练...\n",
      "训练集批次: 312, 验证集批次: 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/run/nvme/job_5065118/tmp/ipykernel_2107680/3615266546.py\", line 477, in <module>\n",
      "    outputs = model(x)\n",
      "              ^^^^^^^^\n",
      "  File \"/usr/local/lib64/python3.12/site-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib64/python3.12/site-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/run/nvme/job_5065118/tmp/ipykernel_2107680/2230600108.py\", line 186, in forward\n",
      "    x, chaos_state = self.chaos_layer(x)  # [B, HIDDEN_DIM, L/8]\n",
      "                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib64/python3.12/site-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib64/python3.12/site-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/run/nvme/job_5065118/tmp/ipykernel_2107680/2230600108.py\", line 33, in forward\n",
      "    chaos_state = torch.sin(transformed + self.chaos_bias) * self.chaos_factor\n",
      "                  ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~\n",
      "torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 4.75 GiB of which 17.38 MiB is free. Process 2070169 has 2.71 GiB memory in use. Process 2073078 has 1.06 GiB memory in use. Process 2183819 has 274.00 MiB memory in use. Process 2184326 has 274.00 MiB memory in use. Process 2186346 has 274.00 MiB memory in use. Process 2186900 has 274.00 MiB memory in use. Including non-PyTorch memory, this process has 974.00 MiB memory in use. Of the allocated memory 851.15 MiB is allocated by PyTorch, and 32.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "  0%|          | 0/312 [00:00<?, ?it/s]/run/nvme/job_5065118/tmp/ipykernel_2107680/3615266546.py:171: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "  1%|          | 2/312 [00:00<01:35,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "内存不足错误在批次 0: CUDA out of memory. Tried to allocate 490.00 MiB. GPU 0 has a total capacity of 4.75 GiB of which 259.38 MiB is free. Process 2070169 has 2.71 GiB memory in use. Process 2073078 has 1.06 GiB memory in use. Process 2183819 has 274.00 MiB memory in use. Process 2184326 has 274.00 MiB memory in use. Process 2186346 has 274.00 MiB memory in use. Process 2186900 has 274.00 MiB memory in use. Including non-PyTorch memory, this process has 732.00 MiB memory in use. Of the allocated memory 606.34 MiB is allocated by PyTorch, and 27.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "内存不足错误在批次 1: CUDA out of memory. Tried to allocate 490.00 MiB. GPU 0 has a total capacity of 4.75 GiB of which 259.38 MiB is free. Process 2070169 has 2.71 GiB memory in use. Process 2073078 has 1.06 GiB memory in use. Process 2183819 has 274.00 MiB memory in use. Process 2184326 has 274.00 MiB memory in use. Process 2186346 has 274.00 MiB memory in use. Process 2186900 has 274.00 MiB memory in use. Including non-PyTorch memory, this process has 732.00 MiB memory in use. Of the allocated memory 606.34 MiB is allocated by PyTorch, and 27.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "内存不足错误在批次 2: CUDA out of memory. Tried to allocate 490.00 MiB. GPU 0 has a total capacity of 4.75 GiB of which 259.38 MiB is free. Process 2070169 has 2.71 GiB memory in use. Process 2073078 has 1.06 GiB memory in use. Process 2183819 has 274.00 MiB memory in use. Process 2184326 has 274.00 MiB memory in use. Process 2186346 has 274.00 MiB memory in use. Process 2186900 has 274.00 MiB memory in use. Including non-PyTorch memory, this process has 732.00 MiB memory in use. Of the allocated memory 606.34 MiB is allocated by PyTorch, and 27.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 5/312 [00:01<00:51,  5.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "内存不足错误在批次 3: CUDA out of memory. Tried to allocate 490.00 MiB. GPU 0 has a total capacity of 4.75 GiB of which 259.38 MiB is free. Process 2070169 has 2.71 GiB memory in use. Process 2073078 has 1.06 GiB memory in use. Process 2183819 has 274.00 MiB memory in use. Process 2184326 has 274.00 MiB memory in use. Process 2186346 has 274.00 MiB memory in use. Process 2186900 has 274.00 MiB memory in use. Including non-PyTorch memory, this process has 732.00 MiB memory in use. Of the allocated memory 606.34 MiB is allocated by PyTorch, and 27.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "内存不足错误在批次 4: CUDA out of memory. Tried to allocate 490.00 MiB. GPU 0 has a total capacity of 4.75 GiB of which 259.38 MiB is free. Process 2070169 has 2.71 GiB memory in use. Process 2073078 has 1.06 GiB memory in use. Process 2183819 has 274.00 MiB memory in use. Process 2184326 has 274.00 MiB memory in use. Process 2186346 has 274.00 MiB memory in use. Process 2186900 has 274.00 MiB memory in use. Including non-PyTorch memory, this process has 732.00 MiB memory in use. Of the allocated memory 606.34 MiB is allocated by PyTorch, and 27.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "内存不足错误在批次 5: CUDA out of memory. Tried to allocate 490.00 MiB. GPU 0 has a total capacity of 4.75 GiB of which 259.38 MiB is free. Process 2070169 has 2.71 GiB memory in use. Process 2073078 has 1.06 GiB memory in use. Process 2183819 has 274.00 MiB memory in use. Process 2184326 has 274.00 MiB memory in use. Process 2186346 has 274.00 MiB memory in use. Process 2186900 has 274.00 MiB memory in use. Including non-PyTorch memory, this process has 732.00 MiB memory in use. Of the allocated memory 606.34 MiB is allocated by PyTorch, and 27.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 8/312 [00:01<00:43,  7.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "内存不足错误在批次 6: CUDA out of memory. Tried to allocate 490.00 MiB. GPU 0 has a total capacity of 4.75 GiB of which 259.38 MiB is free. Process 2070169 has 2.71 GiB memory in use. Process 2073078 has 1.06 GiB memory in use. Process 2183819 has 274.00 MiB memory in use. Process 2184326 has 274.00 MiB memory in use. Process 2186346 has 274.00 MiB memory in use. Process 2186900 has 274.00 MiB memory in use. Including non-PyTorch memory, this process has 732.00 MiB memory in use. Of the allocated memory 606.34 MiB is allocated by PyTorch, and 27.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "内存不足错误在批次 7: CUDA out of memory. Tried to allocate 490.00 MiB. GPU 0 has a total capacity of 4.75 GiB of which 259.38 MiB is free. Process 2070169 has 2.71 GiB memory in use. Process 2073078 has 1.06 GiB memory in use. Process 2183819 has 274.00 MiB memory in use. Process 2184326 has 274.00 MiB memory in use. Process 2186346 has 274.00 MiB memory in use. Process 2186900 has 274.00 MiB memory in use. Including non-PyTorch memory, this process has 732.00 MiB memory in use. Of the allocated memory 606.34 MiB is allocated by PyTorch, and 27.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "内存不足错误在批次 8: CUDA out of memory. Tried to allocate 490.00 MiB. GPU 0 has a total capacity of 4.75 GiB of which 259.38 MiB is free. Process 2070169 has 2.71 GiB memory in use. Process 2073078 has 1.06 GiB memory in use. Process 2183819 has 274.00 MiB memory in use. Process 2184326 has 274.00 MiB memory in use. Process 2186346 has 274.00 MiB memory in use. Process 2186900 has 274.00 MiB memory in use. Including non-PyTorch memory, this process has 732.00 MiB memory in use. Of the allocated memory 606.34 MiB is allocated by PyTorch, and 27.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 11/312 [00:01<00:41,  7.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "内存不足错误在批次 9: CUDA out of memory. Tried to allocate 490.00 MiB. GPU 0 has a total capacity of 4.75 GiB of which 259.38 MiB is free. Process 2070169 has 2.71 GiB memory in use. Process 2073078 has 1.06 GiB memory in use. Process 2183819 has 274.00 MiB memory in use. Process 2184326 has 274.00 MiB memory in use. Process 2186346 has 274.00 MiB memory in use. Process 2186900 has 274.00 MiB memory in use. Including non-PyTorch memory, this process has 732.00 MiB memory in use. Of the allocated memory 606.34 MiB is allocated by PyTorch, and 27.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "内存不足错误在批次 10: CUDA out of memory. Tried to allocate 490.00 MiB. GPU 0 has a total capacity of 4.75 GiB of which 259.38 MiB is free. Process 2070169 has 2.71 GiB memory in use. Process 2073078 has 1.06 GiB memory in use. Process 2183819 has 274.00 MiB memory in use. Process 2184326 has 274.00 MiB memory in use. Process 2186346 has 274.00 MiB memory in use. Process 2186900 has 274.00 MiB memory in use. Including non-PyTorch memory, this process has 732.00 MiB memory in use. Of the allocated memory 606.34 MiB is allocated by PyTorch, and 27.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "内存不足错误在批次 11: CUDA out of memory. Tried to allocate 490.00 MiB. GPU 0 has a total capacity of 4.75 GiB of which 259.38 MiB is free. Process 2070169 has 2.71 GiB memory in use. Process 2073078 has 1.06 GiB memory in use. Process 2183819 has 274.00 MiB memory in use. Process 2184326 has 274.00 MiB memory in use. Process 2186346 has 274.00 MiB memory in use. Process 2186900 has 274.00 MiB memory in use. Including non-PyTorch memory, this process has 732.00 MiB memory in use. Of the allocated memory 606.34 MiB is allocated by PyTorch, and 27.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 14/312 [00:02<00:40,  7.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "内存不足错误在批次 12: CUDA out of memory. Tried to allocate 490.00 MiB. GPU 0 has a total capacity of 4.75 GiB of which 259.38 MiB is free. Process 2070169 has 2.71 GiB memory in use. Process 2073078 has 1.06 GiB memory in use. Process 2183819 has 274.00 MiB memory in use. Process 2184326 has 274.00 MiB memory in use. Process 2186346 has 274.00 MiB memory in use. Process 2186900 has 274.00 MiB memory in use. Including non-PyTorch memory, this process has 732.00 MiB memory in use. Of the allocated memory 606.34 MiB is allocated by PyTorch, and 27.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "内存不足错误在批次 13: CUDA out of memory. Tried to allocate 490.00 MiB. GPU 0 has a total capacity of 4.75 GiB of which 259.38 MiB is free. Process 2070169 has 2.71 GiB memory in use. Process 2073078 has 1.06 GiB memory in use. Process 2183819 has 274.00 MiB memory in use. Process 2184326 has 274.00 MiB memory in use. Process 2186346 has 274.00 MiB memory in use. Process 2186900 has 274.00 MiB memory in use. Including non-PyTorch memory, this process has 732.00 MiB memory in use. Of the allocated memory 606.34 MiB is allocated by PyTorch, and 27.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "内存不足错误在批次 14: CUDA out of memory. Tried to allocate 490.00 MiB. GPU 0 has a total capacity of 4.75 GiB of which 259.38 MiB is free. Process 2070169 has 2.71 GiB memory in use. Process 2073078 has 1.06 GiB memory in use. Process 2183819 has 274.00 MiB memory in use. Process 2184326 has 274.00 MiB memory in use. Process 2186346 has 274.00 MiB memory in use. Process 2186900 has 274.00 MiB memory in use. Including non-PyTorch memory, this process has 732.00 MiB memory in use. Of the allocated memory 606.34 MiB is allocated by PyTorch, and 27.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 17/312 [00:02<00:39,  7.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "内存不足错误在批次 15: CUDA out of memory. Tried to allocate 490.00 MiB. GPU 0 has a total capacity of 4.75 GiB of which 259.38 MiB is free. Process 2070169 has 2.71 GiB memory in use. Process 2073078 has 1.06 GiB memory in use. Process 2183819 has 274.00 MiB memory in use. Process 2184326 has 274.00 MiB memory in use. Process 2186346 has 274.00 MiB memory in use. Process 2186900 has 274.00 MiB memory in use. Including non-PyTorch memory, this process has 732.00 MiB memory in use. Of the allocated memory 606.34 MiB is allocated by PyTorch, and 27.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "内存不足错误在批次 16: CUDA out of memory. Tried to allocate 490.00 MiB. GPU 0 has a total capacity of 4.75 GiB of which 259.38 MiB is free. Process 2070169 has 2.71 GiB memory in use. Process 2073078 has 1.06 GiB memory in use. Process 2183819 has 274.00 MiB memory in use. Process 2184326 has 274.00 MiB memory in use. Process 2186346 has 274.00 MiB memory in use. Process 2186900 has 274.00 MiB memory in use. Including non-PyTorch memory, this process has 732.00 MiB memory in use. Of the allocated memory 606.34 MiB is allocated by PyTorch, and 27.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "内存不足错误在批次 17: CUDA out of memory. Tried to allocate 490.00 MiB. GPU 0 has a total capacity of 4.75 GiB of which 259.38 MiB is free. Process 2070169 has 2.71 GiB memory in use. Process 2073078 has 1.06 GiB memory in use. Process 2183819 has 274.00 MiB memory in use. Process 2184326 has 274.00 MiB memory in use. Process 2186346 has 274.00 MiB memory in use. Process 2186900 has 274.00 MiB memory in use. Including non-PyTorch memory, this process has 732.00 MiB memory in use. Of the allocated memory 606.34 MiB is allocated by PyTorch, and 27.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 20/312 [00:03<00:38,  7.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "内存不足错误在批次 18: CUDA out of memory. Tried to allocate 490.00 MiB. GPU 0 has a total capacity of 4.75 GiB of which 259.38 MiB is free. Process 2070169 has 2.71 GiB memory in use. Process 2073078 has 1.06 GiB memory in use. Process 2183819 has 274.00 MiB memory in use. Process 2184326 has 274.00 MiB memory in use. Process 2186346 has 274.00 MiB memory in use. Process 2186900 has 274.00 MiB memory in use. Including non-PyTorch memory, this process has 732.00 MiB memory in use. Of the allocated memory 606.34 MiB is allocated by PyTorch, and 27.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "内存不足错误在批次 19: CUDA out of memory. Tried to allocate 490.00 MiB. GPU 0 has a total capacity of 4.75 GiB of which 259.38 MiB is free. Process 2070169 has 2.71 GiB memory in use. Process 2073078 has 1.06 GiB memory in use. Process 2183819 has 274.00 MiB memory in use. Process 2184326 has 274.00 MiB memory in use. Process 2186346 has 274.00 MiB memory in use. Process 2186900 has 274.00 MiB memory in use. Including non-PyTorch memory, this process has 732.00 MiB memory in use. Of the allocated memory 606.34 MiB is allocated by PyTorch, and 27.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "内存不足错误在批次 20: CUDA out of memory. Tried to allocate 490.00 MiB. GPU 0 has a total capacity of 4.75 GiB of which 259.38 MiB is free. Process 2070169 has 2.71 GiB memory in use. Process 2073078 has 1.06 GiB memory in use. Process 2183819 has 274.00 MiB memory in use. Process 2184326 has 274.00 MiB memory in use. Process 2186346 has 274.00 MiB memory in use. Process 2186900 has 274.00 MiB memory in use. Including non-PyTorch memory, this process has 732.00 MiB memory in use. Of the allocated memory 606.34 MiB is allocated by PyTorch, and 27.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 23/312 [00:03<00:38,  7.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "内存不足错误在批次 21: CUDA out of memory. Tried to allocate 490.00 MiB. GPU 0 has a total capacity of 4.75 GiB of which 259.38 MiB is free. Process 2070169 has 2.71 GiB memory in use. Process 2073078 has 1.06 GiB memory in use. Process 2183819 has 274.00 MiB memory in use. Process 2184326 has 274.00 MiB memory in use. Process 2186346 has 274.00 MiB memory in use. Process 2186900 has 274.00 MiB memory in use. Including non-PyTorch memory, this process has 732.00 MiB memory in use. Of the allocated memory 606.34 MiB is allocated by PyTorch, and 27.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "内存不足错误在批次 22: CUDA out of memory. Tried to allocate 490.00 MiB. GPU 0 has a total capacity of 4.75 GiB of which 259.38 MiB is free. Process 2070169 has 2.71 GiB memory in use. Process 2073078 has 1.06 GiB memory in use. Process 2183819 has 274.00 MiB memory in use. Process 2184326 has 274.00 MiB memory in use. Process 2186346 has 274.00 MiB memory in use. Process 2186900 has 274.00 MiB memory in use. Including non-PyTorch memory, this process has 732.00 MiB memory in use. Of the allocated memory 606.34 MiB is allocated by PyTorch, and 27.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "内存不足错误在批次 23: CUDA out of memory. Tried to allocate 490.00 MiB. GPU 0 has a total capacity of 4.75 GiB of which 259.38 MiB is free. Process 2070169 has 2.71 GiB memory in use. Process 2073078 has 1.06 GiB memory in use. Process 2183819 has 274.00 MiB memory in use. Process 2184326 has 274.00 MiB memory in use. Process 2186346 has 274.00 MiB memory in use. Process 2186900 has 274.00 MiB memory in use. Including non-PyTorch memory, this process has 732.00 MiB memory in use. Of the allocated memory 606.34 MiB is allocated by PyTorch, and 27.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 26/312 [00:03<00:37,  7.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "内存不足错误在批次 24: CUDA out of memory. Tried to allocate 490.00 MiB. GPU 0 has a total capacity of 4.75 GiB of which 259.38 MiB is free. Process 2070169 has 2.71 GiB memory in use. Process 2073078 has 1.06 GiB memory in use. Process 2183819 has 274.00 MiB memory in use. Process 2184326 has 274.00 MiB memory in use. Process 2186346 has 274.00 MiB memory in use. Process 2186900 has 274.00 MiB memory in use. Including non-PyTorch memory, this process has 732.00 MiB memory in use. Of the allocated memory 606.34 MiB is allocated by PyTorch, and 27.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "内存不足错误在批次 25: CUDA out of memory. Tried to allocate 490.00 MiB. GPU 0 has a total capacity of 4.75 GiB of which 259.38 MiB is free. Process 2070169 has 2.71 GiB memory in use. Process 2073078 has 1.06 GiB memory in use. Process 2183819 has 274.00 MiB memory in use. Process 2184326 has 274.00 MiB memory in use. Process 2186346 has 274.00 MiB memory in use. Process 2186900 has 274.00 MiB memory in use. Including non-PyTorch memory, this process has 732.00 MiB memory in use. Of the allocated memory 606.34 MiB is allocated by PyTorch, and 27.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "内存不足错误在批次 26: CUDA out of memory. Tried to allocate 490.00 MiB. GPU 0 has a total capacity of 4.75 GiB of which 259.38 MiB is free. Process 2070169 has 2.71 GiB memory in use. Process 2073078 has 1.06 GiB memory in use. Process 2183819 has 274.00 MiB memory in use. Process 2184326 has 274.00 MiB memory in use. Process 2186346 has 274.00 MiB memory in use. Process 2186900 has 274.00 MiB memory in use. Including non-PyTorch memory, this process has 732.00 MiB memory in use. Of the allocated memory 606.34 MiB is allocated by PyTorch, and 27.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 29/312 [00:04<00:37,  7.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "内存不足错误在批次 27: CUDA out of memory. Tried to allocate 490.00 MiB. GPU 0 has a total capacity of 4.75 GiB of which 259.38 MiB is free. Process 2070169 has 2.71 GiB memory in use. Process 2073078 has 1.06 GiB memory in use. Process 2183819 has 274.00 MiB memory in use. Process 2184326 has 274.00 MiB memory in use. Process 2186346 has 274.00 MiB memory in use. Process 2186900 has 274.00 MiB memory in use. Including non-PyTorch memory, this process has 732.00 MiB memory in use. Of the allocated memory 606.34 MiB is allocated by PyTorch, and 27.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "内存不足错误在批次 28: CUDA out of memory. Tried to allocate 490.00 MiB. GPU 0 has a total capacity of 4.75 GiB of which 259.38 MiB is free. Process 2070169 has 2.71 GiB memory in use. Process 2073078 has 1.06 GiB memory in use. Process 2183819 has 274.00 MiB memory in use. Process 2184326 has 274.00 MiB memory in use. Process 2186346 has 274.00 MiB memory in use. Process 2186900 has 274.00 MiB memory in use. Including non-PyTorch memory, this process has 732.00 MiB memory in use. Of the allocated memory 606.34 MiB is allocated by PyTorch, and 27.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "内存不足错误在批次 29: CUDA out of memory. Tried to allocate 490.00 MiB. GPU 0 has a total capacity of 4.75 GiB of which 259.38 MiB is free. Process 2070169 has 2.71 GiB memory in use. Process 2073078 has 1.06 GiB memory in use. Process 2183819 has 274.00 MiB memory in use. Process 2184326 has 274.00 MiB memory in use. Process 2186346 has 274.00 MiB memory in use. Process 2186900 has 274.00 MiB memory in use. Including non-PyTorch memory, this process has 732.00 MiB memory in use. Of the allocated memory 606.34 MiB is allocated by PyTorch, and 27.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 32/312 [00:04<00:36,  7.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "内存不足错误在批次 30: CUDA out of memory. Tried to allocate 490.00 MiB. GPU 0 has a total capacity of 4.75 GiB of which 259.38 MiB is free. Process 2070169 has 2.71 GiB memory in use. Process 2073078 has 1.06 GiB memory in use. Process 2183819 has 274.00 MiB memory in use. Process 2184326 has 274.00 MiB memory in use. Process 2186346 has 274.00 MiB memory in use. Process 2186900 has 274.00 MiB memory in use. Including non-PyTorch memory, this process has 732.00 MiB memory in use. Of the allocated memory 606.34 MiB is allocated by PyTorch, and 27.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "内存不足错误在批次 31: CUDA out of memory. Tried to allocate 490.00 MiB. GPU 0 has a total capacity of 4.75 GiB of which 259.38 MiB is free. Process 2070169 has 2.71 GiB memory in use. Process 2073078 has 1.06 GiB memory in use. Process 2183819 has 274.00 MiB memory in use. Process 2184326 has 274.00 MiB memory in use. Process 2186346 has 274.00 MiB memory in use. Process 2186900 has 274.00 MiB memory in use. Including non-PyTorch memory, this process has 732.00 MiB memory in use. Of the allocated memory 606.34 MiB is allocated by PyTorch, and 27.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "内存不足错误在批次 32: CUDA out of memory. Tried to allocate 490.00 MiB. GPU 0 has a total capacity of 4.75 GiB of which 259.38 MiB is free. Process 2070169 has 2.71 GiB memory in use. Process 2073078 has 1.06 GiB memory in use. Process 2183819 has 274.00 MiB memory in use. Process 2184326 has 274.00 MiB memory in use. Process 2186346 has 274.00 MiB memory in use. Process 2186900 has 274.00 MiB memory in use. Including non-PyTorch memory, this process has 732.00 MiB memory in use. Of the allocated memory 606.34 MiB is allocated by PyTorch, and 27.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 35/312 [00:05<00:36,  7.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "内存不足错误在批次 33: CUDA out of memory. Tried to allocate 490.00 MiB. GPU 0 has a total capacity of 4.75 GiB of which 259.38 MiB is free. Process 2070169 has 2.71 GiB memory in use. Process 2073078 has 1.06 GiB memory in use. Process 2183819 has 274.00 MiB memory in use. Process 2184326 has 274.00 MiB memory in use. Process 2186346 has 274.00 MiB memory in use. Process 2186900 has 274.00 MiB memory in use. Including non-PyTorch memory, this process has 732.00 MiB memory in use. Of the allocated memory 606.34 MiB is allocated by PyTorch, and 27.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "内存不足错误在批次 34: CUDA out of memory. Tried to allocate 490.00 MiB. GPU 0 has a total capacity of 4.75 GiB of which 259.38 MiB is free. Process 2070169 has 2.71 GiB memory in use. Process 2073078 has 1.06 GiB memory in use. Process 2183819 has 274.00 MiB memory in use. Process 2184326 has 274.00 MiB memory in use. Process 2186346 has 274.00 MiB memory in use. Process 2186900 has 274.00 MiB memory in use. Including non-PyTorch memory, this process has 732.00 MiB memory in use. Of the allocated memory 606.34 MiB is allocated by PyTorch, and 27.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "内存不足错误在批次 35: CUDA out of memory. Tried to allocate 490.00 MiB. GPU 0 has a total capacity of 4.75 GiB of which 259.38 MiB is free. Process 2070169 has 2.71 GiB memory in use. Process 2073078 has 1.06 GiB memory in use. Process 2183819 has 274.00 MiB memory in use. Process 2184326 has 274.00 MiB memory in use. Process 2186346 has 274.00 MiB memory in use. Process 2186900 has 274.00 MiB memory in use. Including non-PyTorch memory, this process has 732.00 MiB memory in use. Of the allocated memory 606.34 MiB is allocated by PyTorch, and 27.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 38/312 [00:05<00:36,  7.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "内存不足错误在批次 36: CUDA out of memory. Tried to allocate 490.00 MiB. GPU 0 has a total capacity of 4.75 GiB of which 259.38 MiB is free. Process 2070169 has 2.71 GiB memory in use. Process 2073078 has 1.06 GiB memory in use. Process 2183819 has 274.00 MiB memory in use. Process 2184326 has 274.00 MiB memory in use. Process 2186346 has 274.00 MiB memory in use. Process 2186900 has 274.00 MiB memory in use. Including non-PyTorch memory, this process has 732.00 MiB memory in use. Of the allocated memory 606.34 MiB is allocated by PyTorch, and 27.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "内存不足错误在批次 37: CUDA out of memory. Tried to allocate 490.00 MiB. GPU 0 has a total capacity of 4.75 GiB of which 259.38 MiB is free. Process 2070169 has 2.71 GiB memory in use. Process 2073078 has 1.06 GiB memory in use. Process 2183819 has 274.00 MiB memory in use. Process 2184326 has 274.00 MiB memory in use. Process 2186346 has 274.00 MiB memory in use. Process 2186900 has 274.00 MiB memory in use. Including non-PyTorch memory, this process has 732.00 MiB memory in use. Of the allocated memory 606.34 MiB is allocated by PyTorch, and 27.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "内存不足错误在批次 38: CUDA out of memory. Tried to allocate 490.00 MiB. GPU 0 has a total capacity of 4.75 GiB of which 259.38 MiB is free. Process 2070169 has 2.71 GiB memory in use. Process 2073078 has 1.06 GiB memory in use. Process 2183819 has 274.00 MiB memory in use. Process 2184326 has 274.00 MiB memory in use. Process 2186346 has 274.00 MiB memory in use. Process 2186900 has 274.00 MiB memory in use. Including non-PyTorch memory, this process has 732.00 MiB memory in use. Of the allocated memory 606.34 MiB is allocated by PyTorch, and 27.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 41/312 [00:05<00:35,  7.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "内存不足错误在批次 39: CUDA out of memory. Tried to allocate 490.00 MiB. GPU 0 has a total capacity of 4.75 GiB of which 259.38 MiB is free. Process 2070169 has 2.71 GiB memory in use. Process 2073078 has 1.06 GiB memory in use. Process 2183819 has 274.00 MiB memory in use. Process 2184326 has 274.00 MiB memory in use. Process 2186346 has 274.00 MiB memory in use. Process 2186900 has 274.00 MiB memory in use. Including non-PyTorch memory, this process has 732.00 MiB memory in use. Of the allocated memory 606.34 MiB is allocated by PyTorch, and 27.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "内存不足错误在批次 40: CUDA out of memory. Tried to allocate 490.00 MiB. GPU 0 has a total capacity of 4.75 GiB of which 259.38 MiB is free. Process 2070169 has 2.71 GiB memory in use. Process 2073078 has 1.06 GiB memory in use. Process 2183819 has 274.00 MiB memory in use. Process 2184326 has 274.00 MiB memory in use. Process 2186346 has 274.00 MiB memory in use. Process 2186900 has 274.00 MiB memory in use. Including non-PyTorch memory, this process has 732.00 MiB memory in use. Of the allocated memory 606.34 MiB is allocated by PyTorch, and 27.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "内存不足错误在批次 41: CUDA out of memory. Tried to allocate 490.00 MiB. GPU 0 has a total capacity of 4.75 GiB of which 259.38 MiB is free. Process 2070169 has 2.71 GiB memory in use. Process 2073078 has 1.06 GiB memory in use. Process 2183819 has 274.00 MiB memory in use. Process 2184326 has 274.00 MiB memory in use. Process 2186346 has 274.00 MiB memory in use. Process 2186900 has 274.00 MiB memory in use. Including non-PyTorch memory, this process has 732.00 MiB memory in use. Of the allocated memory 606.34 MiB is allocated by PyTorch, and 27.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 44/312 [00:06<00:34,  7.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "内存不足错误在批次 42: CUDA out of memory. Tried to allocate 490.00 MiB. GPU 0 has a total capacity of 4.75 GiB of which 259.38 MiB is free. Process 2070169 has 2.71 GiB memory in use. Process 2073078 has 1.06 GiB memory in use. Process 2183819 has 274.00 MiB memory in use. Process 2184326 has 274.00 MiB memory in use. Process 2186346 has 274.00 MiB memory in use. Process 2186900 has 274.00 MiB memory in use. Including non-PyTorch memory, this process has 732.00 MiB memory in use. Of the allocated memory 606.34 MiB is allocated by PyTorch, and 27.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "内存不足错误在批次 43: CUDA out of memory. Tried to allocate 490.00 MiB. GPU 0 has a total capacity of 4.75 GiB of which 259.38 MiB is free. Process 2070169 has 2.71 GiB memory in use. Process 2073078 has 1.06 GiB memory in use. Process 2183819 has 274.00 MiB memory in use. Process 2184326 has 274.00 MiB memory in use. Process 2186346 has 274.00 MiB memory in use. Process 2186900 has 274.00 MiB memory in use. Including non-PyTorch memory, this process has 732.00 MiB memory in use. Of the allocated memory 606.34 MiB is allocated by PyTorch, and 27.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "内存不足错误在批次 44: CUDA out of memory. Tried to allocate 490.00 MiB. GPU 0 has a total capacity of 4.75 GiB of which 259.38 MiB is free. Process 2070169 has 2.71 GiB memory in use. Process 2073078 has 1.06 GiB memory in use. Process 2183819 has 274.00 MiB memory in use. Process 2184326 has 274.00 MiB memory in use. Process 2186346 has 274.00 MiB memory in use. Process 2186900 has 274.00 MiB memory in use. Including non-PyTorch memory, this process has 732.00 MiB memory in use. Of the allocated memory 606.34 MiB is allocated by PyTorch, and 27.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 47/312 [00:06<00:34,  7.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "内存不足错误在批次 45: CUDA out of memory. Tried to allocate 490.00 MiB. GPU 0 has a total capacity of 4.75 GiB of which 259.38 MiB is free. Process 2070169 has 2.71 GiB memory in use. Process 2073078 has 1.06 GiB memory in use. Process 2183819 has 274.00 MiB memory in use. Process 2184326 has 274.00 MiB memory in use. Process 2186346 has 274.00 MiB memory in use. Process 2186900 has 274.00 MiB memory in use. Including non-PyTorch memory, this process has 732.00 MiB memory in use. Of the allocated memory 606.34 MiB is allocated by PyTorch, and 27.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "内存不足错误在批次 46: CUDA out of memory. Tried to allocate 490.00 MiB. GPU 0 has a total capacity of 4.75 GiB of which 259.38 MiB is free. Process 2070169 has 2.71 GiB memory in use. Process 2073078 has 1.06 GiB memory in use. Process 2183819 has 274.00 MiB memory in use. Process 2184326 has 274.00 MiB memory in use. Process 2186346 has 274.00 MiB memory in use. Process 2186900 has 274.00 MiB memory in use. Including non-PyTorch memory, this process has 732.00 MiB memory in use. Of the allocated memory 606.34 MiB is allocated by PyTorch, and 27.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "内存不足错误在批次 47: CUDA out of memory. Tried to allocate 490.00 MiB. GPU 0 has a total capacity of 4.75 GiB of which 259.38 MiB is free. Process 2070169 has 2.71 GiB memory in use. Process 2073078 has 1.06 GiB memory in use. Process 2183819 has 274.00 MiB memory in use. Process 2184326 has 274.00 MiB memory in use. Process 2186346 has 274.00 MiB memory in use. Process 2186900 has 274.00 MiB memory in use. Including non-PyTorch memory, this process has 732.00 MiB memory in use. Of the allocated memory 606.34 MiB is allocated by PyTorch, and 27.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 50/312 [00:07<00:34,  7.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "内存不足错误在批次 48: CUDA out of memory. Tried to allocate 490.00 MiB. GPU 0 has a total capacity of 4.75 GiB of which 259.38 MiB is free. Process 2070169 has 2.71 GiB memory in use. Process 2073078 has 1.06 GiB memory in use. Process 2183819 has 274.00 MiB memory in use. Process 2184326 has 274.00 MiB memory in use. Process 2186346 has 274.00 MiB memory in use. Process 2186900 has 274.00 MiB memory in use. Including non-PyTorch memory, this process has 732.00 MiB memory in use. Of the allocated memory 606.34 MiB is allocated by PyTorch, and 27.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "内存不足错误在批次 49: CUDA out of memory. Tried to allocate 490.00 MiB. GPU 0 has a total capacity of 4.75 GiB of which 259.38 MiB is free. Process 2070169 has 2.71 GiB memory in use. Process 2073078 has 1.06 GiB memory in use. Process 2183819 has 274.00 MiB memory in use. Process 2184326 has 274.00 MiB memory in use. Process 2186346 has 274.00 MiB memory in use. Process 2186900 has 274.00 MiB memory in use. Including non-PyTorch memory, this process has 732.00 MiB memory in use. Of the allocated memory 606.34 MiB is allocated by PyTorch, and 27.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "内存不足错误在批次 50: CUDA out of memory. Tried to allocate 490.00 MiB. GPU 0 has a total capacity of 4.75 GiB of which 259.38 MiB is free. Process 2070169 has 2.71 GiB memory in use. Process 2073078 has 1.06 GiB memory in use. Process 2183819 has 274.00 MiB memory in use. Process 2184326 has 274.00 MiB memory in use. Process 2186346 has 274.00 MiB memory in use. Process 2186900 has 274.00 MiB memory in use. Including non-PyTorch memory, this process has 732.00 MiB memory in use. Of the allocated memory 606.34 MiB is allocated by PyTorch, and 27.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 53/312 [00:07<00:33,  7.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "内存不足错误在批次 51: CUDA out of memory. Tried to allocate 490.00 MiB. GPU 0 has a total capacity of 4.75 GiB of which 259.38 MiB is free. Process 2070169 has 2.71 GiB memory in use. Process 2073078 has 1.06 GiB memory in use. Process 2183819 has 274.00 MiB memory in use. Process 2184326 has 274.00 MiB memory in use. Process 2186346 has 274.00 MiB memory in use. Process 2186900 has 274.00 MiB memory in use. Including non-PyTorch memory, this process has 732.00 MiB memory in use. Of the allocated memory 606.34 MiB is allocated by PyTorch, and 27.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "内存不足错误在批次 52: CUDA out of memory. Tried to allocate 490.00 MiB. GPU 0 has a total capacity of 4.75 GiB of which 259.38 MiB is free. Process 2070169 has 2.71 GiB memory in use. Process 2073078 has 1.06 GiB memory in use. Process 2183819 has 274.00 MiB memory in use. Process 2184326 has 274.00 MiB memory in use. Process 2186346 has 274.00 MiB memory in use. Process 2186900 has 274.00 MiB memory in use. Including non-PyTorch memory, this process has 732.00 MiB memory in use. Of the allocated memory 606.34 MiB is allocated by PyTorch, and 27.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "内存不足错误在批次 53: CUDA out of memory. Tried to allocate 490.00 MiB. GPU 0 has a total capacity of 4.75 GiB of which 259.38 MiB is free. Process 2070169 has 2.71 GiB memory in use. Process 2073078 has 1.06 GiB memory in use. Process 2183819 has 274.00 MiB memory in use. Process 2184326 has 274.00 MiB memory in use. Process 2186346 has 274.00 MiB memory in use. Process 2186900 has 274.00 MiB memory in use. Including non-PyTorch memory, this process has 732.00 MiB memory in use. Of the allocated memory 606.34 MiB is allocated by PyTorch, and 27.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 56/312 [00:07<00:33,  7.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "内存不足错误在批次 54: CUDA out of memory. Tried to allocate 490.00 MiB. GPU 0 has a total capacity of 4.75 GiB of which 259.38 MiB is free. Process 2070169 has 2.71 GiB memory in use. Process 2073078 has 1.06 GiB memory in use. Process 2183819 has 274.00 MiB memory in use. Process 2184326 has 274.00 MiB memory in use. Process 2186346 has 274.00 MiB memory in use. Process 2186900 has 274.00 MiB memory in use. Including non-PyTorch memory, this process has 732.00 MiB memory in use. Of the allocated memory 606.34 MiB is allocated by PyTorch, and 27.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "内存不足错误在批次 55: CUDA out of memory. Tried to allocate 490.00 MiB. GPU 0 has a total capacity of 4.75 GiB of which 259.38 MiB is free. Process 2070169 has 2.71 GiB memory in use. Process 2073078 has 1.06 GiB memory in use. Process 2183819 has 274.00 MiB memory in use. Process 2184326 has 274.00 MiB memory in use. Process 2186346 has 274.00 MiB memory in use. Process 2186900 has 274.00 MiB memory in use. Including non-PyTorch memory, this process has 732.00 MiB memory in use. Of the allocated memory 606.34 MiB is allocated by PyTorch, and 27.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "内存不足错误在批次 56: CUDA out of memory. Tried to allocate 490.00 MiB. GPU 0 has a total capacity of 4.75 GiB of which 259.38 MiB is free. Process 2070169 has 2.71 GiB memory in use. Process 2073078 has 1.06 GiB memory in use. Process 2183819 has 274.00 MiB memory in use. Process 2184326 has 274.00 MiB memory in use. Process 2186346 has 274.00 MiB memory in use. Process 2186900 has 274.00 MiB memory in use. Including non-PyTorch memory, this process has 732.00 MiB memory in use. Of the allocated memory 606.34 MiB is allocated by PyTorch, and 27.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 59/312 [00:08<00:33,  7.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "内存不足错误在批次 57: CUDA out of memory. Tried to allocate 490.00 MiB. GPU 0 has a total capacity of 4.75 GiB of which 259.38 MiB is free. Process 2070169 has 2.71 GiB memory in use. Process 2073078 has 1.06 GiB memory in use. Process 2183819 has 274.00 MiB memory in use. Process 2184326 has 274.00 MiB memory in use. Process 2186346 has 274.00 MiB memory in use. Process 2186900 has 274.00 MiB memory in use. Including non-PyTorch memory, this process has 732.00 MiB memory in use. Of the allocated memory 606.34 MiB is allocated by PyTorch, and 27.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "内存不足错误在批次 58: CUDA out of memory. Tried to allocate 490.00 MiB. GPU 0 has a total capacity of 4.75 GiB of which 259.38 MiB is free. Process 2070169 has 2.71 GiB memory in use. Process 2073078 has 1.06 GiB memory in use. Process 2183819 has 274.00 MiB memory in use. Process 2184326 has 274.00 MiB memory in use. Process 2186346 has 274.00 MiB memory in use. Process 2186900 has 274.00 MiB memory in use. Including non-PyTorch memory, this process has 732.00 MiB memory in use. Of the allocated memory 606.34 MiB is allocated by PyTorch, and 27.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "内存不足错误在批次 59: CUDA out of memory. Tried to allocate 490.00 MiB. GPU 0 has a total capacity of 4.75 GiB of which 259.38 MiB is free. Process 2070169 has 2.71 GiB memory in use. Process 2073078 has 1.06 GiB memory in use. Process 2183819 has 274.00 MiB memory in use. Process 2184326 has 274.00 MiB memory in use. Process 2186346 has 274.00 MiB memory in use. Process 2186900 has 274.00 MiB memory in use. Including non-PyTorch memory, this process has 732.00 MiB memory in use. Of the allocated memory 606.34 MiB is allocated by PyTorch, and 27.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 62/312 [00:08<00:32,  7.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "内存不足错误在批次 60: CUDA out of memory. Tried to allocate 490.00 MiB. GPU 0 has a total capacity of 4.75 GiB of which 259.38 MiB is free. Process 2070169 has 2.71 GiB memory in use. Process 2073078 has 1.06 GiB memory in use. Process 2183819 has 274.00 MiB memory in use. Process 2184326 has 274.00 MiB memory in use. Process 2186346 has 274.00 MiB memory in use. Process 2186900 has 274.00 MiB memory in use. Including non-PyTorch memory, this process has 732.00 MiB memory in use. Of the allocated memory 606.34 MiB is allocated by PyTorch, and 27.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "内存不足错误在批次 61: CUDA out of memory. Tried to allocate 490.00 MiB. GPU 0 has a total capacity of 4.75 GiB of which 259.38 MiB is free. Process 2070169 has 2.71 GiB memory in use. Process 2073078 has 1.06 GiB memory in use. Process 2183819 has 274.00 MiB memory in use. Process 2184326 has 274.00 MiB memory in use. Process 2186346 has 274.00 MiB memory in use. Process 2186900 has 274.00 MiB memory in use. Including non-PyTorch memory, this process has 732.00 MiB memory in use. Of the allocated memory 606.34 MiB is allocated by PyTorch, and 27.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "内存不足错误在批次 62: CUDA out of memory. Tried to allocate 490.00 MiB. GPU 0 has a total capacity of 4.75 GiB of which 259.38 MiB is free. Process 2070169 has 2.71 GiB memory in use. Process 2073078 has 1.06 GiB memory in use. Process 2183819 has 274.00 MiB memory in use. Process 2184326 has 274.00 MiB memory in use. Process 2186346 has 274.00 MiB memory in use. Process 2186900 has 274.00 MiB memory in use. Including non-PyTorch memory, this process has 732.00 MiB memory in use. Of the allocated memory 606.34 MiB is allocated by PyTorch, and 27.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 65/312 [00:09<00:32,  7.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "内存不足错误在批次 63: CUDA out of memory. Tried to allocate 490.00 MiB. GPU 0 has a total capacity of 4.75 GiB of which 259.38 MiB is free. Process 2070169 has 2.71 GiB memory in use. Process 2073078 has 1.06 GiB memory in use. Process 2183819 has 274.00 MiB memory in use. Process 2184326 has 274.00 MiB memory in use. Process 2186346 has 274.00 MiB memory in use. Process 2186900 has 274.00 MiB memory in use. Including non-PyTorch memory, this process has 732.00 MiB memory in use. Of the allocated memory 606.34 MiB is allocated by PyTorch, and 27.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "内存不足错误在批次 64: CUDA out of memory. Tried to allocate 490.00 MiB. GPU 0 has a total capacity of 4.75 GiB of which 259.38 MiB is free. Process 2070169 has 2.71 GiB memory in use. Process 2073078 has 1.06 GiB memory in use. Process 2183819 has 274.00 MiB memory in use. Process 2184326 has 274.00 MiB memory in use. Process 2186346 has 274.00 MiB memory in use. Process 2186900 has 274.00 MiB memory in use. Including non-PyTorch memory, this process has 732.00 MiB memory in use. Of the allocated memory 606.34 MiB is allocated by PyTorch, and 27.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "内存不足错误在批次 65: CUDA out of memory. Tried to allocate 490.00 MiB. GPU 0 has a total capacity of 4.75 GiB of which 259.38 MiB is free. Process 2070169 has 2.71 GiB memory in use. Process 2073078 has 1.06 GiB memory in use. Process 2183819 has 274.00 MiB memory in use. Process 2184326 has 274.00 MiB memory in use. Process 2186346 has 274.00 MiB memory in use. Process 2186900 has 274.00 MiB memory in use. Including non-PyTorch memory, this process has 732.00 MiB memory in use. Of the allocated memory 606.34 MiB is allocated by PyTorch, and 27.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 68/312 [00:09<00:31,  7.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "内存不足错误在批次 66: CUDA out of memory. Tried to allocate 490.00 MiB. GPU 0 has a total capacity of 4.75 GiB of which 259.38 MiB is free. Process 2070169 has 2.71 GiB memory in use. Process 2073078 has 1.06 GiB memory in use. Process 2183819 has 274.00 MiB memory in use. Process 2184326 has 274.00 MiB memory in use. Process 2186346 has 274.00 MiB memory in use. Process 2186900 has 274.00 MiB memory in use. Including non-PyTorch memory, this process has 732.00 MiB memory in use. Of the allocated memory 606.34 MiB is allocated by PyTorch, and 27.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "内存不足错误在批次 67: CUDA out of memory. Tried to allocate 490.00 MiB. GPU 0 has a total capacity of 4.75 GiB of which 259.38 MiB is free. Process 2070169 has 2.71 GiB memory in use. Process 2073078 has 1.06 GiB memory in use. Process 2183819 has 274.00 MiB memory in use. Process 2184326 has 274.00 MiB memory in use. Process 2186346 has 274.00 MiB memory in use. Process 2186900 has 274.00 MiB memory in use. Including non-PyTorch memory, this process has 732.00 MiB memory in use. Of the allocated memory 606.34 MiB is allocated by PyTorch, and 27.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "内存不足错误在批次 68: CUDA out of memory. Tried to allocate 490.00 MiB. GPU 0 has a total capacity of 4.75 GiB of which 259.38 MiB is free. Process 2070169 has 2.71 GiB memory in use. Process 2073078 has 1.06 GiB memory in use. Process 2183819 has 274.00 MiB memory in use. Process 2184326 has 274.00 MiB memory in use. Process 2186346 has 274.00 MiB memory in use. Process 2186900 has 274.00 MiB memory in use. Including non-PyTorch memory, this process has 732.00 MiB memory in use. Of the allocated memory 606.34 MiB is allocated by PyTorch, and 27.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 71/312 [00:09<00:31,  7.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "内存不足错误在批次 69: CUDA out of memory. Tried to allocate 490.00 MiB. GPU 0 has a total capacity of 4.75 GiB of which 259.38 MiB is free. Process 2070169 has 2.71 GiB memory in use. Process 2073078 has 1.06 GiB memory in use. Process 2183819 has 274.00 MiB memory in use. Process 2184326 has 274.00 MiB memory in use. Process 2186346 has 274.00 MiB memory in use. Process 2186900 has 274.00 MiB memory in use. Including non-PyTorch memory, this process has 732.00 MiB memory in use. Of the allocated memory 606.34 MiB is allocated by PyTorch, and 27.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "内存不足错误在批次 70: CUDA out of memory. Tried to allocate 490.00 MiB. GPU 0 has a total capacity of 4.75 GiB of which 259.38 MiB is free. Process 2070169 has 2.71 GiB memory in use. Process 2073078 has 1.06 GiB memory in use. Process 2183819 has 274.00 MiB memory in use. Process 2184326 has 274.00 MiB memory in use. Process 2186346 has 274.00 MiB memory in use. Process 2186900 has 274.00 MiB memory in use. Including non-PyTorch memory, this process has 732.00 MiB memory in use. Of the allocated memory 606.34 MiB is allocated by PyTorch, and 27.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "内存不足错误在批次 71: CUDA out of memory. Tried to allocate 490.00 MiB. GPU 0 has a total capacity of 4.75 GiB of which 259.38 MiB is free. Process 2070169 has 2.71 GiB memory in use. Process 2073078 has 1.06 GiB memory in use. Process 2183819 has 274.00 MiB memory in use. Process 2184326 has 274.00 MiB memory in use. Process 2186346 has 274.00 MiB memory in use. Process 2186900 has 274.00 MiB memory in use. Including non-PyTorch memory, this process has 732.00 MiB memory in use. Of the allocated memory 606.34 MiB is allocated by PyTorch, and 27.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▎       | 74/312 [00:10<00:31,  7.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "内存不足错误在批次 72: CUDA out of memory. Tried to allocate 490.00 MiB. GPU 0 has a total capacity of 4.75 GiB of which 259.38 MiB is free. Process 2070169 has 2.71 GiB memory in use. Process 2073078 has 1.06 GiB memory in use. Process 2183819 has 274.00 MiB memory in use. Process 2184326 has 274.00 MiB memory in use. Process 2186346 has 274.00 MiB memory in use. Process 2186900 has 274.00 MiB memory in use. Including non-PyTorch memory, this process has 732.00 MiB memory in use. Of the allocated memory 606.34 MiB is allocated by PyTorch, and 27.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "内存不足错误在批次 73: CUDA out of memory. Tried to allocate 490.00 MiB. GPU 0 has a total capacity of 4.75 GiB of which 259.38 MiB is free. Process 2070169 has 2.71 GiB memory in use. Process 2073078 has 1.06 GiB memory in use. Process 2183819 has 274.00 MiB memory in use. Process 2184326 has 274.00 MiB memory in use. Process 2186346 has 274.00 MiB memory in use. Process 2186900 has 274.00 MiB memory in use. Including non-PyTorch memory, this process has 732.00 MiB memory in use. Of the allocated memory 606.34 MiB is allocated by PyTorch, and 27.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "内存不足错误在批次 74: CUDA out of memory. Tried to allocate 490.00 MiB. GPU 0 has a total capacity of 4.75 GiB of which 259.38 MiB is free. Process 2070169 has 2.71 GiB memory in use. Process 2073078 has 1.06 GiB memory in use. Process 2183819 has 274.00 MiB memory in use. Process 2184326 has 274.00 MiB memory in use. Process 2186346 has 274.00 MiB memory in use. Process 2186900 has 274.00 MiB memory in use. Including non-PyTorch memory, this process has 732.00 MiB memory in use. Of the allocated memory 606.34 MiB is allocated by PyTorch, and 27.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 77/312 [00:10<00:31,  7.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "内存不足错误在批次 75: CUDA out of memory. Tried to allocate 490.00 MiB. GPU 0 has a total capacity of 4.75 GiB of which 259.38 MiB is free. Process 2070169 has 2.71 GiB memory in use. Process 2073078 has 1.06 GiB memory in use. Process 2183819 has 274.00 MiB memory in use. Process 2184326 has 274.00 MiB memory in use. Process 2186346 has 274.00 MiB memory in use. Process 2186900 has 274.00 MiB memory in use. Including non-PyTorch memory, this process has 732.00 MiB memory in use. Of the allocated memory 606.34 MiB is allocated by PyTorch, and 27.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "内存不足错误在批次 76: CUDA out of memory. Tried to allocate 490.00 MiB. GPU 0 has a total capacity of 4.75 GiB of which 259.38 MiB is free. Process 2070169 has 2.71 GiB memory in use. Process 2073078 has 1.06 GiB memory in use. Process 2183819 has 274.00 MiB memory in use. Process 2184326 has 274.00 MiB memory in use. Process 2186346 has 274.00 MiB memory in use. Process 2186900 has 274.00 MiB memory in use. Including non-PyTorch memory, this process has 732.00 MiB memory in use. Of the allocated memory 606.34 MiB is allocated by PyTorch, and 27.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "内存不足错误在批次 77: CUDA out of memory. Tried to allocate 490.00 MiB. GPU 0 has a total capacity of 4.75 GiB of which 259.38 MiB is free. Process 2070169 has 2.71 GiB memory in use. Process 2073078 has 1.06 GiB memory in use. Process 2183819 has 274.00 MiB memory in use. Process 2184326 has 274.00 MiB memory in use. Process 2186346 has 274.00 MiB memory in use. Process 2186900 has 274.00 MiB memory in use. Including non-PyTorch memory, this process has 732.00 MiB memory in use. Of the allocated memory 606.34 MiB is allocated by PyTorch, and 27.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 80/312 [00:10<00:31,  7.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "内存不足错误在批次 78: CUDA out of memory. Tried to allocate 490.00 MiB. GPU 0 has a total capacity of 4.75 GiB of which 259.38 MiB is free. Process 2070169 has 2.71 GiB memory in use. Process 2073078 has 1.06 GiB memory in use. Process 2183819 has 274.00 MiB memory in use. Process 2184326 has 274.00 MiB memory in use. Process 2186346 has 274.00 MiB memory in use. Process 2186900 has 274.00 MiB memory in use. Including non-PyTorch memory, this process has 732.00 MiB memory in use. Of the allocated memory 606.34 MiB is allocated by PyTorch, and 27.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "内存不足错误在批次 79: CUDA out of memory. Tried to allocate 490.00 MiB. GPU 0 has a total capacity of 4.75 GiB of which 259.38 MiB is free. Process 2070169 has 2.71 GiB memory in use. Process 2073078 has 1.06 GiB memory in use. Process 2183819 has 274.00 MiB memory in use. Process 2184326 has 274.00 MiB memory in use. Process 2186346 has 274.00 MiB memory in use. Process 2186900 has 274.00 MiB memory in use. Including non-PyTorch memory, this process has 732.00 MiB memory in use. Of the allocated memory 606.34 MiB is allocated by PyTorch, and 27.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "内存不足错误在批次 80: CUDA out of memory. Tried to allocate 490.00 MiB. GPU 0 has a total capacity of 4.75 GiB of which 259.38 MiB is free. Process 2070169 has 2.71 GiB memory in use. Process 2073078 has 1.06 GiB memory in use. Process 2183819 has 274.00 MiB memory in use. Process 2184326 has 274.00 MiB memory in use. Process 2186346 has 274.00 MiB memory in use. Process 2186900 has 274.00 MiB memory in use. Including non-PyTorch memory, this process has 732.00 MiB memory in use. Of the allocated memory 606.34 MiB is allocated by PyTorch, and 27.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 83/312 [00:11<00:30,  7.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "内存不足错误在批次 81: CUDA out of memory. Tried to allocate 490.00 MiB. GPU 0 has a total capacity of 4.75 GiB of which 259.38 MiB is free. Process 2070169 has 2.71 GiB memory in use. Process 2073078 has 1.06 GiB memory in use. Process 2183819 has 274.00 MiB memory in use. Process 2184326 has 274.00 MiB memory in use. Process 2186346 has 274.00 MiB memory in use. Process 2186900 has 274.00 MiB memory in use. Including non-PyTorch memory, this process has 732.00 MiB memory in use. Of the allocated memory 606.34 MiB is allocated by PyTorch, and 27.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "内存不足错误在批次 82: CUDA out of memory. Tried to allocate 490.00 MiB. GPU 0 has a total capacity of 4.75 GiB of which 259.38 MiB is free. Process 2070169 has 2.71 GiB memory in use. Process 2073078 has 1.06 GiB memory in use. Process 2183819 has 274.00 MiB memory in use. Process 2184326 has 274.00 MiB memory in use. Process 2186346 has 274.00 MiB memory in use. Process 2186900 has 274.00 MiB memory in use. Including non-PyTorch memory, this process has 732.00 MiB memory in use. Of the allocated memory 606.34 MiB is allocated by PyTorch, and 27.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "内存不足错误在批次 83: CUDA out of memory. Tried to allocate 490.00 MiB. GPU 0 has a total capacity of 4.75 GiB of which 259.38 MiB is free. Process 2070169 has 2.71 GiB memory in use. Process 2073078 has 1.06 GiB memory in use. Process 2183819 has 274.00 MiB memory in use. Process 2184326 has 274.00 MiB memory in use. Process 2186346 has 274.00 MiB memory in use. Process 2186900 has 274.00 MiB memory in use. Including non-PyTorch memory, this process has 732.00 MiB memory in use. Of the allocated memory 606.34 MiB is allocated by PyTorch, and 27.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 84/312 [00:11<00:30,  7.49it/s]Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x7fffb51edb20>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 775, in _clean_thread_parent_frames\n",
      "    def _clean_thread_parent_frames(\n",
      "\n",
      "KeyboardInterrupt: \n",
      " 28%|██▊       | 86/312 [00:11<00:30,  7.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "内存不足错误在批次 84: CUDA out of memory. Tried to allocate 490.00 MiB. GPU 0 has a total capacity of 4.75 GiB of which 259.38 MiB is free. Process 2070169 has 2.71 GiB memory in use. Process 2073078 has 1.06 GiB memory in use. Process 2183819 has 274.00 MiB memory in use. Process 2184326 has 274.00 MiB memory in use. Process 2186346 has 274.00 MiB memory in use. Process 2186900 has 274.00 MiB memory in use. Including non-PyTorch memory, this process has 732.00 MiB memory in use. Of the allocated memory 606.34 MiB is allocated by PyTorch, and 27.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "内存不足错误在批次 85: CUDA out of memory. Tried to allocate 490.00 MiB. GPU 0 has a total capacity of 4.75 GiB of which 259.38 MiB is free. Process 2070169 has 2.71 GiB memory in use. Process 2073078 has 1.06 GiB memory in use. Process 2183819 has 274.00 MiB memory in use. Process 2184326 has 274.00 MiB memory in use. Process 2186346 has 274.00 MiB memory in use. Process 2186900 has 274.00 MiB memory in use. Including non-PyTorch memory, this process has 732.00 MiB memory in use. Of the allocated memory 606.34 MiB is allocated by PyTorch, and 27.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "内存不足错误在批次 86: CUDA out of memory. Tried to allocate 490.00 MiB. GPU 0 has a total capacity of 4.75 GiB of which 259.38 MiB is free. Process 2070169 has 2.71 GiB memory in use. Process 2073078 has 1.06 GiB memory in use. Process 2183819 has 274.00 MiB memory in use. Process 2184326 has 274.00 MiB memory in use. Process 2186346 has 274.00 MiB memory in use. Process 2186900 has 274.00 MiB memory in use. Including non-PyTorch memory, this process has 732.00 MiB memory in use. Of the allocated memory 606.34 MiB is allocated by PyTorch, and 27.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 88/312 [00:12<00:29,  7.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "内存不足错误在批次 87: CUDA out of memory. Tried to allocate 490.00 MiB. GPU 0 has a total capacity of 4.75 GiB of which 259.38 MiB is free. Process 2070169 has 2.71 GiB memory in use. Process 2073078 has 1.06 GiB memory in use. Process 2183819 has 274.00 MiB memory in use. Process 2184326 has 274.00 MiB memory in use. Process 2186346 has 274.00 MiB memory in use. Process 2186900 has 274.00 MiB memory in use. Including non-PyTorch memory, this process has 732.00 MiB memory in use. Of the allocated memory 606.34 MiB is allocated by PyTorch, and 27.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 88/312 [00:17<00:43,  5.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练错误: DataLoader worker (pid(s) 2235979, 2235980) exited unexpectedly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  1%|          | 2/312 [00:00<00:51,  6.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "内存不足错误在批次 0: CUDA out of memory. Tried to allocate 490.00 MiB. GPU 0 has a total capacity of 4.75 GiB of which 271.38 MiB is free. Process 2070169 has 2.71 GiB memory in use. Process 2073078 has 1.06 GiB memory in use. Process 2183819 has 274.00 MiB memory in use. Process 2184326 has 274.00 MiB memory in use. Process 2186346 has 274.00 MiB memory in use. Process 2186900 has 274.00 MiB memory in use. Including non-PyTorch memory, this process has 720.00 MiB memory in use. Of the allocated memory 606.84 MiB is allocated by PyTorch, and 15.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "内存不足错误在批次 1: CUDA out of memory. Tried to allocate 490.00 MiB. GPU 0 has a total capacity of 4.75 GiB of which 271.38 MiB is free. Process 2070169 has 2.71 GiB memory in use. Process 2073078 has 1.06 GiB memory in use. Process 2183819 has 274.00 MiB memory in use. Process 2184326 has 274.00 MiB memory in use. Process 2186346 has 274.00 MiB memory in use. Process 2186900 has 274.00 MiB memory in use. Including non-PyTorch memory, this process has 720.00 MiB memory in use. Of the allocated memory 606.47 MiB is allocated by PyTorch, and 15.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "内存不足错误在批次 2: CUDA out of memory. Tried to allocate 490.00 MiB. GPU 0 has a total capacity of 4.75 GiB of which 271.38 MiB is free. Process 2070169 has 2.71 GiB memory in use. Process 2073078 has 1.06 GiB memory in use. Process 2183819 has 274.00 MiB memory in use. Process 2184326 has 274.00 MiB memory in use. Process 2186346 has 274.00 MiB memory in use. Process 2186900 has 274.00 MiB memory in use. Including non-PyTorch memory, this process has 720.00 MiB memory in use. Of the allocated memory 606.47 MiB is allocated by PyTorch, and 15.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 5/312 [00:00<00:43,  7.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "内存不足错误在批次 3: CUDA out of memory. Tried to allocate 490.00 MiB. GPU 0 has a total capacity of 4.75 GiB of which 271.38 MiB is free. Process 2070169 has 2.71 GiB memory in use. Process 2073078 has 1.06 GiB memory in use. Process 2183819 has 274.00 MiB memory in use. Process 2184326 has 274.00 MiB memory in use. Process 2186346 has 274.00 MiB memory in use. Process 2186900 has 274.00 MiB memory in use. Including non-PyTorch memory, this process has 720.00 MiB memory in use. Of the allocated memory 606.47 MiB is allocated by PyTorch, and 15.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "内存不足错误在批次 4: CUDA out of memory. Tried to allocate 490.00 MiB. GPU 0 has a total capacity of 4.75 GiB of which 271.38 MiB is free. Process 2070169 has 2.71 GiB memory in use. Process 2073078 has 1.06 GiB memory in use. Process 2183819 has 274.00 MiB memory in use. Process 2184326 has 274.00 MiB memory in use. Process 2186346 has 274.00 MiB memory in use. Process 2186900 has 274.00 MiB memory in use. Including non-PyTorch memory, this process has 720.00 MiB memory in use. Of the allocated memory 606.47 MiB is allocated by PyTorch, and 15.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "内存不足错误在批次 5: CUDA out of memory. Tried to allocate 490.00 MiB. GPU 0 has a total capacity of 4.75 GiB of which 271.38 MiB is free. Process 2070169 has 2.71 GiB memory in use. Process 2073078 has 1.06 GiB memory in use. Process 2183819 has 274.00 MiB memory in use. Process 2184326 has 274.00 MiB memory in use. Process 2186346 has 274.00 MiB memory in use. Process 2186900 has 274.00 MiB memory in use. Including non-PyTorch memory, this process has 720.00 MiB memory in use. Of the allocated memory 606.47 MiB is allocated by PyTorch, and 15.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 8/312 [00:01<00:41,  7.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "内存不足错误在批次 6: CUDA out of memory. Tried to allocate 490.00 MiB. GPU 0 has a total capacity of 4.75 GiB of which 271.38 MiB is free. Process 2070169 has 2.71 GiB memory in use. Process 2073078 has 1.06 GiB memory in use. Process 2183819 has 274.00 MiB memory in use. Process 2184326 has 274.00 MiB memory in use. Process 2186346 has 274.00 MiB memory in use. Process 2186900 has 274.00 MiB memory in use. Including non-PyTorch memory, this process has 720.00 MiB memory in use. Of the allocated memory 606.47 MiB is allocated by PyTorch, and 15.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "内存不足错误在批次 7: CUDA out of memory. Tried to allocate 490.00 MiB. GPU 0 has a total capacity of 4.75 GiB of which 271.38 MiB is free. Process 2070169 has 2.71 GiB memory in use. Process 2073078 has 1.06 GiB memory in use. Process 2183819 has 274.00 MiB memory in use. Process 2184326 has 274.00 MiB memory in use. Process 2186346 has 274.00 MiB memory in use. Process 2186900 has 274.00 MiB memory in use. Including non-PyTorch memory, this process has 720.00 MiB memory in use. Of the allocated memory 606.47 MiB is allocated by PyTorch, and 15.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "内存不足错误在批次 8: CUDA out of memory. Tried to allocate 490.00 MiB. GPU 0 has a total capacity of 4.75 GiB of which 271.38 MiB is free. Process 2070169 has 2.71 GiB memory in use. Process 2073078 has 1.06 GiB memory in use. Process 2183819 has 274.00 MiB memory in use. Process 2184326 has 274.00 MiB memory in use. Process 2186346 has 274.00 MiB memory in use. Process 2186900 has 274.00 MiB memory in use. Including non-PyTorch memory, this process has 720.00 MiB memory in use. Of the allocated memory 606.47 MiB is allocated by PyTorch, and 15.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 11/312 [00:01<00:39,  7.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "内存不足错误在批次 9: CUDA out of memory. Tried to allocate 490.00 MiB. GPU 0 has a total capacity of 4.75 GiB of which 271.38 MiB is free. Process 2070169 has 2.71 GiB memory in use. Process 2073078 has 1.06 GiB memory in use. Process 2183819 has 274.00 MiB memory in use. Process 2184326 has 274.00 MiB memory in use. Process 2186346 has 274.00 MiB memory in use. Process 2186900 has 274.00 MiB memory in use. Including non-PyTorch memory, this process has 720.00 MiB memory in use. Of the allocated memory 606.47 MiB is allocated by PyTorch, and 15.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "内存不足错误在批次 10: CUDA out of memory. Tried to allocate 490.00 MiB. GPU 0 has a total capacity of 4.75 GiB of which 271.38 MiB is free. Process 2070169 has 2.71 GiB memory in use. Process 2073078 has 1.06 GiB memory in use. Process 2183819 has 274.00 MiB memory in use. Process 2184326 has 274.00 MiB memory in use. Process 2186346 has 274.00 MiB memory in use. Process 2186900 has 274.00 MiB memory in use. Including non-PyTorch memory, this process has 720.00 MiB memory in use. Of the allocated memory 606.47 MiB is allocated by PyTorch, and 15.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "内存不足错误在批次 11: CUDA out of memory. Tried to allocate 490.00 MiB. GPU 0 has a total capacity of 4.75 GiB of which 271.38 MiB is free. Process 2070169 has 2.71 GiB memory in use. Process 2073078 has 1.06 GiB memory in use. Process 2183819 has 274.00 MiB memory in use. Process 2184326 has 274.00 MiB memory in use. Process 2186346 has 274.00 MiB memory in use. Process 2186900 has 274.00 MiB memory in use. Including non-PyTorch memory, this process has 720.00 MiB memory in use. Of the allocated memory 606.47 MiB is allocated by PyTorch, and 15.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 14/312 [00:01<00:39,  7.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "内存不足错误在批次 12: CUDA out of memory. Tried to allocate 490.00 MiB. GPU 0 has a total capacity of 4.75 GiB of which 271.38 MiB is free. Process 2070169 has 2.71 GiB memory in use. Process 2073078 has 1.06 GiB memory in use. Process 2183819 has 274.00 MiB memory in use. Process 2184326 has 274.00 MiB memory in use. Process 2186346 has 274.00 MiB memory in use. Process 2186900 has 274.00 MiB memory in use. Including non-PyTorch memory, this process has 720.00 MiB memory in use. Of the allocated memory 606.47 MiB is allocated by PyTorch, and 15.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "内存不足错误在批次 13: CUDA out of memory. Tried to allocate 490.00 MiB. GPU 0 has a total capacity of 4.75 GiB of which 271.38 MiB is free. Process 2070169 has 2.71 GiB memory in use. Process 2073078 has 1.06 GiB memory in use. Process 2183819 has 274.00 MiB memory in use. Process 2184326 has 274.00 MiB memory in use. Process 2186346 has 274.00 MiB memory in use. Process 2186900 has 274.00 MiB memory in use. Including non-PyTorch memory, this process has 720.00 MiB memory in use. Of the allocated memory 606.47 MiB is allocated by PyTorch, and 15.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "内存不足错误在批次 14: CUDA out of memory. Tried to allocate 490.00 MiB. GPU 0 has a total capacity of 4.75 GiB of which 271.38 MiB is free. Process 2070169 has 2.71 GiB memory in use. Process 2073078 has 1.06 GiB memory in use. Process 2183819 has 274.00 MiB memory in use. Process 2184326 has 274.00 MiB memory in use. Process 2186346 has 274.00 MiB memory in use. Process 2186900 has 274.00 MiB memory in use. Including non-PyTorch memory, this process has 720.00 MiB memory in use. Of the allocated memory 606.47 MiB is allocated by PyTorch, and 15.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x7fffb51edb20>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 775, in _clean_thread_parent_frames\n",
      "    def _clean_thread_parent_frames(\n",
      "\n",
      "KeyboardInterrupt: \n",
      "  5%|▌         | 17/312 [00:02<00:38,  7.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "内存不足错误在批次 15: CUDA out of memory. Tried to allocate 490.00 MiB. GPU 0 has a total capacity of 4.75 GiB of which 271.38 MiB is free. Process 2070169 has 2.71 GiB memory in use. Process 2073078 has 1.06 GiB memory in use. Process 2183819 has 274.00 MiB memory in use. Process 2184326 has 274.00 MiB memory in use. Process 2186346 has 274.00 MiB memory in use. Process 2186900 has 274.00 MiB memory in use. Including non-PyTorch memory, this process has 720.00 MiB memory in use. Of the allocated memory 606.47 MiB is allocated by PyTorch, and 15.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "内存不足错误在批次 16: CUDA out of memory. Tried to allocate 490.00 MiB. GPU 0 has a total capacity of 4.75 GiB of which 271.38 MiB is free. Process 2070169 has 2.71 GiB memory in use. Process 2073078 has 1.06 GiB memory in use. Process 2183819 has 274.00 MiB memory in use. Process 2184326 has 274.00 MiB memory in use. Process 2186346 has 274.00 MiB memory in use. Process 2186900 has 274.00 MiB memory in use. Including non-PyTorch memory, this process has 720.00 MiB memory in use. Of the allocated memory 606.47 MiB is allocated by PyTorch, and 15.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "内存不足错误在批次 17: CUDA out of memory. Tried to allocate 490.00 MiB. GPU 0 has a total capacity of 4.75 GiB of which 271.38 MiB is free. Process 2070169 has 2.71 GiB memory in use. Process 2073078 has 1.06 GiB memory in use. Process 2183819 has 274.00 MiB memory in use. Process 2184326 has 274.00 MiB memory in use. Process 2186346 has 274.00 MiB memory in use. Process 2186900 has 274.00 MiB memory in use. Including non-PyTorch memory, this process has 720.00 MiB memory in use. Of the allocated memory 606.47 MiB is allocated by PyTorch, and 15.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x7fffb51edb20>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 775, in _clean_thread_parent_frames\n",
      "    def _clean_thread_parent_frames(\n",
      "\n",
      "KeyboardInterrupt: \n",
      "  6%|▌         | 18/312 [00:03<01:02,  4.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练被用户中断\n",
      "训练完成，最佳验证准确率: 0.00%\n",
      "评估模型性能...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "评估中:   0%|          | 0/348 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 978.00 MiB. GPU 0 has a total capacity of 4.75 GiB of which 675.38 MiB is free. Process 2070169 has 2.71 GiB memory in use. Process 2073078 has 1.06 GiB memory in use. Process 2183819 has 274.00 MiB memory in use. Process 2184326 has 274.00 MiB memory in use. Process 2186346 has 274.00 MiB memory in use. Process 2186900 has 274.00 MiB memory in use. Including non-PyTorch memory, this process has 316.00 MiB memory in use. Of the allocated memory 164.93 MiB is allocated by PyTorch, and 53.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOutOfMemoryError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 498\u001b[39m\n\u001b[32m    496\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m评估模型性能...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    497\u001b[39m evaluator = T5Evaluator(trainer.model, config)\n\u001b[32m--> \u001b[39m\u001b[32m498\u001b[39m test_metrics = \u001b[43mevaluator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataloaders\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtest\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m测试集性能:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    500\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m总损失: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_metrics[\u001b[33m'\u001b[39m\u001b[33mtotal_loss\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 424\u001b[39m, in \u001b[36mT5Evaluator.evaluate\u001b[39m\u001b[34m(self, dataloader)\u001b[39m\n\u001b[32m    421\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m inputs.dim() == \u001b[32m2\u001b[39m:\n\u001b[32m    422\u001b[39m     inputs = inputs.unsqueeze(\u001b[32m1\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m424\u001b[39m outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    425\u001b[39m losses = \u001b[38;5;28mself\u001b[39m.criterion(outputs, labels, epoch=\u001b[32m1\u001b[39m)\n\u001b[32m    427\u001b[39m \u001b[38;5;66;03m# 累计损失\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib64/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib64/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 189\u001b[39m, in \u001b[36mT5CHiLAPModel.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    186\u001b[39m x, chaos_state = \u001b[38;5;28mself\u001b[39m.chaos_layer(x)  \u001b[38;5;66;03m# [B, HIDDEN_DIM, L/8]\u001b[39;00m\n\u001b[32m    188\u001b[39m \u001b[38;5;66;03m# 注意力处理（获取权重用于损失分析）\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m189\u001b[39m x, attn_weights = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# [B, HIDDEN_DIM, L/8]\u001b[39;00m\n\u001b[32m    191\u001b[39m \u001b[38;5;66;03m# TDNN处理\u001b[39;00m\n\u001b[32m    192\u001b[39m x = \u001b[38;5;28mself\u001b[39m.tdnn_block(x)  \u001b[38;5;66;03m# [B, HIDDEN_DIM, L/8]\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib64/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib64/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 69\u001b[39m, in \u001b[36mEnhancedAttention.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     66\u001b[39m v = \u001b[38;5;28mself\u001b[39m.value(x).view(batch_size, \u001b[38;5;28mself\u001b[39m.heads, \u001b[38;5;28mself\u001b[39m.head_dim, seq_len)  \u001b[38;5;66;03m# [B, H, D, L]\u001b[39;00m\n\u001b[32m     68\u001b[39m \u001b[38;5;66;03m# 计算注意力分数 [B, H, L, L]\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m69\u001b[39m scores = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mq\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m / (\u001b[38;5;28mself\u001b[39m.head_dim **\u001b[32m0.5\u001b[39m)\n\u001b[32m     70\u001b[39m attn_weights = F.softmax(scores, dim=-\u001b[32m1\u001b[39m)\n\u001b[32m     72\u001b[39m \u001b[38;5;66;03m# 应用注意力权重\u001b[39;00m\n",
      "\u001b[31mOutOfMemoryError\u001b[39m: CUDA out of memory. Tried to allocate 978.00 MiB. GPU 0 has a total capacity of 4.75 GiB of which 675.38 MiB is free. Process 2070169 has 2.71 GiB memory in use. Process 2073078 has 1.06 GiB memory in use. Process 2183819 has 274.00 MiB memory in use. Process 2184326 has 274.00 MiB memory in use. Process 2186346 has 274.00 MiB memory in use. Process 2186900 has 274.00 MiB memory in use. Including non-PyTorch memory, this process has 316.00 MiB memory in use. Of the allocated memory 164.93 MiB is allocated by PyTorch, and 53.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import os\n",
    "import gc\n",
    "import math\n",
    "\n",
    "# 复杂损失函数实现（T5模型核心）\n",
    "class ComplexLoss(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.ce_loss = nn.CrossEntropyLoss()\n",
    "        \n",
    "    def phase_synchronization_loss(self, chaos_state, reference_attractor):\n",
    "        \"\"\"相位同步损失：衡量混沌状态与参考吸引子的同步性\"\"\"\n",
    "        # 调整参考吸引子形状以匹配混沌状态\n",
    "        batch_size = chaos_state.shape[0]\n",
    "        ref = reference_attractor.repeat(batch_size, 1, 1)  # [B, C, T]\n",
    "        \n",
    "        # 计算动态时间规整(DTW)距离作为同步性度量\n",
    "        dtw_dist = self._dtw_distance(chaos_state, ref)\n",
    "        return torch.mean(dtw_dist)\n",
    "    \n",
    "    def lyapunov_stability_loss(self, embeddings):\n",
    "        \"\"\"李雅普诺夫稳定性损失：衡量嵌入向量的稳定性\"\"\"\n",
    "        # 计算嵌入向量的余弦相似度矩阵\n",
    "        cos_sim = F.cosine_similarity(embeddings.unsqueeze(1), embeddings.unsqueeze(0), dim=2)\n",
    "        # 计算相似度方差作为不稳定性度量\n",
    "        return torch.var(cos_sim)\n",
    "    \n",
    "    def _dtw_distance(self, x, y):\n",
    "        \"\"\"动态时间规整距离计算（简化版）\"\"\"\n",
    "        batch_size, channels, seq_len = x.shape\n",
    "        dist_matrix = torch.cdist(x.permute(0, 2, 1), y.permute(0, 2, 1))  # [B, L, T]\n",
    "        \n",
    "        # 累积距离计算\n",
    "        dtw = torch.zeros_like(dist_matrix)\n",
    "        dtw[:, 0, 0] = dist_matrix[:, 0, 0]\n",
    "        \n",
    "        for i in range(1, seq_len):\n",
    "            dtw[:, i, 0] = dtw[:, i-1, 0] + dist_matrix[:, i, 0]\n",
    "            \n",
    "        for j in range(1, y.shape[2]):\n",
    "            dtw[:, 0, j] = dtw[:, 0, j-1] + dist_matrix[:, 0, j]\n",
    "            \n",
    "        for i in range(1, seq_len):\n",
    "            for j in range(1, y.shape[2]):\n",
    "                dtw[:, i, j] = dist_matrix[:, i, j] + torch.min(\n",
    "                    torch.stack([dtw[:, i-1, j], dtw[:, i, j-1], dtw[:, i-1, j-1]]), dim=0\n",
    "                ).values\n",
    "                \n",
    "        return dtw[:, -1, -1]  # 返回每条序列的最终距离\n",
    "    \n",
    "    def forward(self, model_outputs, labels, epoch):\n",
    "        \"\"\"\n",
    "        前向传播计算总损失\n",
    "        :param model_outputs: 模型输出字典\n",
    "        :param labels: 真实标签\n",
    "        :param epoch: 当前 epoch（用于损失预热）\n",
    "        :return: 总损失及各分项损失\n",
    "        \"\"\"\n",
    "        # 基础交叉熵损失\n",
    "        ce = self.ce_loss(model_outputs[\"logits\"], labels)\n",
    "        \n",
    "        # 损失预热：逐步增加复杂损失权重\n",
    "        warmup_factor = min(1.0, epoch / self.config.LOSS_WARMUP_EPOCHS) if self.training else 1.0\n",
    "        \n",
    "        # 相位同步损失\n",
    "        sync_loss = self.phase_synchronization_loss(\n",
    "            model_outputs[\"chaos_state\"], \n",
    "            model_outputs[\"reference_attractor\"]\n",
    "        ) * warmup_factor * self.config.SYNC_WEIGHT\n",
    "        \n",
    "        # 李雅普诺夫稳定性损失\n",
    "        lyap_loss = self.lyapunov_stability_loss(model_outputs[\"embedding\"]) * warmup_factor * self.config.LYAPUNOV_WEIGHT\n",
    "        \n",
    "        # 总损失\n",
    "        total_loss = ce * self.config.CE_WEIGHT + sync_loss + lyap_loss\n",
    "        \n",
    "        return {\n",
    "            \"total_loss\": total_loss,\n",
    "            \"ce_loss\": ce,\n",
    "            \"sync_loss\": sync_loss,\n",
    "            \"lyap_loss\": lyap_loss\n",
    "        }\n",
    "\n",
    "\n",
    "# T5模型训练器\n",
    "class T5Trainer:\n",
    "    def __init__(self, config=Config, model=None):\n",
    "        \"\"\"初始化T5模型训练器\"\"\"\n",
    "        self.config = config\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        print(f\"使用设备: {self.device}\")\n",
    "\n",
    "        # 模型初始化\n",
    "        if model is None:\n",
    "            raise ValueError(\"初始化T5Trainer时必须传入model参数\")\n",
    "        self.model = model.to(self.device)\n",
    "\n",
    "        # 损失函数和优化器\n",
    "        self.criterion = ComplexLoss(config)\n",
    "        self.optimizer = optim.Adam(\n",
    "            self.model.parameters(),\n",
    "            lr=config.LR,\n",
    "            weight_decay=config.WEIGHT_DECAY\n",
    "        )\n",
    "\n",
    "        # 学习率调度器\n",
    "        self.scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            self.optimizer,\n",
    "            mode='min',\n",
    "            factor=0.5,\n",
    "            patience=3,\n",
    "        )\n",
    "\n",
    "        # 学习率预热调度器\n",
    "        self.warmup_scheduler = optim.lr_scheduler.LambdaLR(\n",
    "            self.optimizer,\n",
    "            lr_lambda=lambda epoch: min(1.0, epoch / config.WARMUP_EPOCHS)\n",
    "        )\n",
    "\n",
    "        # 混合精度训练\n",
    "        if config.ENABLE_MIXED_PRECISION and torch.cuda.is_available():\n",
    "            self.scaler = torch.cuda.amp.GradScaler()\n",
    "            print(\"启用混合精度训练\")\n",
    "        else:\n",
    "            self.scaler = None\n",
    "\n",
    "        # 检查点目录\n",
    "        os.makedirs(config.CHECKPOINT_DIR, exist_ok=True)\n",
    "\n",
    "        # 早停机制\n",
    "        self.early_stop_counter = 0\n",
    "        self.best_val_accuracy = 0.0\n",
    "        self.best_val_loss = float('inf')\n",
    "\n",
    "    def train_one_epoch(self, dataloader, epoch):\n",
    "        \"\"\"训练一个epoch\"\"\"\n",
    "        self.model.train()\n",
    "        self.criterion.train()\n",
    "        \n",
    "        total_metrics = {\n",
    "            \"total_loss\": 0.0,\n",
    "            \"ce_loss\": 0.0,\n",
    "            \"sync_loss\": 0.0,\n",
    "            \"lyap_loss\": 0.0,\n",
    "            \"correct\": 0,\n",
    "            \"total\": 0\n",
    "        }\n",
    "\n",
    "        # 梯度累积设置\n",
    "        accumulation_steps = self.config.GRADIENT_ACCUMULATION_STEPS\n",
    "        self.optimizer.zero_grad()\n",
    "\n",
    "        progress_bar = tqdm(enumerate(dataloader), total=len(dataloader))\n",
    "        for i, (inputs, labels) in progress_bar:\n",
    "            try:\n",
    "                inputs, labels = inputs.to(self.device), labels.to(self.device)\n",
    "\n",
    "                # 确保输入维度正确 [batch, 1, seq_len]\n",
    "                if inputs.dim() == 2:\n",
    "                    inputs = inputs.unsqueeze(1)\n",
    "\n",
    "                # 混合精度训练\n",
    "                if self.scaler is not None:\n",
    "                    with torch.cuda.amp.autocast():\n",
    "                        # 模型前向传播\n",
    "                        outputs = self.model(inputs)\n",
    "                        # 计算损失\n",
    "                        losses = self.criterion(outputs, labels, epoch)\n",
    "                        loss = losses[\"total_loss\"] / accumulation_steps\n",
    "\n",
    "                    # 反向传播\n",
    "                    self.scaler.scale(loss).backward()\n",
    "\n",
    "                    # 梯度裁剪\n",
    "                    self.scaler.unscale_(self.optimizer)\n",
    "                    torch.nn.utils.clip_grad_norm_(\n",
    "                        self.model.parameters(), \n",
    "                        self.config.GRAD_CLIP\n",
    "                    )\n",
    "\n",
    "                    # 梯度累积更新\n",
    "                    if (i + 1) % accumulation_steps == 0:\n",
    "                        self.scaler.step(self.optimizer)\n",
    "                        self.scaler.update()\n",
    "                        if epoch <= self.config.WARMUP_EPOCHS:\n",
    "                            self.warmup_scheduler.step()\n",
    "                        self.optimizer.zero_grad()\n",
    "\n",
    "                else:\n",
    "                    # 标准训练流程\n",
    "                    outputs = self.model(inputs)\n",
    "                    losses = self.criterion(outputs, labels, epoch)\n",
    "                    loss = losses[\"total_loss\"] / accumulation_steps\n",
    "                    loss.backward()\n",
    "\n",
    "                    # 梯度裁剪\n",
    "                    torch.nn.utils.clip_grad_norm_(\n",
    "                        self.model.parameters(), \n",
    "                        self.config.GRAD_CLIP\n",
    "                    )\n",
    "\n",
    "                    # 梯度累积更新\n",
    "                    if (i + 1) % accumulation_steps == 0:\n",
    "                        self.optimizer.step()\n",
    "                        if epoch <= self.config.WARMUP_EPOCHS:\n",
    "                            self.warmup_scheduler.step()\n",
    "                        self.optimizer.zero_grad()\n",
    "\n",
    "                # 统计指标\n",
    "                for key in losses:\n",
    "                    total_metrics[key] += losses[key].item() * accumulation_steps\n",
    "                \n",
    "                # 计算准确率\n",
    "                _, predicted = outputs[\"logits\"].max(1)\n",
    "                total_metrics[\"total\"] += labels.size(0)\n",
    "                total_metrics[\"correct\"] += predicted.eq(labels).sum().item()\n",
    "\n",
    "                # 更新进度条\n",
    "                if i % 10 == 0:\n",
    "                    avg_loss = total_metrics[\"total_loss\"] / (i + 1)\n",
    "                    accuracy = 100. * total_metrics[\"correct\"] / total_metrics[\"total\"]\n",
    "                    progress_bar.set_description(\n",
    "                        f\"Epoch {epoch}, Loss: {avg_loss:.4f}, Acc: {accuracy:.2f}%\"\n",
    "                    )\n",
    "\n",
    "                # 内存管理\n",
    "                if i % 50 == 0:\n",
    "                    torch.cuda.empty_cache()\n",
    "                    gc.collect()\n",
    "\n",
    "            except RuntimeError as e:\n",
    "                if \"out of memory\" in str(e):\n",
    "                    print(f\"内存不足错误在批次 {i}: {e}\")\n",
    "                    torch.cuda.empty_cache()\n",
    "                    gc.collect()\n",
    "                    continue\n",
    "                else:\n",
    "                    raise e\n",
    "\n",
    "        # 计算平均指标\n",
    "        avg_metrics = {\n",
    "            key: val / len(dataloader) for key, val in total_metrics.items() if key != \"correct\" and key != \"total\"\n",
    "        }\n",
    "        avg_metrics[\"accuracy\"] = 100. * total_metrics[\"correct\"] / total_metrics[\"total\"]\n",
    "        return avg_metrics\n",
    "\n",
    "    def validate(self, dataloader):\n",
    "        \"\"\"验证模型性能\"\"\"\n",
    "        self.model.eval()\n",
    "        self.criterion.eval()\n",
    "        \n",
    "        total_metrics = {\n",
    "            \"total_loss\": 0.0,\n",
    "            \"ce_loss\": 0.0,\n",
    "            \"sync_loss\": 0.0,\n",
    "            \"lyap_loss\": 0.0,\n",
    "            \"correct\": 0,\n",
    "            \"total\": 0\n",
    "        }\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for i, (inputs, labels) in enumerate(dataloader):\n",
    "                try:\n",
    "                    inputs, labels = inputs.to(self.device), labels.to(self.device)\n",
    "\n",
    "                    # 确保输入维度正确\n",
    "                    if inputs.dim() == 2:\n",
    "                        inputs = inputs.unsqueeze(1)\n",
    "\n",
    "                    # 模型前向传播\n",
    "                    outputs = self.model(inputs)\n",
    "                    losses = self.criterion(outputs, labels, epoch=1)  # 验证时使用最大权重\n",
    "\n",
    "                    # 统计损失\n",
    "                    for key in losses:\n",
    "                        total_metrics[key] += losses[key].item()\n",
    "\n",
    "                    # 统计准确率\n",
    "                    _, predicted = outputs[\"logits\"].max(1)\n",
    "                    total_metrics[\"total\"] += labels.size(0)\n",
    "                    total_metrics[\"correct\"] += predicted.eq(labels).sum().item()\n",
    "\n",
    "                    # 内存管理\n",
    "                    if i % 20 == 0:\n",
    "                        torch.cuda.empty_cache()\n",
    "                        gc.collect()\n",
    "\n",
    "                except RuntimeError as e:\n",
    "                    if \"out of memory\" in str(e):\n",
    "                        print(f\"验证时内存不足: {e}\")\n",
    "                        torch.cuda.empty_cache()\n",
    "                        gc.collect()\n",
    "                        continue\n",
    "                    else:\n",
    "                        raise e\n",
    "\n",
    "        # 计算平均指标\n",
    "        avg_metrics = {\n",
    "            key: val / len(dataloader) for key, val in total_metrics.items() if key != \"correct\" and key != \"total\"\n",
    "        }\n",
    "        avg_metrics[\"accuracy\"] = 100. * total_metrics[\"correct\"] / total_metrics[\"total\"]\n",
    "        return avg_metrics\n",
    "\n",
    "    def train(self, train_dataloader, val_dataloader):\n",
    "        \"\"\"完整训练流程\"\"\"\n",
    "        print(\"开始T5模型训练...\")\n",
    "        print(f\"训练集批次: {len(train_dataloader)}, 验证集批次: {len(val_dataloader)}\")\n",
    "\n",
    "        for epoch in range(1, self.config.EPOCHS + 1):\n",
    "            try:\n",
    "                # 训练一个epoch\n",
    "                train_metrics = self.train_one_epoch(train_dataloader, epoch)\n",
    "                print(f\"Epoch {epoch}/{self.config.EPOCHS}\")\n",
    "                print(f\"训练: 总损失={train_metrics['total_loss']:.4f}, \"\n",
    "                      f\"交叉熵={train_metrics['ce_loss']:.4f}, \"\n",
    "                      f\"同步损失={train_metrics['sync_loss']:.4f}, \"\n",
    "                      f\"李雅普诺夫损失={train_metrics['lyap_loss']:.4f}, \"\n",
    "                      f\"准确率={train_metrics['accuracy']:.2f}%\")\n",
    "\n",
    "                # 验证\n",
    "                val_metrics = self.validate(val_dataloader)\n",
    "                print(f\"验证: 总损失={val_metrics['total_loss']:.4f}, \"\n",
    "                      f\"准确率={val_metrics['accuracy']:.2f}%\")\n",
    "\n",
    "                # 更新学习率\n",
    "                self.scheduler.step(val_metrics[\"total_loss\"])\n",
    "                current_lr = self.optimizer.param_groups[0]['lr']\n",
    "                print(f\"当前学习率: {current_lr:.6f}\")\n",
    "\n",
    "                # 早停检查 (基于验证准确率)\n",
    "                if val_metrics[\"accuracy\"] > self.best_val_accuracy + self.config.MIN_DELTA:\n",
    "                    self.best_val_accuracy = val_metrics[\"accuracy\"]\n",
    "                    self.best_val_loss = val_metrics[\"total_loss\"]\n",
    "                    self.early_stop_counter = 0\n",
    "                    # 保存最佳模型\n",
    "                    torch.save({\n",
    "                        'epoch': epoch,\n",
    "                        'model_state_dict': self.model.state_dict(),\n",
    "                        'optimizer_state_dict': self.optimizer.state_dict(),\n",
    "                        'val_loss': val_metrics[\"total_loss\"],\n",
    "                        'val_accuracy': val_metrics[\"accuracy\"]\n",
    "                    }, os.path.join(self.config.CHECKPOINT_DIR, 'best_t5_model.pth'))\n",
    "                    print(f\"保存最佳模型，验证准确率: {val_metrics['accuracy']:.2f}%\")\n",
    "                else:\n",
    "                    self.early_stop_counter += 1\n",
    "                    if self.early_stop_counter >= self.config.PATIENCE:\n",
    "                        print(f\"早停于第 {epoch} 轮\")\n",
    "                        break\n",
    "\n",
    "                # 定期保存模型\n",
    "                if epoch % self.config.SAVE_INTERVAL == 0:\n",
    "                    torch.save({\n",
    "                        'epoch': epoch,\n",
    "                        'model_state_dict': self.model.state_dict(),\n",
    "                        'optimizer_state_dict': self.optimizer.state_dict(),\n",
    "                        'train_loss': train_metrics[\"total_loss\"],\n",
    "                        'train_accuracy': train_metrics[\"accuracy\"]\n",
    "                    }, os.path.join(self.config.CHECKPOINT_DIR, f't5_model_epoch_{epoch}.pth'))\n",
    "\n",
    "                # 清理内存\n",
    "                torch.cuda.empty_cache()\n",
    "                gc.collect()\n",
    "\n",
    "            except KeyboardInterrupt:\n",
    "                print(\"训练被用户中断\")\n",
    "                break\n",
    "            except Exception as e:\n",
    "                print(f\"训练错误: {e}\")\n",
    "                torch.cuda.empty_cache()\n",
    "                gc.collect()\n",
    "                continue\n",
    "\n",
    "        print(f\"训练完成，最佳验证准确率: {self.best_val_accuracy:.2f}%\")\n",
    "\n",
    "    def load_checkpoint(self, checkpoint_path):\n",
    "        \"\"\"加载检查点\"\"\"\n",
    "        checkpoint = torch.load(checkpoint_path, map_location=self.device)\n",
    "        self.model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        if 'optimizer_state_dict' in checkpoint:\n",
    "            self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        epoch = checkpoint.get('epoch', 0)\n",
    "        self.best_val_accuracy = checkpoint.get('val_accuracy', self.best_val_accuracy)\n",
    "        print(f\"从第 {epoch} 轮加载检查点，最佳验证准确率: {self.best_val_accuracy:.2f}%\")\n",
    "        return epoch\n",
    "\n",
    "\n",
    "# 评估器类\n",
    "class T5Evaluator:\n",
    "    def __init__(self, model, config=Config):\n",
    "        \"\"\"初始化T5模型评估器\"\"\"\n",
    "        self.model = model\n",
    "        self.config = config\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.model.to(self.device)\n",
    "        self.model.eval()\n",
    "        self.criterion = ComplexLoss(config)\n",
    "\n",
    "    def evaluate(self, dataloader):\n",
    "        \"\"\"完整评估，返回所有指标\"\"\"\n",
    "        metrics = {\n",
    "            \"total_loss\": 0.0,\n",
    "            \"ce_loss\": 0.0,\n",
    "            \"sync_loss\": 0.0,\n",
    "            \"lyap_loss\": 0.0,\n",
    "            \"accuracy\": 0.0,\n",
    "            \"correct\": 0,\n",
    "            \"total\": 0\n",
    "        }\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in tqdm(dataloader, desc=\"评估中\"):\n",
    "                inputs, labels = inputs.to(self.device), labels.to(self.device)\n",
    "                \n",
    "                if inputs.dim() == 2:\n",
    "                    inputs = inputs.unsqueeze(1)\n",
    "\n",
    "                outputs = self.model(inputs)\n",
    "                losses = self.criterion(outputs, labels, epoch=1)\n",
    "                \n",
    "                # 累计损失\n",
    "                for key in losses:\n",
    "                    metrics[key] += losses[key].item()\n",
    "                \n",
    "                # 累计准确率\n",
    "                _, predicted = outputs[\"logits\"].max(1)\n",
    "                metrics[\"total\"] += labels.size(0)\n",
    "                metrics[\"correct\"] += predicted.eq(labels).sum().item()\n",
    "\n",
    "        # 计算平均指标\n",
    "        metrics[\"accuracy\"] = 100. * metrics[\"correct\"] / metrics[\"total\"]\n",
    "        metrics[\"total_loss\"] /= len(dataloader)\n",
    "        metrics[\"ce_loss\"] /= len(dataloader)\n",
    "        metrics[\"sync_loss\"] /= len(dataloader)\n",
    "        metrics[\"lyap_loss\"] /= len(dataloader)\n",
    "        \n",
    "        return metrics\n",
    "\n",
    "\n",
    "# 测试训练器\n",
    "if __name__ == \"__main__\":\n",
    "    # 加载配置\n",
    "    config = Config()\n",
    "    \n",
    "    # 创建数据加载器\n",
    "    print(\"创建T5数据加载器...\")\n",
    "    dataloaders = get_t5_dataloaders()\n",
    "    \n",
    "    # 获取类别数\n",
    "    num_classes = len(dataloaders[\"train\"].dataset.speaker_to_idx)\n",
    "    print(f\"说话人数量（类别数）: {num_classes}\")\n",
    "    \n",
    "    # 创建模型\n",
    "    print(\"初始化T5 C-HiLAP模型...\")\n",
    "    model = T5CHiLAPModel(num_classes=num_classes)\n",
    "    \n",
    "    # 创建训练器\n",
    "    print(\"初始化训练器...\")\n",
    "    trainer = T5Trainer(config=config, model=model)\n",
    "    \n",
    "    # 测试前向传播\n",
    "    print(\"测试前向传播...\")\n",
    "    try:\n",
    "        x, y = next(iter(dataloaders[\"train\"]))\n",
    "        x = x.to(trainer.device)\n",
    "        y = y.to(trainer.device)\n",
    "        \n",
    "        if x.dim() == 2:\n",
    "            x = x.unsqueeze(1)\n",
    "            \n",
    "        outputs = model(x)\n",
    "        print(f\"嵌入向量形状: {outputs['embedding'].shape}\")\n",
    "        print(f\"分类输出形状: {outputs['logits'].shape}\")\n",
    "        \n",
    "        # 测试损失计算\n",
    "        losses = trainer.criterion(outputs, y, epoch=1)\n",
    "        print(f\"损失值: {losses['total_loss'].item():.4f}\")\n",
    "        print(\"前向传播测试成功!\")\n",
    "    except Exception as e:\n",
    "        print(f\"前向传播测试失败: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        exit(1)\n",
    "    \n",
    "    # 开始训练\n",
    "    print(\"启动训练...\")\n",
    "    trainer.train(dataloaders[\"train\"], dataloaders[\"val\"])\n",
    "    \n",
    "    # 评估模型\n",
    "    print(\"评估模型性能...\")\n",
    "    evaluator = T5Evaluator(trainer.model, config)\n",
    "    test_metrics = evaluator.evaluate(dataloaders[\"test\"])\n",
    "    print(\"\\n测试集性能:\")\n",
    "    print(f\"总损失: {test_metrics['total_loss']:.4f}\")\n",
    "    print(f\"交叉熵损失: {test_metrics['ce_loss']:.4f}\")\n",
    "    print(f\"相位同步损失: {test_metrics['sync_loss']:.4f}\")\n",
    "    print(f\"李雅普诺夫损失: {test_metrics['lyap_loss']:.4f}\")\n",
    "    print(f\"准确率: {test_metrics['accuracy']:.2f}%\")\n",
    "    \n",
    "    # 带噪声测试集评估\n",
    "    noisy_test_metrics = evaluator.evaluate(dataloaders[\"noisy_test\"])\n",
    "    print(\"\\n带噪声测试集性能:\")\n",
    "    print(f\"准确率: {noisy_test_metrics['accuracy']:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
