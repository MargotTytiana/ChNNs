{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ae62be-6655-46fe-aced-619aca3a3a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from typing import Dict, Any, Tuple, Optional, List\n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from pathlib import Path\n",
    "from typing import Dict, Any, Tuple, Optional\n",
    "\n",
    "# =============================================================================\n",
    "# 统一导入设置 (复制到每个文件)\n",
    "# =============================================================================\n",
    "def setup_module_imports(current_file: str = __file__):\n",
    "    \"\"\"Setup imports for current module.\"\"\"\n",
    "    try:\n",
    "        from setup_imports import setup_project_imports\n",
    "        return setup_project_imports(current_file), True\n",
    "    except ImportError:\n",
    "        # Fallback: manual path setup\n",
    "        current_dir = Path(current_file).resolve().parent  # experiments目录\n",
    "        project_root = current_dir.parent  # experiments -> Model\n",
    "        \n",
    "        paths_to_add = [\n",
    "            str(project_root),\n",
    "            str(project_root / 'core'),\n",
    "            str(project_root / 'models'), \n",
    "            str(project_root / 'features'),\n",
    "            str(project_root / 'data'),\n",
    "            str(project_root / 'utils'),\n",
    "            str(project_root / 'evaluation'),\n",
    "        ]\n",
    "        \n",
    "        for path in paths_to_add:\n",
    "            if Path(path).exists() and path not in sys.path:\n",
    "                sys.path.insert(0, path)\n",
    "        \n",
    "        return project_root, False\n",
    "\n",
    "# Setup imports\n",
    "PROJECT_ROOT, USING_IMPORT_MANAGER = setup_module_imports()\n",
    "\n",
    "# =============================================================================  \n",
    "# 项目模块导入 (现在路径已经正确设置)\n",
    "# =============================================================================\n",
    "from experiments.base_experiment import BaseExperiment\n",
    "from models.hybrid_models import TraditionalMLPBaseline, HybridModelManager  \n",
    "from models.mlp_classifier import MLPClassifier\n",
    "from features.traditional_features import MelExtractor, MFCCExtractor\n",
    "from data.dataset_loader import create_speaker_dataloaders, LibriSpeechChaoticDataset\n",
    "\n",
    "\n",
    "class ChaoticExperiment(BaseExperiment):\n",
    "    \"\"\"\n",
    "    Chaotic Network Experiment for robust speaker recognition using chaos theory.\n",
    "    \n",
    "    This experiment implements the complete chaotic neural network pipeline:\n",
    "    1. Phase space reconstruction\n",
    "    2. Chaotic feature extraction (MLSA + RQA)\n",
    "    3. Chaotic embedding layer\n",
    "    4. Strange attractor pooling\n",
    "    5. Speaker embedding and classification\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        config: Dict[str, Any],\n",
    "        experiment_name: str = 'chaotic_experiment',\n",
    "        output_dir: str = './experiments/outputs',\n",
    "        device: str = 'auto',\n",
    "        seed: int = 42\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initialize Chaotic Network Experiment.\n",
    "        \n",
    "        Args:\n",
    "            config: Experiment configuration\n",
    "            experiment_name: Name of the experiment  \n",
    "            output_dir: Output directory for results\n",
    "            device: Device to use ('auto', 'cpu', 'cuda')\n",
    "            seed: Random seed\n",
    "        \"\"\"\n",
    "        super().__init__(config, experiment_name, output_dir, device, seed)\n",
    "        \n",
    "        # Validate chaotic-specific config\n",
    "        self._validate_config()\n",
    "        \n",
    "        # Initialize chaotic components\n",
    "        self.feature_visualizer = None\n",
    "        self.chaotic_analyzer = None\n",
    "        \n",
    "        # Experiment tracking\n",
    "        self.chaotic_metrics = {\n",
    "            'attractor_dimensions': [],\n",
    "            'lyapunov_exponents': [],\n",
    "            'embedding_quality': []\n",
    "        }\n",
    "        \n",
    "        self.logger.info(f\"Initialized chaotic network experiment with {config['chaotic_system']} system\")\n",
    "    \n",
    "    def _validate_config(self):\n",
    "        \"\"\"Validate chaotic experiment configuration.\"\"\"\n",
    "        required_keys = ['num_speakers', 'batch_size', 'chaotic_system']\n",
    "        \n",
    "        for key in required_keys:\n",
    "            if key not in self.config:\n",
    "                raise ValueError(f\"Missing required config key: {key}\")\n",
    "        \n",
    "        # Validate chaotic system type\n",
    "        valid_systems = ['lorenz', 'rossler', 'mackey_glass', 'chua']\n",
    "        if self.config['chaotic_system'] not in valid_systems:\n",
    "            raise ValueError(f\"Invalid chaotic_system. Must be one of: {valid_systems}\")\n",
    "        \n",
    "        # Set default values for chaotic network\n",
    "        self.config.setdefault('learning_rate', 0.0005)  # Lower LR for chaotic systems\n",
    "        self.config.setdefault('weight_decay', 1e-5)\n",
    "        \n",
    "        # Phase space reconstruction defaults\n",
    "        self.config.setdefault('embedding_dim', 10)\n",
    "        self.config.setdefault('delay_method', 'autocorr')\n",
    "        \n",
    "        # Chaotic feature extraction defaults  \n",
    "        self.config.setdefault('mlsa_scales', 5)\n",
    "        self.config.setdefault('rqa_radius_ratio', 0.1)\n",
    "        \n",
    "        # Chaotic embedding defaults\n",
    "        self.config.setdefault('evolution_time', 0.5)\n",
    "        self.config.setdefault('time_step', 0.01)\n",
    "        self.config.setdefault('coupling_strength', 1.0)\n",
    "        self.config.setdefault('noise_level', 0.001)\n",
    "        \n",
    "        # Attractor pooling defaults\n",
    "        self.config.setdefault('pooling_type', 'comprehensive')\n",
    "        self.config.setdefault('correlation_radii', None)\n",
    "        \n",
    "        # Speaker embedding defaults\n",
    "        self.config.setdefault('speaker_embedding_dim', 128)\n",
    "        self.config.setdefault('embedding_hidden_dims', [64, 32])\n",
    "        \n",
    "        # Classification defaults\n",
    "        self.config.setdefault('classifier_type', 'cosine')\n",
    "        self.config.setdefault('temperature', 30.0)\n",
    "        self.config.setdefault('margin', 0.35)\n",
    "        \n",
    "        # Audio processing defaults\n",
    "        self.config.setdefault('sample_rate', 16000)\n",
    "        self.config.setdefault('frame_length', 400)\n",
    "        self.config.setdefault('hop_length', 160)\n",
    "        self.config.setdefault('max_audio_length', 3.0)\n",
    "        \n",
    "        # Training specific defaults\n",
    "        self.config.setdefault('gradient_clipping', 1.0)  # Important for chaotic systems\n",
    "        self.config.setdefault('adaptive_embedding', False)\n",
    "    \n",
    "    def create_model(self) -> nn.Module:\n",
    "        \"\"\"Create chaotic network model based on configuration.\"\"\"\n",
    "        model_type = self.config.get('model_type', 'full_chaotic')\n",
    "        \n",
    "        if model_type == 'full_chaotic':\n",
    "            # Complete chaotic network\n",
    "            if ChaoticSpeakerRecognitionNetwork is not None:\n",
    "                model = ChaoticSpeakerRecognitionNetwork(\n",
    "                    # Audio processing parameters\n",
    "                    sample_rate=self.config['sample_rate'],\n",
    "                    frame_length=self.config['frame_length'],\n",
    "                    hop_length=self.config['hop_length'],\n",
    "                    \n",
    "                    # Phase space reconstruction  \n",
    "                    embedding_dim=self.config['embedding_dim'],\n",
    "                    delay_method=self.config['delay_method'],\n",
    "                    \n",
    "                    # Chaotic features\n",
    "                    mlsa_scales=self.config['mlsa_scales'],\n",
    "                    rqa_radius_ratio=self.config['rqa_radius_ratio'],\n",
    "                    \n",
    "                    # Chaotic embedding\n",
    "                    chaotic_system=self.config['chaotic_system'],\n",
    "                    evolution_time=self.config['evolution_time'],\n",
    "                    time_step=self.config['time_step'],\n",
    "                    \n",
    "                    # Attractor pooling\n",
    "                    pooling_type=self.config['pooling_type'],\n",
    "                    \n",
    "                    # Speaker embedding\n",
    "                    speaker_embedding_dim=self.config['speaker_embedding_dim'],\n",
    "                    \n",
    "                    # Classification\n",
    "                    num_speakers=self.config['num_speakers'],\n",
    "                    classifier_type=self.config['classifier_type'],\n",
    "                    \n",
    "                    device=self.device\n",
    "                )\n",
    "            else:\n",
    "                # Mock implementation\n",
    "                model = MockChaoticNetwork(self.config)\n",
    "        \n",
    "        elif model_type == 'traditional_chaotic':\n",
    "            # Traditional features + chaotic processing\n",
    "            if TraditionalChaoticHybrid is not None:\n",
    "                model = TraditionalChaoticHybrid(\n",
    "                    feature_type=self.config.get('feature_type', 'mel'),\n",
    "                    n_mels=self.config.get('n_mels', 80),\n",
    "                    n_mfcc=self.config.get('n_mfcc', 13),\n",
    "                    sample_rate=self.config['sample_rate'],\n",
    "                    evolution_time=self.config['evolution_time'],\n",
    "                    pooling_type=self.config['pooling_type'],\n",
    "                    speaker_embedding_dim=self.config['speaker_embedding_dim'],\n",
    "                    num_speakers=self.config['num_speakers'],\n",
    "                    classifier_type=self.config['classifier_type'],\n",
    "                    device=self.device\n",
    "                )\n",
    "            else:\n",
    "                model = MockChaoticNetwork(self.config)\n",
    "        \n",
    "        elif model_type == 'chaotic_mlp':\n",
    "            # Chaotic features + MLP classifier\n",
    "            if ChaoticMLPHybrid is not None:\n",
    "                model = ChaoticMLPHybrid(\n",
    "                    sample_rate=self.config['sample_rate'],\n",
    "                    embedding_dim=self.config['embedding_dim'],\n",
    "                    mlsa_scales=self.config['mlsa_scales'],\n",
    "                    rqa_radius_ratio=self.config['rqa_radius_ratio'],\n",
    "                    hidden_dims=self.config.get('mlp_hidden_dims', [128, 64, 32]),\n",
    "                    dropout_rate=self.config.get('dropout_rate', 0.2),\n",
    "                    num_speakers=self.config['num_speakers'],\n",
    "                    device=self.device\n",
    "                )\n",
    "            else:\n",
    "                model = MockChaoticNetwork(self.config)\n",
    "        \n",
    "        else:\n",
    "            raise ValueError(f\"Unknown model type: {model_type}\")\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def create_dataloaders(self) -> Tuple[DataLoader, DataLoader, DataLoader]:\n",
    "        \"\"\"Create data loaders for chaotic network training.\"\"\"\n",
    "        if create_speaker_dataloaders is not None:\n",
    "            # Use real data loading with chaotic preprocessing\n",
    "            train_loader, val_loader, test_loader = create_speaker_dataloaders(\n",
    "                data_dir=self.config.get('data_dir', './data'),\n",
    "                batch_size=self.config['batch_size'],\n",
    "                sample_rate=self.config['sample_rate'],\n",
    "                max_length=self.config['max_audio_length'],\n",
    "                num_workers=self.config.get('num_workers', 4),\n",
    "                train_split=self.config.get('train_split', 0.7),\n",
    "                val_split=self.config.get('val_split', 0.15),\n",
    "                seed=self.seed,\n",
    "                # Chaotic-specific preprocessing\n",
    "                apply_chaotic_preprocessing=True,\n",
    "                embedding_dim=self.config['embedding_dim']\n",
    "            )\n",
    "        else:\n",
    "            # Create mock data loaders\n",
    "            self.logger.warning(\"Using mock data loaders for testing\")\n",
    "            \n",
    "            train_dataset = MockDataset(1000, self.config['num_speakers'])\n",
    "            val_dataset = MockDataset(200, self.config['num_speakers'])\n",
    "            test_dataset = MockDataset(200, self.config['num_speakers'])\n",
    "            \n",
    "            train_loader = DataLoader(\n",
    "                train_dataset,\n",
    "                batch_size=self.config['batch_size'],\n",
    "                shuffle=True,\n",
    "                num_workers=0\n",
    "            )\n",
    "            val_loader = DataLoader(\n",
    "                val_dataset,\n",
    "                batch_size=self.config['batch_size'],\n",
    "                shuffle=False,\n",
    "                num_workers=0\n",
    "            )\n",
    "            test_loader = DataLoader(\n",
    "                test_dataset,\n",
    "                batch_size=self.config['batch_size'],\n",
    "                shuffle=False,\n",
    "                num_workers=0\n",
    "            )\n",
    "        \n",
    "        return train_loader, val_loader, test_loader\n",
    "    \n",
    "    def create_optimizer(self, model: nn.Module) -> optim.Optimizer:\n",
    "        \"\"\"Create optimizer optimized for chaotic networks.\"\"\"\n",
    "        optimizer_config = self.config.get('optimizer', {})\n",
    "        optimizer_type = optimizer_config.get('type', 'adamw').lower()  # AdamW better for chaotic systems\n",
    "        \n",
    "        if optimizer_type == 'adamw':\n",
    "            optimizer = optim.AdamW(\n",
    "                model.parameters(),\n",
    "                lr=self.config['learning_rate'],\n",
    "                weight_decay=self.config['weight_decay'],\n",
    "                betas=(0.9, 0.999),  # Standard betas\n",
    "                **optimizer_config.get('params', {})\n",
    "            )\n",
    "        elif optimizer_type == 'adam':\n",
    "            optimizer = optim.Adam(\n",
    "                model.parameters(),\n",
    "                lr=self.config['learning_rate'],\n",
    "                weight_decay=self.config['weight_decay'],\n",
    "                **optimizer_config.get('params', {})\n",
    "            )\n",
    "        elif optimizer_type == 'sgd':\n",
    "            optimizer = optim.SGD(\n",
    "                model.parameters(),\n",
    "                lr=self.config['learning_rate'],\n",
    "                weight_decay=self.config['weight_decay'],\n",
    "                momentum=optimizer_config.get('params', {}).get('momentum', 0.9),\n",
    "                nesterov=optimizer_config.get('params', {}).get('nesterov', True)\n",
    "            )\n",
    "        else:\n",
    "            self.logger.warning(f\"Unknown optimizer type: {optimizer_type}, using AdamW\")\n",
    "            optimizer = optim.AdamW(\n",
    "                model.parameters(),\n",
    "                lr=self.config['learning_rate'],\n",
    "                weight_decay=self.config['weight_decay']\n",
    "            )\n",
    "        \n",
    "        return optimizer\n",
    "    \n",
    "    def forward_pass(\n",
    "        self, \n",
    "        batch: Tuple[torch.Tensor, torch.Tensor], \n",
    "        training: bool = True\n",
    "    ) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Perform forward pass through chaotic network.\n",
    "        \n",
    "        Args:\n",
    "            batch: Tuple of (audio, speaker_labels)\n",
    "            training: Whether in training mode\n",
    "            \n",
    "        Returns:\n",
    "            Tuple of (loss, predictions, targets)\n",
    "        \"\"\"\n",
    "        audio, targets = batch\n",
    "        \n",
    "        # Forward pass through chaotic network\n",
    "        if hasattr(self.model, 'forward') and 'labels' in self.model.forward.__code__.co_varnames:\n",
    "            # Full chaotic network with labels support\n",
    "            logits = self.model(audio, labels=targets if training else None)\n",
    "        else:\n",
    "            # Standard forward pass\n",
    "            logits = self.model(audio)\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = self.criterion(logits, targets)\n",
    "        \n",
    "        # Get predictions\n",
    "        with torch.no_grad():\n",
    "            predictions = torch.argmax(logits, dim=1)\n",
    "        \n",
    "        return loss, predictions, targets\n",
    "    \n",
    "    def calculate_metrics(\n",
    "        self, \n",
    "        predictions: torch.Tensor, \n",
    "        targets: torch.Tensor, \n",
    "        loss: float\n",
    "    ) -> Dict[str, float]:\n",
    "        \"\"\"Calculate chaotic network specific metrics.\"\"\"\n",
    "        metrics = super().calculate_metrics(predictions, targets, loss)\n",
    "        \n",
    "        # Add chaotic-specific metrics\n",
    "        with torch.no_grad():\n",
    "            # Prediction confidence analysis\n",
    "            if hasattr(self.model, 'predict'):\n",
    "                # Get confidence scores\n",
    "                sample_audio = torch.randn(1, 8000).to(self.device)  # Sample for confidence analysis\n",
    "                try:\n",
    "                    _, confidence = self.model.predict(sample_audio)\n",
    "                    metrics['avg_confidence'] = confidence.mean().item()\n",
    "                except:\n",
    "                    pass  # Skip if predict method fails\n",
    "            \n",
    "            # Embedding quality metrics\n",
    "            if hasattr(self.model, 'extract_embeddings'):\n",
    "                try:\n",
    "                    sample_audio = torch.randn(min(16, predictions.shape[0]), 8000).to(self.device)\n",
    "                    embeddings = self.model.extract_embeddings(sample_audio)\n",
    "                    \n",
    "                    # Embedding diversity (average pairwise distance)\n",
    "                    if embeddings.shape[0] > 1:\n",
    "                        pairwise_distances = torch.cdist(embeddings, embeddings, p=2)\n",
    "                        # Exclude diagonal (distance to self)\n",
    "                        mask = ~torch.eye(embeddings.shape[0], dtype=bool, device=self.device)\n",
    "                        avg_distance = pairwise_distances[mask].mean().item()\n",
    "                        metrics['embedding_diversity'] = avg_distance\n",
    "                    \n",
    "                    # Embedding norm consistency\n",
    "                    embedding_norms = torch.norm(embeddings, dim=1)\n",
    "                    metrics['embedding_norm_mean'] = embedding_norms.mean().item()\n",
    "                    metrics['embedding_norm_std'] = embedding_norms.std().item()\n",
    "                    \n",
    "                except:\n",
    "                    pass  # Skip if extraction fails\n",
    "        \n",
    "        return metrics\n",
    "    \n",
    "    def train_epoch(self) -> Dict[str, float]:\n",
    "        \"\"\"Train epoch with chaotic network specific monitoring.\"\"\"\n",
    "        # Call parent train_epoch\n",
    "        epoch_metrics = super().train_epoch()\n",
    "        \n",
    "        # Add chaotic system monitoring\n",
    "        if hasattr(self.model, 'forward') and hasattr(self.model, 'chaotic_embedding'):\n",
    "            self._monitor_chaotic_dynamics()\n",
    "        \n",
    "        return epoch_metrics\n",
    "    \n",
    "    def _monitor_chaotic_dynamics(self):\n",
    "        \"\"\"Monitor chaotic dynamics during training.\"\"\"\n",
    "        try:\n",
    "            # Sample a batch for analysis\n",
    "            sample_batch = next(iter(self.val_loader))\n",
    "            sample_audio, _ = sample_batch\n",
    "            sample_audio = sample_audio[:4].to(self.device)  # Small batch for analysis\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                if hasattr(self.model, 'forward'):\n",
    "                    _, intermediates = self.model(sample_audio, return_intermediates=True)\n",
    "                    \n",
    "                    # Analyze chaotic trajectories\n",
    "                    if 'chaotic_trajectories' in intermediates:\n",
    "                        trajectories = intermediates['chaotic_trajectories']\n",
    "                        \n",
    "                        # Calculate basic trajectory statistics\n",
    "                        trajectory_std = torch.std(trajectories).item()\n",
    "                        trajectory_range = (torch.max(trajectories) - torch.min(trajectories)).item()\n",
    "                        \n",
    "                        self.chaotic_metrics['trajectory_std'] = trajectory_std\n",
    "                        self.chaotic_metrics['trajectory_range'] = trajectory_range\n",
    "                        \n",
    "                        # Log to tensorboard\n",
    "                        self.writer.add_scalar('Chaotic/trajectory_std', trajectory_std, self.state.epoch)\n",
    "                        self.writer.add_scalar('Chaotic/trajectory_range', trajectory_range, self.state.epoch)\n",
    "                    \n",
    "                    # Analyze pooled features\n",
    "                    if 'pooled_features' in intermediates:\n",
    "                        pooled = intermediates['pooled_features']\n",
    "                        feature_diversity = torch.std(pooled, dim=0).mean().item()\n",
    "                        \n",
    "                        self.writer.add_scalar('Chaotic/feature_diversity', feature_diversity, self.state.epoch)\n",
    "                        \n",
    "        except Exception as e:\n",
    "            self.logger.debug(f\"Chaotic monitoring failed: {e}\")\n",
    "    \n",
    "    def analyze_chaotic_features(self, num_samples: int = 100) -> Dict[str, Any]:\n",
    "        \"\"\"Comprehensive analysis of chaotic features and dynamics.\"\"\"\n",
    "        self.logger.info(\"Analyzing chaotic features and dynamics...\")\n",
    "        \n",
    "        analysis_results = {}\n",
    "        \n",
    "        # Collect samples for analysis\n",
    "        self.model.eval()\n",
    "        sample_data = []\n",
    "        sample_labels = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            samples_collected = 0\n",
    "            for batch in self.test_loader:\n",
    "                if samples_collected >= num_samples:\n",
    "                    break\n",
    "                    \n",
    "                audio, labels = batch\n",
    "                audio = audio.to(self.device)\n",
    "                \n",
    "                batch_size = min(audio.shape[0], num_samples - samples_collected)\n",
    "                audio = audio[:batch_size]\n",
    "                labels = labels[:batch_size]\n",
    "                \n",
    "                sample_data.append(audio)\n",
    "                sample_labels.extend(labels.tolist())\n",
    "                samples_collected += batch_size\n",
    "            \n",
    "            if sample_data:\n",
    "                sample_audio = torch.cat(sample_data, dim=0)\n",
    "                \n",
    "                # Extract intermediate representations\n",
    "                if hasattr(self.model, 'forward'):\n",
    "                    try:\n",
    "                        _, intermediates = self.model(sample_audio, return_intermediates=True)\n",
    "                        \n",
    "                        # Analyze each stage\n",
    "                        analysis_results['phase_space'] = self._analyze_phase_space(\n",
    "                            intermediates.get('phase_space')\n",
    "                        )\n",
    "                        analysis_results['chaotic_features'] = self._analyze_chaotic_features_dist(\n",
    "                            intermediates.get('chaotic_features')\n",
    "                        )\n",
    "                        analysis_results['trajectories'] = self._analyze_trajectories(\n",
    "                            intermediates.get('chaotic_trajectories')\n",
    "                        )\n",
    "                        analysis_results['pooled_features'] = self._analyze_pooled_features(\n",
    "                            intermediates.get('pooled_features')\n",
    "                        )\n",
    "                        analysis_results['embeddings'] = self._analyze_speaker_embeddings(\n",
    "                            intermediates.get('speaker_embeddings'),\n",
    "                            sample_labels\n",
    "                        )\n",
    "                        \n",
    "                    except Exception as e:\n",
    "                        self.logger.warning(f\"Feature analysis failed: {e}\")\n",
    "                        analysis_results['error'] = str(e)\n",
    "        \n",
    "        # Save analysis results\n",
    "        analysis_file = os.path.join(self.results_dir, 'chaotic_analysis.json')\n",
    "        with open(analysis_file, 'w') as f:\n",
    "            # Convert tensors to lists for JSON serialization\n",
    "            json_results = self._convert_tensors_for_json(analysis_results)\n",
    "            json.dump(json_results, f, indent=2)\n",
    "        \n",
    "        self.logger.info(\"Chaotic analysis completed\")\n",
    "        return analysis_results\n",
    "    \n",
    "    def _analyze_phase_space(self, phase_space_data: Optional[torch.Tensor]) -> Dict[str, Any]:\n",
    "        \"\"\"Analyze phase space reconstruction quality.\"\"\"\n",
    "        if phase_space_data is None:\n",
    "            return {'error': 'No phase space data available'}\n",
    "        \n",
    "        analysis = {}\n",
    "        \n",
    "        # Basic statistics\n",
    "        analysis['mean'] = phase_space_data.mean().item()\n",
    "        analysis['std'] = phase_space_data.std().item()\n",
    "        analysis['min'] = phase_space_data.min().item()\n",
    "        analysis['max'] = phase_space_data.max().item()\n",
    "        \n",
    "        # Dimensionality analysis\n",
    "        analysis['shape'] = list(phase_space_data.shape)\n",
    "        analysis['effective_dim'] = self._estimate_effective_dimension(phase_space_data)\n",
    "        \n",
    "        return analysis\n",
    "    \n",
    "    def _analyze_chaotic_features_dist(self, features: Optional[torch.Tensor]) -> Dict[str, Any]:\n",
    "        \"\"\"Analyze distribution of chaotic features.\"\"\"\n",
    "        if features is None:\n",
    "            return {'error': 'No chaotic features available'}\n",
    "        \n",
    "        analysis = {}\n",
    "        \n",
    "        # Feature statistics per dimension\n",
    "        analysis['per_dim_stats'] = []\n",
    "        for dim in range(features.shape[-1]):\n",
    "            dim_data = features[..., dim]\n",
    "            dim_stats = {\n",
    "                'mean': dim_data.mean().item(),\n",
    "                'std': dim_data.std().item(),\n",
    "                'min': dim_data.min().item(),\n",
    "                'max': dim_data.max().item()\n",
    "            }\n",
    "            analysis['per_dim_stats'].append(dim_stats)\n",
    "        \n",
    "        # Overall feature diversity\n",
    "        analysis['feature_diversity'] = torch.std(features, dim=0).mean().item()\n",
    "        analysis['feature_range'] = (features.max() - features.min()).item()\n",
    "        \n",
    "        return analysis\n",
    "    \n",
    "    def _analyze_trajectories(self, trajectories: Optional[torch.Tensor]) -> Dict[str, Any]:\n",
    "        \"\"\"Analyze chaotic trajectory properties.\"\"\"\n",
    "        if trajectories is None:\n",
    "            return {'error': 'No trajectory data available'}\n",
    "        \n",
    "        analysis = {}\n",
    "        \n",
    "        # Trajectory statistics\n",
    "        analysis['num_trajectories'] = trajectories.shape[0]\n",
    "        analysis['trajectory_length'] = trajectories.shape[1] if len(trajectories.shape) > 1 else 0\n",
    "        analysis['state_dimension'] = trajectories.shape[2] if len(trajectories.shape) > 2 else 0\n",
    "        \n",
    "        # Trajectory properties\n",
    "        trajectory_norms = torch.norm(trajectories, dim=-1)\n",
    "        analysis['avg_trajectory_norm'] = trajectory_norms.mean().item()\n",
    "        analysis['trajectory_norm_std'] = trajectory_norms.std().item()\n",
    "        \n",
    "        # Path length analysis\n",
    "        if len(trajectories.shape) == 3 and trajectories.shape[1] > 1:\n",
    "            diffs = torch.diff(trajectories, dim=1)\n",
    "            path_lengths = torch.norm(diffs, dim=-1).sum(dim=1)\n",
    "            analysis['avg_path_length'] = path_lengths.mean().item()\n",
    "            analysis['path_length_std'] = path_lengths.std().item()\n",
    "        \n",
    "        return analysis\n",
    "    \n",
    "    def _analyze_pooled_features(self, pooled_features: Optional[torch.Tensor]) -> Dict[str, Any]:\n",
    "        \"\"\"Analyze pooled attractor features.\"\"\"\n",
    "        if pooled_features is None:\n",
    "            return {'error': 'No pooled features available'}\n",
    "        \n",
    "        analysis = {}\n",
    "        \n",
    "        # Feature dimensionality\n",
    "        analysis['feature_dim'] = pooled_features.shape[-1] if len(pooled_features.shape) > 0 else 0\n",
    "        \n",
    "        # Feature statistics\n",
    "        analysis['mean'] = pooled_features.mean().item()\n",
    "        analysis['std'] = pooled_features.std().item()\n",
    "        \n",
    "        # Per-feature analysis\n",
    "        if len(pooled_features.shape) > 1:\n",
    "            per_feature_std = torch.std(pooled_features, dim=0)\n",
    "            analysis['per_feature_std'] = per_feature_std.tolist()\n",
    "            analysis['feature_diversity'] = per_feature_std.mean().item()\n",
    "        \n",
    "        return analysis\n",
    "    \n",
    "    def _analyze_speaker_embeddings(\n",
    "        self, \n",
    "        embeddings: Optional[torch.Tensor], \n",
    "        labels: List[int]\n",
    "    ) -> Dict[str, Any]:\n",
    "        \"\"\"Analyze speaker embedding quality.\"\"\"\n",
    "        if embeddings is None:\n",
    "            return {'error': 'No speaker embeddings available'}\n",
    "        \n",
    "        analysis = {}\n",
    "        \n",
    "        # Embedding properties\n",
    "        analysis['embedding_dim'] = embeddings.shape[-1] if len(embeddings.shape) > 0 else 0\n",
    "        analysis['num_embeddings'] = embeddings.shape[0] if len(embeddings.shape) > 0 else 0\n",
    "        \n",
    "        # Embedding norms (should be normalized)\n",
    "        embedding_norms = torch.norm(embeddings, dim=-1)\n",
    "        analysis['norm_mean'] = embedding_norms.mean().item()\n",
    "        analysis['norm_std'] = embedding_norms.std().item()\n",
    "        \n",
    "        # Inter-class and intra-class distances\n",
    "        if len(set(labels)) > 1 and len(embeddings.shape) > 1:\n",
    "            unique_labels = list(set(labels))\n",
    "            intra_class_distances = []\n",
    "            inter_class_distances = []\n",
    "            \n",
    "            for label in unique_labels:\n",
    "                label_indices = [i for i, l in enumerate(labels) if l == label]\n",
    "                if len(label_indices) > 1:\n",
    "                    label_embeddings = embeddings[label_indices]\n",
    "                    # Intra-class distances\n",
    "                    pairwise_dist = torch.cdist(label_embeddings, label_embeddings, p=2)\n",
    "                    mask = ~torch.eye(len(label_indices), dtype=bool)\n",
    "                    intra_class_distances.extend(pairwise_dist[mask].tolist())\n",
    "                \n",
    "                # Inter-class distances\n",
    "                other_indices = [i for i, l in enumerate(labels) if l != label]\n",
    "                if other_indices and label_indices:\n",
    "                    label_embeddings = embeddings[label_indices]\n",
    "                    other_embeddings = embeddings[other_indices]\n",
    "                    inter_dist = torch.cdist(label_embeddings, other_embeddings, p=2)\n",
    "                    inter_class_distances.extend(inter_dist.flatten().tolist())\n",
    "            \n",
    "            if intra_class_distances:\n",
    "                analysis['intra_class_distance'] = {\n",
    "                    'mean': np.mean(intra_class_distances),\n",
    "                    'std': np.std(intra_class_distances)\n",
    "                }\n",
    "            \n",
    "            if inter_class_distances:\n",
    "                analysis['inter_class_distance'] = {\n",
    "                    'mean': np.mean(inter_class_distances),\n",
    "                    'std': np.std(inter_class_distances)\n",
    "                }\n",
    "            \n",
    "            # Separation ratio\n",
    "            if intra_class_distances and inter_class_distances:\n",
    "                separation_ratio = np.mean(inter_class_distances) / np.mean(intra_class_distances)\n",
    "                analysis['separation_ratio'] = separation_ratio\n",
    "        \n",
    "        return analysis\n",
    "    \n",
    "    def _estimate_effective_dimension(self, data: torch.Tensor) -> float:\n",
    "        \"\"\"Estimate effective dimension of data using PCA.\"\"\"\n",
    "        try:\n",
    "            # Flatten data for PCA analysis\n",
    "            if len(data.shape) > 2:\n",
    "                data_flat = data.view(data.shape[0], -1)\n",
    "            else:\n",
    "                data_flat = data\n",
    "            \n",
    "            # Center the data\n",
    "            data_centered = data_flat - data_flat.mean(dim=0, keepdim=True)\n",
    "            \n",
    "            # Compute SVD\n",
    "            U, S, V = torch.svd(data_centered)\n",
    "            \n",
    "            # Compute explained variance ratio\n",
    "            explained_variance = S ** 2\n",
    "            total_variance = explained_variance.sum()\n",
    "            explained_ratio = explained_variance / total_variance\n",
    "            \n",
    "            # Find effective dimension (95% variance)\n",
    "            cumsum_ratio = torch.cumsum(explained_ratio, dim=0)\n",
    "            effective_dim = (cumsum_ratio < 0.95).sum().item() + 1\n",
    "            \n",
    "            return min(effective_dim, data_flat.shape[1])\n",
    "            \n",
    "        except Exception:\n",
    "            return data.shape[-1] if len(data.shape) > 0 else 0\n",
    "    \n",
    "    def _convert_tensors_for_json(self, obj: Any) -> Any:\n",
    "        \"\"\"Convert tensors to lists for JSON serialization.\"\"\"\n",
    "        if isinstance(obj, torch.Tensor):\n",
    "            return obj.tolist()\n",
    "        elif isinstance(obj, dict):\n",
    "            return {key: self._convert_tensors_for_json(value) for key, value in obj.items()}\n",
    "        elif isinstance(obj, list):\n",
    "            return [self._convert_tensors_for_json(item) for item in obj]\n",
    "        else:\n",
    "            return obj\n",
    "    \n",
    "    def visualize_chaotic_dynamics(self, save_plots: bool = True) -> Dict[str, str]:\n",
    "        \"\"\"Create visualizations of chaotic dynamics.\"\"\"\n",
    "        if not save_plots:\n",
    "            return {}\n",
    "        \n",
    "        self.logger.info(\"Creating chaotic dynamics visualizations...\")\n",
    "        \n",
    "        plot_paths = {}\n",
    "        plots_dir = os.path.join(self.results_dir, 'plots')\n",
    "        os.makedirs(plots_dir, exist_ok=True)\n",
    "        \n",
    "        try:\n",
    "            # Sample data for visualization\n",
    "            sample_batch = next(iter(self.test_loader))\n",
    "            sample_audio, sample_labels = sample_batch\n",
    "            sample_audio = sample_audio[:8].to(self.device)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                if hasattr(self.model, 'forward'):\n",
    "                    _, intermediates = self.model(sample_audio, return_intermediates=True)\n",
    "                    \n",
    "                    # Plot chaotic trajectories\n",
    "                    if 'chaotic_trajectories' in intermediates:\n",
    "                        trajectory_plot = self._plot_trajectories(\n",
    "                            intermediates['chaotic_trajectories'],\n",
    "                            os.path.join(plots_dir, 'chaotic_trajectories.png')\n",
    "                        )\n",
    "                        if trajectory_plot:\n",
    "                            plot_paths['trajectories'] = trajectory_plot\n",
    "                    \n",
    "                    # Plot feature distributions\n",
    "                    if 'pooled_features' in intermediates:\n",
    "                        feature_plot = self._plot_feature_distributions(\n",
    "                            intermediates['pooled_features'],\n",
    "                            os.path.join(plots_dir, 'feature_distributions.png')\n",
    "                        )\n",
    "                        if feature_plot:\n",
    "                            plot_paths['features'] = feature_plot\n",
    "                    \n",
    "                    # Plot embeddings\n",
    "                    if 'speaker_embeddings' in intermediates:\n",
    "                        embedding_plot = self._plot_embeddings(\n",
    "                            intermediates['speaker_embeddings'],\n",
    "                            sample_labels,\n",
    "                            os.path.join(plots_dir, 'speaker_embeddings.png')\n",
    "                        )\n",
    "                        if embedding_plot:\n",
    "                            plot_paths['embeddings'] = embedding_plot\n",
    "        \n",
    "        except Exception as e:\n",
    "            self.logger.warning(f\"Visualization failed: {e}\")\n",
    "        \n",
    "        return plot_paths\n",
    "    \n",
    "    def _plot_trajectories(self, trajectories: torch.Tensor, save_path: str) -> Optional[str]:\n",
    "        \"\"\"Plot chaotic trajectories in 3D.\"\"\"\n",
    "        try:\n",
    "            import matplotlib.pyplot as plt\n",
    "            from mpl_toolkits.mplot3d import Axes3D\n",
    "            \n",
    "            trajectories_cpu = trajectories.cpu().numpy()\n",
    "            \n",
    "            fig = plt.figure(figsize=(15, 5))\n",
    "            \n",
    "            # Plot first 3 trajectories\n",
    "            for i in range(min(3, trajectories_cpu.shape[0])):\n",
    "                ax = fig.add_subplot(1, 3, i+1, projection='3d')\n",
    "                traj = trajectories_cpu[i]\n",
    "                \n",
    "                ax.plot(traj[:, 0], traj[:, 1], traj[:, 2], linewidth=0.8)\n",
    "                ax.scatter(traj[0, 0], traj[0, 1], traj[0, 2], color='green', s=50, label='Start')\n",
    "                ax.scatter(traj[-1, 0], traj[-1, 1], traj[-1, 2], color='red', s=50, label='End')\n",
    "                \n",
    "                ax.set_title(f'Trajectory {i+1}')\n",
    "                ax.set_xlabel('X')\n",
    "                ax.set_ylabel('Y')\n",
    "                ax.set_zlabel('Z')\n",
    "                ax.legend()\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
    "            plt.close()\n",
    "            \n",
    "            return save_path\n",
    "            \n",
    "        except ImportError:\n",
    "            self.logger.warning(\"Matplotlib not available for plotting\")\n",
    "            return None\n",
    "        except Exception as e:\n",
    "            self.logger.warning(f\"Trajectory plotting failed: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def _plot_feature_distributions(self, features: torch.Tensor, save_path: str) -> Optional[str]:\n",
    "        \"\"\"Plot distribution of pooled features.\"\"\"\n",
    "        try:\n",
    "            import matplotlib.pyplot as plt\n",
    "            \n",
    "            features_cpu = features.cpu().numpy()\n",
    "            \n",
    "            fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "            axes = axes.flatten()\n",
    "            \n",
    "            for i in range(min(features_cpu.shape[1], len(axes))):\n",
    "                ax = axes[i]\n",
    "                ax.hist(features_cpu[:, i], bins=30, alpha=0.7, edgecolor='black')\n",
    "                ax.set_title(f'Feature {i+1}')\n",
    "                ax.set_xlabel('Value')\n",
    "                ax.set_ylabel('Count')\n",
    "                ax.grid(True, alpha=0.3)\n",
    "            \n",
    "            # Hide unused subplots\n",
    "            for i in range(features_cpu.shape[1], len(axes)):\n",
    "                axes[i].set_visible(False)\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
    "            plt.close()\n",
    "            \n",
    "            return save_path\n",
    "            \n",
    "        except ImportError:\n",
    "            return None\n",
    "        except Exception as e:\n",
    "            self.logger.warning(f\"Feature distribution plotting failed: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def _plot_embeddings(\n",
    "        self, \n",
    "        embeddings: torch.Tensor, \n",
    "        labels: torch.Tensor, \n",
    "        save_path: str\n",
    "    ) -> Optional[str]:\n",
    "        \"\"\"Plot speaker embeddings using t-SNE.\"\"\"\n",
    "        try:\n",
    "            import matplotlib.pyplot as plt\n",
    "            from sklearn.manifold import TSNE\n",
    "            \n",
    "            embeddings_cpu = embeddings.cpu().numpy()\n",
    "            labels_cpu = labels.cpu().numpy()\n",
    "            \n",
    "            # Use t-SNE for dimensionality reduction\n",
    "            tsne = TSNE(n_components=2, random_state=42, perplexity=min(30, len(embeddings_cpu)-1))\n",
    "            embeddings_2d = tsne.fit_transform(embeddings_cpu)\n",
    "            \n",
    "            # Create scatter plot\n",
    "            fig, ax = plt.subplots(figsize=(10, 8))\n",
    "            \n",
    "            unique_labels = np.unique(labels_cpu)\n",
    "            colors = plt.cm.tab10(np.linspace(0, 1, len(unique_labels)))\n",
    "            \n",
    "            for i, label in enumerate(unique_labels):\n",
    "                mask = labels_cpu == label\n",
    "                ax.scatter(\n",
    "                    embeddings_2d[mask, 0], \n",
    "                    embeddings_2d[mask, 1], \n",
    "                    c=[colors[i]], \n",
    "                    label=f'Speaker {label}',\n",
    "                    alpha=0.7,\n",
    "                    s=50\n",
    "                )\n",
    "            \n",
    "            ax.set_title('Speaker Embeddings (t-SNE)')\n",
    "            ax.set_xlabel('t-SNE Dimension 1')\n",
    "            ax.set_ylabel('t-SNE Dimension 2')\n",
    "            ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "            ax.grid(True, alpha=0.3)\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
    "            plt.close()\n",
    "            \n",
    "            return save_path\n",
    "            \n",
    "        except ImportError:\n",
    "            self.logger.warning(\"Scikit-learn not available for t-SNE plotting\")\n",
    "            return None\n",
    "        except Exception as e:\n",
    "            self.logger.warning(f\"Embedding plotting failed: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def run_chaotic_analysis(self) -> Dict[str, Any]:\n",
    "        \"\"\"Run complete chaotic network analysis.\"\"\"\n",
    "        self.logger.info(\"Running comprehensive chaotic network analysis...\")\n",
    "        \n",
    "        analysis_results = {}\n",
    "        \n",
    "        # Model complexity analysis\n",
    "        total_params = sum(p.numel() for p in self.model.parameters())\n",
    "        trainable_params = sum(p.numel() for p in self.model.parameters() if p.requires_grad)\n",
    "        \n",
    "        analysis_results['model_complexity'] = {\n",
    "            'total_parameters': total_params,\n",
    "            'trainable_parameters': trainable_params,\n",
    "            'model_size_mb': total_params * 4 / (1024 * 1024)\n",
    "        }\n",
    "        \n",
    "        # Chaotic system configuration\n",
    "        analysis_results['chaotic_config'] = {\n",
    "            'system_type': self.config['chaotic_system'],\n",
    "            'evolution_time': self.config['evolution_time'],\n",
    "            'time_step': self.config['time_step'],\n",
    "            'embedding_dim': self.config['embedding_dim'],\n",
    "            'pooling_type': self.config['pooling_type']\n",
    "        }\n",
    "        \n",
    "        # Feature analysis\n",
    "        feature_analysis = self.analyze_chaotic_features(num_samples=200)\n",
    "        analysis_results['feature_analysis'] = feature_analysis\n",
    "        \n",
    "        # Create visualizations\n",
    "        visualization_paths = self.visualize_chaotic_dynamics(save_plots=True)\n",
    "        analysis_results['visualizations'] = visualization_paths\n",
    "        \n",
    "        # Training dynamics\n",
    "        analysis_results['training_dynamics'] = {\n",
    "            'best_epoch': self.state.best_epoch,\n",
    "            'best_metric': self.state.best_metric,\n",
    "            'final_training_loss': self.state.train_losses[-1] if self.state.train_losses else None,\n",
    "            'chaotic_metrics': self.chaotic_metrics\n",
    "        }\n",
    "        \n",
    "        # Save comprehensive analysis\n",
    "        analysis_file = os.path.join(self.results_dir, 'comprehensive_chaotic_analysis.json')\n",
    "        with open(analysis_file, 'w') as f:\n",
    "            json_results = self._convert_tensors_for_json(analysis_results)\n",
    "            json.dump(json_results, f, indent=2)\n",
    "        \n",
    "        self.logger.info(\"Chaotic network analysis completed\")\n",
    "        return analysis_results\n",
    "\n",
    "\n",
    "def create_chaotic_experiments(base_config: Dict[str, Any]) -> Dict[str, ChaoticExperiment]:\n",
    "    \"\"\"\n",
    "    Create multiple chaotic experiments with different configurations.\n",
    "    \n",
    "    Args:\n",
    "        base_config: Base configuration for experiments\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary of chaotic experiments\n",
    "    \"\"\"\n",
    "    chaotic_systems = ['lorenz', 'rossler']\n",
    "    model_types = ['full_chaotic', 'traditional_chaotic']\n",
    "    \n",
    "    experiments = {}\n",
    "    \n",
    "    for system in chaotic_systems:\n",
    "        for model_type in model_types:\n",
    "            config = base_config.copy()\n",
    "            config['chaotic_system'] = system\n",
    "            config['model_type'] = model_type\n",
    "            \n",
    "            # Adjust parameters based on system\n",
    "            if system == 'lorenz':\n",
    "                config['evolution_time'] = 0.5\n",
    "                config['coupling_strength'] = 1.0\n",
    "            elif system == 'rossler':\n",
    "                config['evolution_time'] = 0.8\n",
    "                config['coupling_strength'] = 0.8\n",
    "            \n",
    "            experiment_name = f'chaotic_{system}_{model_type}'\n",
    "            experiment = ChaoticExperiment(\n",
    "                config=config,\n",
    "                experiment_name=experiment_name,\n",
    "                seed=config.get('seed', 42)\n",
    "            )\n",
    "            \n",
    "            experiments[f'{system}_{model_type}'] = experiment\n",
    "    \n",
    "    return experiments\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(f\"✓ Project Root: {PROJECT_ROOT}\")\n",
    "    print(f\"✓ Import Manager: {USING_IMPORT_MANAGER}\")\n",
    "    print(f\"✓ Module imports successful\")\n",
    "    # Example usage and testing\n",
    "    \n",
    "    # Test configuration\n",
    "    test_config = {\n",
    "        'chaotic_system': 'lorenz',\n",
    "        'model_type': 'full_chaotic',\n",
    "        'num_speakers': 10,\n",
    "        'batch_size': 8,\n",
    "        'learning_rate': 0.0005,\n",
    "        'embedding_dim': 8,\n",
    "        'mlsa_scales': 3,\n",
    "        'evolution_time': 0.2,\n",
    "        'pooling_type': 'comprehensive',\n",
    "        'speaker_embedding_dim': 64,\n",
    "        'classifier_type': 'cosine',\n",
    "        'sample_rate': 16000,\n",
    "        'primary_metric': 'accuracy',\n",
    "        'log_interval': 5\n",
    "    }\n",
    "    \n",
    "    print(\"Testing ChaoticExperiment...\")\n",
    "    \n",
    "    # Test single experiment\n",
    "    experiment = ChaoticExperiment(\n",
    "        config=test_config,\n",
    "        experiment_name='test_chaotic_lorenz'\n",
    "    )\n",
    "    \n",
    "    print(\"Setting up experiment...\")\n",
    "    experiment.setup()\n",
    "    \n",
    "    print(\"Running chaotic analysis...\")\n",
    "    analysis = experiment.run_chaotic_analysis()\n",
    "    print(f\"Model parameters: {analysis['model_complexity']['total_parameters']:,}\")\n",
    "    \n",
    "    print(\"Training for 2 epochs...\")\n",
    "    experiment.train(num_epochs=2)\n",
    "    \n",
    "    print(\"Chaotic experiment test completed!\")\n",
    "    \n",
    "    # Test multiple experiments creation\n",
    "    print(\"\\nTesting multiple chaotic experiments creation...\")\n",
    "    base_config = {\n",
    "        'num_speakers': 5,\n",
    "        'batch_size': 4,\n",
    "        'learning_rate': 0.0005,\n",
    "        'sample_rate': 16000\n",
    "    }\n",
    "    \n",
    "    chaotic_experiments = create_chaotic_experiments(base_config)\n",
    "    print(f\"Created {len(chaotic_experiments)} chaotic experiments:\")\n",
    "    for name in chaotic_experiments.keys():\n",
    "        print(f\"  - {name}\")\n",
    "    \n",
    "    print(\"All tests completed successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
