{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05743c85-1ae1-4acd-84be-96c8f58a642f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '__file__' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 27\u001b[39m\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msetup_imports\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m setup_project_imports\n\u001b[32m     28\u001b[39m     setup_project_imports()\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'setup_imports'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 31\u001b[39m\n\u001b[32m     28\u001b[39m     setup_project_imports()\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[32m     30\u001b[39m     \u001b[38;5;66;03m# 手动设置路径\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m     project_root = os.path.abspath(os.path.join(os.path.dirname(\u001b[34;43m__file__\u001b[39;49m), \u001b[33m'\u001b[39m\u001b[33m..\u001b[39m\u001b[33m'\u001b[39m))\n\u001b[32m     32\u001b[39m     sys.path.insert(\u001b[32m0\u001b[39m, project_root)\n\u001b[32m     33\u001b[39m \u001b[38;5;66;03m# Advanced plotting libraries\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name '__file__' is not defined"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Feature Visualizer - Comprehensive Visualization Tools for Chaotic Features.\n",
    "\n",
    "This module provides advanced visualization capabilities for analyzing chaotic\n",
    "features extracted by the C-HiLAP system, including statistical distributions,\n",
    "correlations, dimensionality reduction plots, and specialized chaos visualizations.\n",
    "\n",
    "Author: C-HiLAP Project\n",
    "Date: 2025\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from typing import Dict, List, Tuple, Optional, Union, Any, Callable\n",
    "from dataclasses import dataclass, field\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# 导入路径设置\n",
    "try:\n",
    "    from setup_imports import setup_project_imports\n",
    "    setup_project_imports()\n",
    "except ImportError:\n",
    "    # 手动设置路径\n",
    "    project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), '..'))\n",
    "    sys.path.insert(0, project_root)\n",
    "    \n",
    "# Advanced plotting libraries\n",
    "try:\n",
    "    import plotly.graph_objects as go\n",
    "    import plotly.express as px\n",
    "    from plotly.subplots import make_subplots\n",
    "    import plotly.offline as pyo\n",
    "    PLOTLY_AVAILABLE = True\n",
    "except ImportError:\n",
    "    PLOTLY_AVAILABLE = False\n",
    "    warnings.warn(\"Plotly not available. Some interactive visualizations will be disabled.\")\n",
    "\n",
    "# Dimensionality reduction for visualization\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE, UMAP\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Statistical analysis\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "\n",
    "# Import project modules\n",
    "try:\n",
    "    from features.chaotic_features import ChaoticFeatureExtractor\n",
    "    from core.phase_space_reconstruction import PhaseSpaceReconstructor\n",
    "    from core.mlsa_extractor import MLSAExtractor\n",
    "    from core.rqa_extractor import RQAExtractor\n",
    "except ImportError as e:\n",
    "    warnings.warn(f\"Could not import project modules: {e}\")\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class VisualizationConfig:\n",
    "    \"\"\"Configuration for visualization settings.\"\"\"\n",
    "    \n",
    "    # Figure settings\n",
    "    figure_size: Tuple[int, int] = (12, 8)\n",
    "    dpi: int = 300\n",
    "    style: str = 'whitegrid'  # seaborn style\n",
    "    color_palette: str = 'husl'  # color palette\n",
    "    font_size: int = 12\n",
    "    title_size: int = 14\n",
    "    \n",
    "    # Plot settings\n",
    "    alpha: float = 0.7\n",
    "    line_width: float = 2.0\n",
    "    marker_size: float = 50\n",
    "    \n",
    "    # Save settings\n",
    "    save_format: str = 'png'  # 'png', 'pdf', 'svg', 'eps'\n",
    "    save_dpi: int = 300\n",
    "    bbox_inches: str = 'tight'\n",
    "    \n",
    "    # Interactive settings\n",
    "    enable_interactive: bool = True\n",
    "    plotly_theme: str = 'plotly_white'\n",
    "    \n",
    "    # Color schemes\n",
    "    chaos_colors: Dict[str, str] = field(default_factory=lambda: {\n",
    "        'mlsa': '#FF6B6B',\n",
    "        'rqa': '#4ECDC4', \n",
    "        'traditional': '#45B7D1',\n",
    "        'fused': '#96CEB4'\n",
    "    })\n",
    "\n",
    "\n",
    "class BaseVisualizer:\n",
    "    \"\"\"Base class for all visualizers.\"\"\"\n",
    "    \n",
    "    def __init__(self, config: VisualizationConfig = None):\n",
    "        self.config = config or VisualizationConfig()\n",
    "        self._setup_style()\n",
    "        \n",
    "    def _setup_style(self):\n",
    "        \"\"\"Setup matplotlib and seaborn styles.\"\"\"\n",
    "        sns.set_style(self.config.style)\n",
    "        plt.rcParams.update({\n",
    "            'font.size': self.config.font_size,\n",
    "            'axes.titlesize': self.config.title_size,\n",
    "            'axes.labelsize': self.config.font_size,\n",
    "            'xtick.labelsize': self.config.font_size,\n",
    "            'ytick.labelsize': self.config.font_size,\n",
    "            'legend.fontsize': self.config.font_size,\n",
    "            'figure.dpi': self.config.dpi,\n",
    "            'savefig.dpi': self.config.save_dpi,\n",
    "            'savefig.bbox': self.config.bbox_inches\n",
    "        })\n",
    "    \n",
    "    def _save_figure(self, fig, filename: str, output_dir: str = None):\n",
    "        \"\"\"Save figure with proper formatting.\"\"\"\n",
    "        if output_dir:\n",
    "            Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
    "            filepath = Path(output_dir) / f\"{filename}.{self.config.save_format}\"\n",
    "        else:\n",
    "            filepath = f\"{filename}.{self.config.save_format}\"\n",
    "        \n",
    "        fig.savefig(filepath, format=self.config.save_format, \n",
    "                   dpi=self.config.save_dpi, bbox_inches=self.config.bbox_inches)\n",
    "        print(f\"Figure saved: {filepath}\")\n",
    "\n",
    "\n",
    "class FeatureDistributionVisualizer(BaseVisualizer):\n",
    "    \"\"\"Visualizer for feature distributions and statistics.\"\"\"\n",
    "    \n",
    "    def plot_feature_distributions(self, features: np.ndarray, \n",
    "                                 feature_names: List[str] = None,\n",
    "                                 labels: np.ndarray = None,\n",
    "                                 max_features: int = 20,\n",
    "                                 output_dir: str = None) -> plt.Figure:\n",
    "        \"\"\"\n",
    "        Plot distributions of multiple features.\n",
    "        \n",
    "        Args:\n",
    "            features: Feature matrix (n_samples, n_features)\n",
    "            feature_names: Names of features\n",
    "            labels: Optional class labels for coloring\n",
    "            max_features: Maximum number of features to plot\n",
    "            output_dir: Output directory for saving\n",
    "            \n",
    "        Returns:\n",
    "            Matplotlib figure\n",
    "        \"\"\"\n",
    "        n_samples, n_features = features.shape\n",
    "        n_plot = min(n_features, max_features)\n",
    "        \n",
    "        # Select most variable features if too many\n",
    "        if n_features > max_features:\n",
    "            feature_vars = np.var(features, axis=0)\n",
    "            top_indices = np.argsort(feature_vars)[-max_features:]\n",
    "            features_to_plot = features[:, top_indices]\n",
    "            if feature_names:\n",
    "                names_to_plot = [feature_names[i] for i in top_indices]\n",
    "            else:\n",
    "                names_to_plot = [f\"Feature_{i}\" for i in top_indices]\n",
    "        else:\n",
    "            features_to_plot = features\n",
    "            names_to_plot = feature_names or [f\"Feature_{i}\" for i in range(n_features)]\n",
    "        \n",
    "        # Create subplots\n",
    "        n_cols = min(4, n_plot)\n",
    "        n_rows = (n_plot + n_cols - 1) // n_cols\n",
    "        \n",
    "        fig, axes = plt.subplots(n_rows, n_cols, figsize=(n_cols * 4, n_rows * 3))\n",
    "        if n_plot == 1:\n",
    "            axes = [axes]\n",
    "        elif n_rows == 1:\n",
    "            axes = axes.flatten() if n_cols > 1 else [axes]\n",
    "        else:\n",
    "            axes = axes.flatten()\n",
    "        \n",
    "        for i in range(n_plot):\n",
    "            ax = axes[i]\n",
    "            feature_data = features_to_plot[:, i]\n",
    "            \n",
    "            if labels is not None:\n",
    "                # Plot by class\n",
    "                unique_labels = np.unique(labels)\n",
    "                for j, label in enumerate(unique_labels):\n",
    "                    mask = labels == label\n",
    "                    ax.hist(feature_data[mask], alpha=0.6, \n",
    "                           label=f'Class {label}', bins=30)\n",
    "                ax.legend()\n",
    "            else:\n",
    "                # Single distribution\n",
    "                ax.hist(feature_data, bins=30, alpha=self.config.alpha,\n",
    "                       color=sns.color_palette()[i % 10])\n",
    "            \n",
    "            ax.set_title(names_to_plot[i])\n",
    "            ax.set_xlabel('Feature Value')\n",
    "            ax.set_ylabel('Frequency')\n",
    "            ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Hide empty subplots\n",
    "        for i in range(n_plot, len(axes)):\n",
    "            axes[i].set_visible(False)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        if output_dir:\n",
    "            self._save_figure(fig, \"feature_distributions\", output_dir)\n",
    "        \n",
    "        return fig\n",
    "    \n",
    "    def plot_feature_statistics(self, features: np.ndarray,\n",
    "                               feature_names: List[str] = None,\n",
    "                               output_dir: str = None) -> plt.Figure:\n",
    "        \"\"\"Plot comprehensive feature statistics.\"\"\"\n",
    "        n_features = features.shape[1]\n",
    "        feature_names = feature_names or [f\"Feature_{i}\" for i in range(n_features)]\n",
    "        \n",
    "        # Calculate statistics\n",
    "        stats = {\n",
    "            'mean': np.mean(features, axis=0),\n",
    "            'std': np.std(features, axis=0),\n",
    "            'skewness': self._calculate_skewness(features),\n",
    "            'kurtosis': self._calculate_kurtosis(features),\n",
    "            'min': np.min(features, axis=0),\n",
    "            'max': np.max(features, axis=0)\n",
    "        }\n",
    "        \n",
    "        # Create subplots\n",
    "        fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "        axes = axes.flatten()\n",
    "        \n",
    "        for i, (stat_name, stat_values) in enumerate(stats.items()):\n",
    "            ax = axes[i]\n",
    "            \n",
    "            # Bar plot for statistics\n",
    "            bars = ax.bar(range(len(stat_values)), stat_values, \n",
    "                         alpha=self.config.alpha)\n",
    "            \n",
    "            # Color bars by value\n",
    "            colors = plt.cm.viridis(np.linspace(0, 1, len(stat_values)))\n",
    "            for bar, color in zip(bars, colors):\n",
    "                bar.set_color(color)\n",
    "            \n",
    "            ax.set_title(f'Feature {stat_name.capitalize()}')\n",
    "            ax.set_xlabel('Feature Index')\n",
    "            ax.set_ylabel(stat_name.capitalize())\n",
    "            ax.grid(True, alpha=0.3)\n",
    "            \n",
    "            # Rotate x-labels if too many features\n",
    "            if len(feature_names) > 20:\n",
    "                ax.tick_params(axis='x', rotation=45)\n",
    "            else:\n",
    "                ax.set_xticks(range(len(feature_names)))\n",
    "                ax.set_xticklabels(feature_names, rotation=45, ha='right')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        if output_dir:\n",
    "            self._save_figure(fig, \"feature_statistics\", output_dir)\n",
    "        \n",
    "        return fig\n",
    "    \n",
    "    def _calculate_skewness(self, data: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Calculate skewness for each feature.\"\"\"\n",
    "        mean = np.mean(data, axis=0)\n",
    "        std = np.std(data, axis=0)\n",
    "        n = data.shape[0]\n",
    "        \n",
    "        skewness = np.sum(((data - mean) / std) ** 3, axis=0) / n\n",
    "        return skewness\n",
    "    \n",
    "    def _calculate_kurtosis(self, data: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Calculate kurtosis for each feature.\"\"\"\n",
    "        mean = np.mean(data, axis=0)\n",
    "        std = np.std(data, axis=0)\n",
    "        n = data.shape[0]\n",
    "        \n",
    "        kurtosis = np.sum(((data - mean) / std) ** 4, axis=0) / n - 3\n",
    "        return kurtosis\n",
    "\n",
    "\n",
    "class CorrelationVisualizer(BaseVisualizer):\n",
    "    \"\"\"Visualizer for feature correlations and relationships.\"\"\"\n",
    "    \n",
    "    def plot_correlation_matrix(self, features: np.ndarray,\n",
    "                               feature_names: List[str] = None,\n",
    "                               method: str = 'pearson',\n",
    "                               output_dir: str = None) -> plt.Figure:\n",
    "        \"\"\"\n",
    "        Plot feature correlation matrix.\n",
    "        \n",
    "        Args:\n",
    "            features: Feature matrix\n",
    "            feature_names: Feature names\n",
    "            method: Correlation method ('pearson', 'spearman')\n",
    "            output_dir: Output directory\n",
    "            \n",
    "        Returns:\n",
    "            Matplotlib figure\n",
    "        \"\"\"\n",
    "        # Calculate correlation matrix\n",
    "        if method == 'pearson':\n",
    "            corr_matrix = np.corrcoef(features.T)\n",
    "        elif method == 'spearman':\n",
    "            from scipy.stats import spearmanr\n",
    "            corr_matrix, _ = spearmanr(features, axis=0)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown correlation method: {method}\")\n",
    "        \n",
    "        # Create figure\n",
    "        fig, ax = plt.subplots(figsize=self.config.figure_size)\n",
    "        \n",
    "        # Create heatmap\n",
    "        im = ax.imshow(corr_matrix, cmap='RdBu_r', aspect='auto', \n",
    "                      vmin=-1, vmax=1)\n",
    "        \n",
    "        # Add colorbar\n",
    "        cbar = plt.colorbar(im, ax=ax)\n",
    "        cbar.set_label(f'{method.capitalize()} Correlation')\n",
    "        \n",
    "        # Set ticks and labels\n",
    "        if feature_names and len(feature_names) <= 50:\n",
    "            ax.set_xticks(range(len(feature_names)))\n",
    "            ax.set_yticks(range(len(feature_names)))\n",
    "            ax.set_xticklabels(feature_names, rotation=45, ha='right')\n",
    "            ax.set_yticklabels(feature_names)\n",
    "        else:\n",
    "            # Too many features, use indices\n",
    "            n_ticks = min(10, len(corr_matrix))\n",
    "            tick_indices = np.linspace(0, len(corr_matrix)-1, n_ticks, dtype=int)\n",
    "            ax.set_xticks(tick_indices)\n",
    "            ax.set_yticks(tick_indices)\n",
    "        \n",
    "        ax.set_title(f'Feature Correlation Matrix ({method.capitalize()})')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        if output_dir:\n",
    "            self._save_figure(fig, f\"correlation_matrix_{method}\", output_dir)\n",
    "        \n",
    "        return fig\n",
    "    \n",
    "    def plot_correlation_heatmap_seaborn(self, features: np.ndarray,\n",
    "                                        feature_names: List[str] = None,\n",
    "                                        method: str = 'pearson',\n",
    "                                        output_dir: str = None) -> plt.Figure:\n",
    "        \"\"\"Plot enhanced correlation heatmap using seaborn.\"\"\"\n",
    "        # Create DataFrame for seaborn\n",
    "        if feature_names:\n",
    "            df = pd.DataFrame(features, columns=feature_names)\n",
    "        else:\n",
    "            df = pd.DataFrame(features)\n",
    "        \n",
    "        # Calculate correlation\n",
    "        corr_matrix = df.corr(method=method)\n",
    "        \n",
    "        # Create figure\n",
    "        fig, ax = plt.subplots(figsize=self.config.figure_size)\n",
    "        \n",
    "        # Create heatmap with seaborn\n",
    "        sns.heatmap(corr_matrix, annot=len(corr_matrix) <= 20,  # Annotate if not too many\n",
    "                    cmap='RdBu_r', center=0, square=True,\n",
    "                    linewidths=0.5, cbar_kws={\"shrink\": .8}, ax=ax)\n",
    "        \n",
    "        ax.set_title(f'Feature Correlation Heatmap ({method.capitalize()})')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        if output_dir:\n",
    "            self._save_figure(fig, f\"correlation_heatmap_{method}\", output_dir)\n",
    "        \n",
    "        return fig\n",
    "    \n",
    "    def plot_pairwise_relationships(self, features: np.ndarray,\n",
    "                                   feature_names: List[str] = None,\n",
    "                                   labels: np.ndarray = None,\n",
    "                                   max_features: int = 10,\n",
    "                                   output_dir: str = None) -> plt.Figure:\n",
    "        \"\"\"Plot pairwise relationships between features.\"\"\"\n",
    "        n_features = min(features.shape[1], max_features)\n",
    "        \n",
    "        # Select most variable features\n",
    "        feature_vars = np.var(features, axis=0)\n",
    "        top_indices = np.argsort(feature_vars)[-n_features:]\n",
    "        \n",
    "        selected_features = features[:, top_indices]\n",
    "        if feature_names:\n",
    "            selected_names = [feature_names[i] for i in top_indices]\n",
    "        else:\n",
    "            selected_names = [f\"F{i}\" for i in top_indices]\n",
    "        \n",
    "        # Create DataFrame\n",
    "        df = pd.DataFrame(selected_features, columns=selected_names)\n",
    "        if labels is not None:\n",
    "            df['Label'] = labels\n",
    "        \n",
    "        # Create pair plot\n",
    "        if labels is not None:\n",
    "            g = sns.pairplot(df, hue='Label', diag_kind='hist', \n",
    "                           plot_kws={'alpha': self.config.alpha})\n",
    "        else:\n",
    "            g = sns.pairplot(df, diag_kind='hist',\n",
    "                           plot_kws={'alpha': self.config.alpha})\n",
    "        \n",
    "        g.fig.suptitle('Pairwise Feature Relationships', y=1.02)\n",
    "        \n",
    "        if output_dir:\n",
    "            self._save_figure(g.fig, \"pairwise_relationships\", output_dir)\n",
    "        \n",
    "        return g.fig\n",
    "\n",
    "\n",
    "class DimensionalityReductionVisualizer(BaseVisualizer):\n",
    "    \"\"\"Visualizer for dimensionality reduction and embedding plots.\"\"\"\n",
    "    \n",
    "    def plot_pca_analysis(self, features: np.ndarray,\n",
    "                         labels: np.ndarray = None,\n",
    "                         n_components: int = 10,\n",
    "                         output_dir: str = None) -> Tuple[plt.Figure, Dict]:\n",
    "        \"\"\"\n",
    "        Plot PCA analysis including explained variance and scatter plots.\n",
    "        \n",
    "        Args:\n",
    "            features: Feature matrix\n",
    "            labels: Optional class labels\n",
    "            n_components: Number of PCA components\n",
    "            output_dir: Output directory\n",
    "            \n",
    "        Returns:\n",
    "            Figure and PCA results dictionary\n",
    "        \"\"\"\n",
    "        # Perform PCA\n",
    "        pca = PCA(n_components=min(n_components, features.shape[1]))\n",
    "        features_pca = pca.fit_transform(features)\n",
    "        \n",
    "        # Create subplots\n",
    "        fig = plt.figure(figsize=(16, 12))\n",
    "        \n",
    "        # 1. Explained variance ratio\n",
    "        ax1 = plt.subplot(2, 3, 1)\n",
    "        plt.bar(range(1, len(pca.explained_variance_ratio_) + 1),\n",
    "                pca.explained_variance_ratio_, alpha=self.config.alpha)\n",
    "        plt.xlabel('Principal Component')\n",
    "        plt.ylabel('Explained Variance Ratio')\n",
    "        plt.title('PCA Explained Variance')\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        # 2. Cumulative explained variance\n",
    "        ax2 = plt.subplot(2, 3, 2)\n",
    "        cumsum = np.cumsum(pca.explained_variance_ratio_)\n",
    "        plt.plot(range(1, len(cumsum) + 1), cumsum, 'o-',\n",
    "                linewidth=self.config.line_width)\n",
    "        plt.axhline(y=0.95, color='r', linestyle='--', \n",
    "                   label='95% Variance')\n",
    "        plt.axhline(y=0.99, color='g', linestyle='--', \n",
    "                   label='99% Variance')\n",
    "        plt.xlabel('Number of Components')\n",
    "        plt.ylabel('Cumulative Explained Variance')\n",
    "        plt.title('Cumulative Explained Variance')\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        # 3. PC1 vs PC2 scatter plot\n",
    "        ax3 = plt.subplot(2, 3, 3)\n",
    "        if labels is not None:\n",
    "            unique_labels = np.unique(labels)\n",
    "            colors = plt.cm.Set1(np.linspace(0, 1, len(unique_labels)))\n",
    "            for i, label in enumerate(unique_labels):\n",
    "                mask = labels == label\n",
    "                plt.scatter(features_pca[mask, 0], features_pca[mask, 1],\n",
    "                           c=[colors[i]], label=f'Class {label}',\n",
    "                           alpha=self.config.alpha, s=self.config.marker_size)\n",
    "            plt.legend()\n",
    "        else:\n",
    "            plt.scatter(features_pca[:, 0], features_pca[:, 1],\n",
    "                       alpha=self.config.alpha, s=self.config.marker_size)\n",
    "        \n",
    "        plt.xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.2%} variance)')\n",
    "        plt.ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.2%} variance)')\n",
    "        plt.title('PCA Scatter Plot (PC1 vs PC2)')\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        # 4. PC1 vs PC3 scatter plot (if available)\n",
    "        if features_pca.shape[1] >= 3:\n",
    "            ax4 = plt.subplot(2, 3, 4)\n",
    "            if labels is not None:\n",
    "                for i, label in enumerate(unique_labels):\n",
    "                    mask = labels == label\n",
    "                    plt.scatter(features_pca[mask, 0], features_pca[mask, 2],\n",
    "                               c=[colors[i]], label=f'Class {label}',\n",
    "                               alpha=self.config.alpha, s=self.config.marker_size)\n",
    "                plt.legend()\n",
    "            else:\n",
    "                plt.scatter(features_pca[:, 0], features_pca[:, 2],\n",
    "                           alpha=self.config.alpha, s=self.config.marker_size)\n",
    "            \n",
    "            plt.xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.2%} variance)')\n",
    "            plt.ylabel(f'PC3 ({pca.explained_variance_ratio_[2]:.2%} variance)')\n",
    "            plt.title('PCA Scatter Plot (PC1 vs PC3)')\n",
    "            plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        # 5. Component loadings heatmap (first few components)\n",
    "        ax5 = plt.subplot(2, 3, 5)\n",
    "        n_show = min(5, pca.components_.shape[0])\n",
    "        loadings = pca.components_[:n_show]\n",
    "        \n",
    "        im = plt.imshow(loadings, aspect='auto', cmap='RdBu_r')\n",
    "        plt.colorbar(im, shrink=0.8)\n",
    "        plt.xlabel('Feature Index')\n",
    "        plt.ylabel('Principal Component')\n",
    "        plt.title('PCA Component Loadings')\n",
    "        \n",
    "        # 6. Feature importance based on first PC\n",
    "        ax6 = plt.subplot(2, 3, 6)\n",
    "        pc1_loadings = np.abs(pca.components_[0])\n",
    "        top_indices = np.argsort(pc1_loadings)[-10:]  # Top 10 features\n",
    "        \n",
    "        plt.barh(range(len(top_indices)), pc1_loadings[top_indices])\n",
    "        plt.xlabel('Absolute Loading')\n",
    "        plt.ylabel('Feature Index')\n",
    "        plt.title('Top Features Contributing to PC1')\n",
    "        plt.yticks(range(len(top_indices)), top_indices)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Prepare results\n",
    "        pca_results = {\n",
    "            'pca_model': pca,\n",
    "            'transformed_features': features_pca,\n",
    "            'explained_variance_ratio': pca.explained_variance_ratio_,\n",
    "            'cumulative_variance': cumsum,\n",
    "            'components': pca.components_\n",
    "        }\n",
    "        \n",
    "        if output_dir:\n",
    "            self._save_figure(fig, \"pca_analysis\", output_dir)\n",
    "        \n",
    "        return fig, pca_results\n",
    "    \n",
    "    def plot_tsne_embedding(self, features: np.ndarray,\n",
    "                           labels: np.ndarray = None,\n",
    "                           perplexity: float = 30.0,\n",
    "                           n_iter: int = 1000,\n",
    "                           output_dir: str = None) -> Tuple[plt.Figure, np.ndarray]:\n",
    "        \"\"\"Plot t-SNE embedding.\"\"\"\n",
    "        print(f\"Computing t-SNE embedding with perplexity={perplexity}...\")\n",
    "        \n",
    "        # Perform t-SNE\n",
    "        tsne = TSNE(n_components=2, perplexity=perplexity, n_iter=n_iter,\n",
    "                   random_state=42)\n",
    "        features_tsne = tsne.fit_transform(features)\n",
    "        \n",
    "        # Create plot\n",
    "        fig, ax = plt.subplots(figsize=self.config.figure_size)\n",
    "        \n",
    "        if labels is not None:\n",
    "            unique_labels = np.unique(labels)\n",
    "            colors = plt.cm.Set1(np.linspace(0, 1, len(unique_labels)))\n",
    "            \n",
    "            for i, label in enumerate(unique_labels):\n",
    "                mask = labels == label\n",
    "                ax.scatter(features_tsne[mask, 0], features_tsne[mask, 1],\n",
    "                          c=[colors[i]], label=f'Class {label}',\n",
    "                          alpha=self.config.alpha, s=self.config.marker_size)\n",
    "            ax.legend()\n",
    "        else:\n",
    "            ax.scatter(features_tsne[:, 0], features_tsne[:, 1],\n",
    "                      alpha=self.config.alpha, s=self.config.marker_size,\n",
    "                      c=plt.cm.viridis(np.linspace(0, 1, len(features_tsne))))\n",
    "        \n",
    "        ax.set_xlabel('t-SNE Dimension 1')\n",
    "        ax.set_ylabel('t-SNE Dimension 2')\n",
    "        ax.set_title(f't-SNE Embedding (perplexity={perplexity})')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        if output_dir:\n",
    "            self._save_figure(fig, f\"tsne_embedding_perp{perplexity}\", output_dir)\n",
    "        \n",
    "        return fig, features_tsne\n",
    "    \n",
    "    def plot_umap_embedding(self, features: np.ndarray,\n",
    "                           labels: np.ndarray = None,\n",
    "                           n_neighbors: int = 15,\n",
    "                           min_dist: float = 0.1,\n",
    "                           output_dir: str = None) -> Tuple[plt.Figure, np.ndarray]:\n",
    "        \"\"\"Plot UMAP embedding.\"\"\"\n",
    "        try:\n",
    "            print(f\"Computing UMAP embedding with n_neighbors={n_neighbors}, min_dist={min_dist}...\")\n",
    "            \n",
    "            # Perform UMAP\n",
    "            umap = UMAP(n_neighbors=n_neighbors, min_dist=min_dist, random_state=42)\n",
    "            features_umap = umap.fit_transform(features)\n",
    "            \n",
    "            # Create plot\n",
    "            fig, ax = plt.subplots(figsize=self.config.figure_size)\n",
    "            \n",
    "            if labels is not None:\n",
    "                unique_labels = np.unique(labels)\n",
    "                colors = plt.cm.Set1(np.linspace(0, 1, len(unique_labels)))\n",
    "                \n",
    "                for i, label in enumerate(unique_labels):\n",
    "                    mask = labels == label\n",
    "                    ax.scatter(features_umap[mask, 0], features_umap[mask, 1],\n",
    "                              c=[colors[i]], label=f'Class {label}',\n",
    "                              alpha=self.config.alpha, s=self.config.marker_size)\n",
    "                ax.legend()\n",
    "            else:\n",
    "                ax.scatter(features_umap[:, 0], features_umap[:, 1],\n",
    "                          alpha=self.config.alpha, s=self.config.marker_size,\n",
    "                          c=plt.cm.viridis(np.linspace(0, 1, len(features_umap))))\n",
    "            \n",
    "            ax.set_xlabel('UMAP Dimension 1')\n",
    "            ax.set_ylabel('UMAP Dimension 2')\n",
    "            ax.set_title(f'UMAP Embedding (n_neighbors={n_neighbors}, min_dist={min_dist})')\n",
    "            ax.grid(True, alpha=0.3)\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            \n",
    "            if output_dir:\n",
    "                self._save_figure(fig, f\"umap_embedding_nn{n_neighbors}_md{min_dist}\", output_dir)\n",
    "            \n",
    "            return fig, features_umap\n",
    "            \n",
    "        except ImportError:\n",
    "            warnings.warn(\"UMAP not available. Please install umap-learn package.\")\n",
    "            return None, None\n",
    "\n",
    "\n",
    "class ChaosSpecificVisualizer(BaseVisualizer):\n",
    "    \"\"\"Visualizer for chaos-specific features and analysis.\"\"\"\n",
    "    \n",
    "    def plot_phase_space(self, embedded_data: np.ndarray,\n",
    "                        title: str = \"Phase Space Reconstruction\",\n",
    "                        output_dir: str = None) -> plt.Figure:\n",
    "        \"\"\"Plot phase space reconstruction.\"\"\"\n",
    "        if embedded_data.shape[1] < 2:\n",
    "            warnings.warn(\"Need at least 2D embedding for phase space plot\")\n",
    "            return None\n",
    "        \n",
    "        fig = plt.figure(figsize=self.config.figure_size)\n",
    "        \n",
    "        if embedded_data.shape[1] == 2:\n",
    "            # 2D phase space\n",
    "            plt.plot(embedded_data[:, 0], embedded_data[:, 1], \n",
    "                    alpha=self.config.alpha, linewidth=0.5)\n",
    "            plt.scatter(embedded_data[0, 0], embedded_data[0, 1], \n",
    "                       c='red', s=100, marker='o', label='Start', zorder=5)\n",
    "            plt.xlabel('x(t)')\n",
    "            plt.ylabel('x(t+τ)')\n",
    "            plt.legend()\n",
    "            plt.grid(True, alpha=0.3)\n",
    "            \n",
    "        elif embedded_data.shape[1] >= 3:\n",
    "            # 3D phase space\n",
    "            ax = fig.add_subplot(111, projection='3d')\n",
    "            \n",
    "            # Plot trajectory\n",
    "            ax.plot(embedded_data[:, 0], embedded_data[:, 1], embedded_data[:, 2],\n",
    "                   alpha=self.config.alpha, linewidth=0.5)\n",
    "            \n",
    "            # Mark start point\n",
    "            ax.scatter(embedded_data[0, 0], embedded_data[0, 1], embedded_data[0, 2],\n",
    "                      c='red', s=100, marker='o', label='Start')\n",
    "            \n",
    "            ax.set_xlabel('x(t)')\n",
    "            ax.set_ylabel('x(t+τ)')\n",
    "            ax.set_zlabel('x(t+2τ)')\n",
    "            ax.legend()\n",
    "        \n",
    "        plt.title(title)\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        if output_dir:\n",
    "            self._save_figure(fig, \"phase_space\", output_dir)\n",
    "        \n",
    "        return fig\n",
    "    \n",
    "    def plot_recurrence_matrix(self, recurrence_matrix: np.ndarray,\n",
    "                              title: str = \"Recurrence Matrix\",\n",
    "                              output_dir: str = None) -> plt.Figure:\n",
    "        \"\"\"Plot recurrence matrix.\"\"\"\n",
    "        fig, ax = plt.subplots(figsize=self.config.figure_size)\n",
    "        \n",
    "        # Plot recurrence matrix\n",
    "        im = ax.imshow(recurrence_matrix, cmap='binary', aspect='auto')\n",
    "        \n",
    "        ax.set_xlabel('Time Index')\n",
    "        ax.set_ylabel('Time Index')\n",
    "        ax.set_title(title)\n",
    "        \n",
    "        # Add colorbar\n",
    "        cbar = plt.colorbar(im, ax=ax)\n",
    "        cbar.set_label('Recurrence')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        if output_dir:\n",
    "            self._save_figure(fig, \"recurrence_matrix\", output_dir)\n",
    "        \n",
    "        return fig\n",
    "    \n",
    "    def plot_lyapunov_spectrum(self, spectrum: np.ndarray,\n",
    "                              title: str = \"Lyapunov Spectrum\",\n",
    "                              output_dir: str = None) -> plt.Figure:\n",
    "        \"\"\"Plot Lyapunov spectrum.\"\"\"\n",
    "        fig, ax = plt.subplots(figsize=self.config.figure_size)\n",
    "        \n",
    "        # Plot spectrum\n",
    "        x_indices = range(1, len(spectrum) + 1)\n",
    "        bars = ax.bar(x_indices, spectrum, alpha=self.config.alpha)\n",
    "        \n",
    "        # Color bars based on sign\n",
    "        for i, (bar, value) in enumerate(zip(bars, spectrum)):\n",
    "            if value > 0:\n",
    "                bar.set_color('red')\n",
    "            elif value < 0:\n",
    "                bar.set_color('blue')\n",
    "            else:\n",
    "                bar.set_color('gray')\n",
    "        \n",
    "        # Add horizontal line at zero\n",
    "        ax.axhline(y=0, color='black', linestyle='-', linewidth=1)\n",
    "        \n",
    "        ax.set_xlabel('Lyapunov Exponent Index')\n",
    "        ax.set_ylabel('Lyapunov Exponent Value')\n",
    "        ax.set_title(title)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Add text annotation for chaos detection\n",
    "        n_positive = np.sum(spectrum > 0)\n",
    "        if n_positive > 0:\n",
    "            ax.text(0.7, 0.9, f'Chaotic: {n_positive} positive exponents',\n",
    "                   transform=ax.transAxes, bbox=dict(boxstyle=\"round\", facecolor='wheat'))\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        if output_dir:\n",
    "            self._save_figure(fig, \"lyapunov_spectrum\", output_dir)\n",
    "        \n",
    "        return fig\n",
    "    \n",
    "    def plot_rqa_measures_comparison(self, rqa_results: Dict[str, Any],\n",
    "                                   output_dir: str = None) -> plt.Figure:\n",
    "        \"\"\"Plot comparison of RQA measures across scales.\"\"\"\n",
    "        if not rqa_results:\n",
    "            warnings.warn(\"No RQA results provided\")\n",
    "            return None\n",
    "        \n",
    "        # Extract RQA measures\n",
    "        scales = list(rqa_results.keys())\n",
    "        measures = ['RR', 'DET', 'LAM', 'L_mean', 'V_mean', 'ENTR']\n",
    "        \n",
    "        # Prepare data\n",
    "        data = {measure: [] for measure in measures}\n",
    "        valid_scales = []\n",
    "        \n",
    "        for scale in scales:\n",
    "            if rqa_results[scale].get('success', False):\n",
    "                valid_scales.append(scale)\n",
    "                rqa_measures = rqa_results[scale]['rqa_measures']\n",
    "                \n",
    "                for measure in measures:\n",
    "                    value = rqa_measures.get(measure, np.nan)\n",
    "                    data[measure].append(value)\n",
    "        \n",
    "        if not valid_scales:\n",
    "            warnings.warn(\"No valid RQA results found\")\n",
    "            return None\n",
    "        \n",
    "        # Create subplots\n",
    "        fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "        axes = axes.flatten()\n",
    "        \n",
    "        for i, measure in enumerate(measures):\n",
    "            ax = axes[i]\n",
    "            \n",
    "            values = data[measure]\n",
    "            ax.plot(valid_scales, values, 'o-', linewidth=self.config.line_width,\n",
    "                   markersize=8)\n",
    "            ax.set_xlabel('Scale')\n",
    "            ax.set_ylabel(measure)\n",
    "            ax.set_title(f'RQA {measure} vs Scale')\n",
    "            ax.grid(True, alpha=0.3)\n",
    "            \n",
    "            # Set x-axis to log scale if scales span multiple orders\n",
    "            if max(valid_scales) / min(valid_scales) > 10:\n",
    "                ax.set_xscale('log')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        if output_dir:\n",
    "            self._save_figure(fig, \"rqa_measures_comparison\", output_dir)\n",
    "        \n",
    "        return fig\n",
    "\n",
    "\n",
    "class ComparisonVisualizer(BaseVisualizer):\n",
    "    \"\"\"Visualizer for comparing different feature types.\"\"\"\n",
    "    \n",
    "    def plot_feature_comparison(self, feature_sets: Dict[str, np.ndarray],\n",
    "                               labels: np.ndarray = None,\n",
    "                               method: str = 'pca',\n",
    "                               output_dir: str = None) -> plt.Figure:\n",
    "        \"\"\"\n",
    "        Compare different feature sets using dimensionality reduction.\n",
    "        \n",
    "        Args:\n",
    "            feature_sets: Dictionary of {name: features} pairs\n",
    "            labels: Optional class labels\n",
    "            method: Dimensionality reduction method ('pca', 'tsne')\n",
    "            output_dir: Output directory\n",
    "            \n",
    "        Returns:\n",
    "            Matplotlib figure\n",
    "        \"\"\"\n",
    "        n_sets = len(feature_sets)\n",
    "        if n_sets == 0:\n",
    "            return None\n",
    "        \n",
    "        # Create subplots\n",
    "        n_cols = min(3, n_sets)\n",
    "        n_rows = (n_sets + n_cols - 1) // n_cols\n",
    "        \n",
    "        fig, axes = plt.subplots(n_rows, n_cols, figsize=(n_cols * 6, n_rows * 5))\n",
    "        if n_sets == 1:\n",
    "            axes = [axes]\n",
    "        elif n_rows == 1:\n",
    "            axes = axes.flatten() if n_cols > 1 else [axes]\n",
    "        else:\n",
    "            axes = axes.flatten()\n",
    "        \n",
    "        for i, (name, features) in enumerate(feature_sets.items()):\n",
    "            ax = axes[i]\n",
    "            \n",
    "            # Apply dimensionality reduction\n",
    "            if method == 'pca':\n",
    "                reducer = PCA(n_components=2)\n",
    "                features_2d = reducer.fit_transform(features)\n",
    "                var_explained = reducer.explained_variance_ratio_\n",
    "                xlabel = f'PC1 ({var_explained[0]:.1%})'\n",
    "                ylabel = f'PC2 ({var_explained[1]:.1%})'\n",
    "                \n",
    "            elif method == 'tsne':\n",
    "                reducer = TSNE(n_components=2, random_state=42)\n",
    "                features_2d = reducer.fit_transform(features)\n",
    "                xlabel = 't-SNE Dimension 1'\n",
    "                ylabel = 't-SNE Dimension 2'\n",
    "                \n",
    "            else:\n",
    "                warnings.warn(f\"Unknown method {method}\")\n",
    "                continue\n",
    "            \n",
    "            # Plot\n",
    "            if labels is not None:\n",
    "                unique_labels = np.unique(labels)\n",
    "                colors = plt.cm.Set1(np.linspace(0, 1, len(unique_labels)))\n",
    "                \n",
    "                for j, label in enumerate(unique_labels):\n",
    "                    mask = labels == label\n",
    "                    ax.scatter(features_2d[mask, 0], features_2d[mask, 1],\n",
    "                              c=[colors[j]], label=f'Class {label}',\n",
    "                              alpha=self.config.alpha, s=self.config.marker_size)\n",
    "                \n",
    "                if i == 0:  # Only show legend for first subplot\n",
    "                    ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "            else:\n",
    "                color = self.config.chaos_colors.get(name.lower(), \n",
    "                                                   plt.cm.Set1(i / n_sets))\n",
    "                ax.scatter(features_2d[:, 0], features_2d[:, 1],\n",
    "                          c=color, alpha=self.config.alpha, s=self.config.marker_size)\n",
    "            \n",
    "            ax.set_xlabel(xlabel)\n",
    "            ax.set_ylabel(ylabel)\n",
    "            ax.set_title(f'{name} Features ({method.upper()})')\n",
    "            ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Hide empty subplots\n",
    "        for i in range(n_sets, len(axes)):\n",
    "            axes[i].set_visible(False)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        if output_dir:\n",
    "            self._save_figure(fig, f\"feature_comparison_{method}\", output_dir)\n",
    "        \n",
    "        return fig\n",
    "    \n",
    "    def plot_performance_comparison(self, performance_results: Dict[str, Dict],\n",
    "                                   metrics: List[str] = None,\n",
    "                                   output_dir: str = None) -> plt.Figure:\n",
    "        \"\"\"Plot performance comparison across different feature types.\"\"\"\n",
    "        if not performance_results:\n",
    "            return None\n",
    "        \n",
    "        metrics = metrics or ['accuracy', 'precision', 'recall', 'f1_score']\n",
    "        method_names = list(performance_results.keys())\n",
    "        \n",
    "        # Prepare data\n",
    "        data = {metric: [] for metric in metrics}\n",
    "        valid_methods = []\n",
    "        \n",
    "        for method in method_names:\n",
    "            results = performance_results[method]\n",
    "            if all(metric in results for metric in metrics):\n",
    "                valid_methods.append(method)\n",
    "                for metric in metrics:\n",
    "                    data[metric].append(results[metric])\n",
    "        \n",
    "        if not valid_methods:\n",
    "            warnings.warn(\"No valid performance results found\")\n",
    "            return None\n",
    "        \n",
    "        # Create grouped bar plot\n",
    "        fig, ax = plt.subplots(figsize=self.config.figure_size)\n",
    "        \n",
    "        x = np.arange(len(valid_methods))\n",
    "        width = 0.2\n",
    "        n_metrics = len(metrics)\n",
    "        \n",
    "        colors = plt.cm.Set1(np.linspace(0, 1, n_metrics))\n",
    "        \n",
    "        for i, metric in enumerate(metrics):\n",
    "            offset = (i - n_metrics/2 + 0.5) * width\n",
    "            bars = ax.bar(x + offset, data[metric], width, \n",
    "                         label=metric.capitalize(), color=colors[i],\n",
    "                         alpha=self.config.alpha)\n",
    "            \n",
    "            # Add value labels on bars\n",
    "            for bar in bars:\n",
    "                height = bar.get_height()\n",
    "                ax.text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
    "                       f'{height:.3f}', ha='center', va='bottom', fontsize=10)\n",
    "        \n",
    "        ax.set_xlabel('Feature Type')\n",
    "        ax.set_ylabel('Performance Score')\n",
    "        ax.set_title('Performance Comparison Across Feature Types')\n",
    "        ax.set_xticks(x)\n",
    "        ax.set_xticklabels(valid_methods, rotation=45, ha='right')\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3, axis='y')\n",
    "        ax.set_ylim(0, 1.1)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        if output_dir:\n",
    "            self._save_figure(fig, \"performance_comparison\", output_dir)\n",
    "        \n",
    "        return fig\n",
    "\n",
    "\n",
    "class InteractiveVisualizer:\n",
    "    \"\"\"Interactive visualizer using Plotly.\"\"\"\n",
    "    \n",
    "    def __init__(self, config: VisualizationConfig = None):\n",
    "        self.config = config or VisualizationConfig()\n",
    "        \n",
    "        if not PLOTLY_AVAILABLE:\n",
    "            warnings.warn(\"Plotly not available. Interactive features disabled.\")\n",
    "    \n",
    "    def create_interactive_feature_explorer(self, features: np.ndarray,\n",
    "                                           feature_names: List[str] = None,\n",
    "                                           labels: np.ndarray = None,\n",
    "                                           output_file: str = None) -> go.Figure:\n",
    "        \"\"\"Create interactive feature exploration plot.\"\"\"\n",
    "        if not PLOTLY_AVAILABLE:\n",
    "            return None\n",
    "        \n",
    "        # Perform PCA for 2D visualization\n",
    "        pca = PCA(n_components=2)\n",
    "        features_2d = pca.fit_transform(features)\n",
    "        \n",
    "        # Create DataFrame\n",
    "        df = pd.DataFrame({\n",
    "            'PC1': features_2d[:, 0],\n",
    "            'PC2': features_2d[:, 1],\n",
    "            'Sample_Index': range(len(features_2d))\n",
    "        })\n",
    "        \n",
    "        if labels is not None:\n",
    "            df['Label'] = labels.astype(str)\n",
    "        \n",
    "        # Add original features for hover information\n",
    "        if feature_names:\n",
    "            for i, name in enumerate(feature_names[:10]):  # Limit to first 10\n",
    "                df[name] = features[:, i]\n",
    "        \n",
    "        # Create interactive scatter plot\n",
    "        if labels is not None:\n",
    "            fig = px.scatter(df, x='PC1', y='PC2', color='Label',\n",
    "                           hover_data=feature_names[:10] if feature_names else None,\n",
    "                           title='Interactive Feature Explorer')\n",
    "        else:\n",
    "            fig = px.scatter(df, x='PC1', y='PC2',\n",
    "                           hover_data=feature_names[:10] if feature_names else None,\n",
    "                           title='Interactive Feature Explorer')\n",
    "        \n",
    "        # Update layout\n",
    "        fig.update_layout(\n",
    "            template=self.config.plotly_theme,\n",
    "            xaxis_title=f'PC1 ({pca.explained_variance_ratio_[0]:.1%} variance)',\n",
    "            yaxis_title=f'PC2 ({pca.explained_variance_ratio_[1]:.1%} variance)',\n",
    "            font=dict(size=self.config.font_size)\n",
    "        )\n",
    "        \n",
    "        if output_file:\n",
    "            fig.write_html(output_file)\n",
    "            print(f\"Interactive plot saved: {output_file}\")\n",
    "        \n",
    "        return fig\n",
    "    \n",
    "    def create_interactive_correlation_matrix(self, features: np.ndarray,\n",
    "                                            feature_names: List[str] = None,\n",
    "                                            output_file: str = None) -> go.Figure:\n",
    "        \"\"\"Create interactive correlation matrix.\"\"\"\n",
    "        if not PLOTLY_AVAILABLE:\n",
    "            return None\n",
    "        \n",
    "        # Calculate correlation matrix\n",
    "        corr_matrix = np.corrcoef(features.T)\n",
    "        \n",
    "        # Create labels\n",
    "        if feature_names:\n",
    "            labels = feature_names\n",
    "        else:\n",
    "            labels = [f'Feature_{i}' for i in range(len(corr_matrix))]\n",
    "        \n",
    "        # Create interactive heatmap\n",
    "        fig = go.Figure(data=go.Heatmap(\n",
    "            z=corr_matrix,\n",
    "            x=labels,\n",
    "            y=labels,\n",
    "            colorscale='RdBu',\n",
    "            zmid=0,\n",
    "            text=np.round(corr_matrix, 3),\n",
    "            texttemplate=\"%{text}\",\n",
    "            textfont={\"size\": 8},\n",
    "            hovertemplate='%{y} vs %{x}<br>Correlation: %{z:.3f}<extra></extra>'\n",
    "        ))\n",
    "        \n",
    "        fig.update_layout(\n",
    "            title='Interactive Correlation Matrix',\n",
    "            template=self.config.plotly_theme,\n",
    "            font=dict(size=self.config.font_size),\n",
    "            width=800,\n",
    "            height=800\n",
    "        )\n",
    "        \n",
    "        if output_file:\n",
    "            fig.write_html(output_file)\n",
    "            print(f\"Interactive correlation matrix saved: {output_file}\")\n",
    "        \n",
    "        return fig\n",
    "\n",
    "\n",
    "def create_comprehensive_report(features: np.ndarray,\n",
    "                               feature_names: List[str] = None,\n",
    "                               labels: np.ndarray = None,\n",
    "                               output_dir: str = \"visualization_report\",\n",
    "                               config: VisualizationConfig = None):\n",
    "    \"\"\"Create a comprehensive visualization report.\"\"\"\n",
    "    print(f\"Creating comprehensive visualization report in {output_dir}...\")\n",
    "    \n",
    "    # Create output directory\n",
    "    Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Initialize visualizers\n",
    "    config = config or VisualizationConfig()\n",
    "    \n",
    "    dist_viz = FeatureDistributionVisualizer(config)\n",
    "    corr_viz = CorrelationVisualizer(config)\n",
    "    dim_viz = DimensionalityReductionVisualizer(config)\n",
    "    \n",
    "    # Generate all visualizations\n",
    "    figures = {}\n",
    "    \n",
    "    # 1. Feature distributions\n",
    "    print(\"Creating feature distributions...\")\n",
    "    figures['distributions'] = dist_viz.plot_feature_distributions(\n",
    "        features, feature_names, labels, output_dir=output_dir\n",
    "    )\n",
    "    \n",
    "    # 2. Feature statistics\n",
    "    print(\"Creating feature statistics...\")\n",
    "    figures['statistics'] = dist_viz.plot_feature_statistics(\n",
    "        features, feature_names, output_dir=output_dir\n",
    "    )\n",
    "    \n",
    "    # 3. Correlation analysis\n",
    "    print(\"Creating correlation analysis...\")\n",
    "    figures['correlation'] = corr_viz.plot_correlation_heatmap_seaborn(\n",
    "        features, feature_names, output_dir=output_dir\n",
    "    )\n",
    "    \n",
    "    # 4. PCA analysis\n",
    "    print(\"Creating PCA analysis...\")\n",
    "    figures['pca'], pca_results = dim_viz.plot_pca_analysis(\n",
    "        features, labels, output_dir=output_dir\n",
    "    )\n",
    "    \n",
    "    # 5. t-SNE embedding\n",
    "    print(\"Creating t-SNE embedding...\")\n",
    "    figures['tsne'], _ = dim_viz.plot_tsne_embedding(\n",
    "        features, labels, output_dir=output_dir\n",
    "    )\n",
    "    \n",
    "    # 6. UMAP embedding (if available)\n",
    "    print(\"Creating UMAP embedding...\")\n",
    "    umap_fig, _ = dim_viz.plot_umap_embedding(\n",
    "        features, labels, output_dir=output_dir\n",
    "    )\n",
    "    if umap_fig:\n",
    "        figures['umap'] = umap_fig\n",
    "    \n",
    "    # Save summary\n",
    "    summary = {\n",
    "        'n_samples': features.shape[0],\n",
    "        'n_features': features.shape[1],\n",
    "        'n_classes': len(np.unique(labels)) if labels is not None else 'Unknown',\n",
    "        'pca_variance_95': np.sum(pca_results['explained_variance_ratio'].cumsum() <= 0.95) + 1,\n",
    "        'total_variance_explained': pca_results['explained_variance_ratio'].sum()\n",
    "    }\n",
    "    \n",
    "    with open(Path(output_dir) / \"report_summary.json\", 'w') as f:\n",
    "        json.dump(summary, f, indent=2, default=str)\n",
    "    \n",
    "    print(f\"✓ Comprehensive visualization report created in {output_dir}\")\n",
    "    print(f\"Generated {len(figures)} visualizations\")\n",
    "    \n",
    "    return figures\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Example usage and testing\n",
    "    print(\"Testing Feature Visualizer...\")\n",
    "    \n",
    "    # Generate synthetic data for testing\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # Create synthetic features with different characteristics\n",
    "    n_samples = 200\n",
    "    n_features = 50\n",
    "    \n",
    "    # Generate features with different distributions\n",
    "    features = np.random.randn(n_samples, n_features)\n",
    "    \n",
    "    # Add some structure\n",
    "    features[:, 0] = features[:, 1] + np.random.normal(0, 0.1, n_samples)  # Correlated features\n",
    "    features[:, 2] = features[:, 0] ** 2 + np.random.normal(0, 0.2, n_samples)  # Nonlinear relation\n",
    "    \n",
    "    # Create labels\n",
    "    labels = np.random.choice([0, 1, 2], n_samples)\n",
    "    \n",
    "    # Feature names\n",
    "    feature_names = [f\"Feature_{i}\" for i in range(n_features)]\n",
    "    \n",
    "    print(f\"Generated synthetic data: {features.shape} features, {len(np.unique(labels))} classes\")\n",
    "    \n",
    "    # Test different visualizers\n",
    "    config = VisualizationConfig(figure_size=(10, 8))\n",
    "    \n",
    "    # 1. Test distribution visualizer\n",
    "    print(\"\\nTesting distribution visualizer...\")\n",
    "    dist_viz = FeatureDistributionVisualizer(config)\n",
    "    fig1 = dist_viz.plot_feature_distributions(features, feature_names, labels)\n",
    "    plt.show(block=False)\n",
    "    \n",
    "    # 2. Test correlation visualizer  \n",
    "    print(\"Testing correlation visualizer...\")\n",
    "    corr_viz = CorrelationVisualizer(config)\n",
    "    fig2 = corr_viz.plot_correlation_heatmap_seaborn(features, feature_names)\n",
    "    plt.show(block=False)\n",
    "    \n",
    "    # 3. Test dimensionality reduction visualizer\n",
    "    print(\"Testing dimensionality reduction visualizer...\")\n",
    "    dim_viz = DimensionalityReductionVisualizer(config)\n",
    "    fig3, pca_results = dim_viz.plot_pca_analysis(features, labels)\n",
    "    plt.show(block=False)\n",
    "    \n",
    "    # 4. Test t-SNE\n",
    "    print(\"Testing t-SNE visualization...\")\n",
    "    fig4, tsne_features = dim_viz.plot_tsne_embedding(features, labels, n_iter=500)\n",
    "    plt.show(block=False)\n",
    "    \n",
    "    # 5. Test comprehensive report\n",
    "    print(\"\\nCreating comprehensive report...\")\n",
    "    output_dir = \"test_visualization_report\"\n",
    "    figures = create_comprehensive_report(\n",
    "        features, feature_names, labels, \n",
    "        output_dir=output_dir, config=config\n",
    "    )\n",
    "    \n",
    "    print(f\"✓ Feature Visualizer testing completed!\")\n",
    "    print(f\"Generated {len(figures)} visualization figures\")\n",
    "    print(f\"Report saved in: {output_dir}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
